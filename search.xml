<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[迁移学习——Keras]]></title>
    <url>%2F2020%2F07%2F03%2F74-%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94Keras%2F</url>
    <content type="text"><![CDATA[本文讲解迁移学习（Transfer Learning），以及迁移学习在Keras中的实现。 Understanding transfer learning: the concepts在上篇文章中，我们知道过拟合是如何产生的，我们也采用了数据增广方式来避免过拟合。但这样的方式缺点就在于我们都要构建模型重头开始训练。 是否有可能存在一个已经训练好的模型，并将其学习得到的特征应用到我们所需要预测的样本上呢？这就是迁移学习主要干的事。我们将已训练模型所得到的参数给锁定，直接将这些训练好的特征投入到需要进行下一步训练的模型当中。 在Horses versas Humans数据集中，我们以《Rethinking the Inception Architecture for Computer Vision》该文章中的模型作为已训练模型，将其迁移至我们的数据集中，帮助提高训练准确率。这篇文章采用了ImageNet数据集进行预训练，这个数据集非常庞大，包括了140万张图片，并覆盖1000个不同的类别。 Coding transfer learning from the inception mode123456789101112131415161718192021222324252627# 加载模块import osimport tensorflow as tffrom tensorflow.keras import layersfrom tensorflow.keras import Modelfrom os import getcwd# 加载已经训练好的模型 (pre_trained_model)path_inception = f&quot;&#123;getcwd()&#125;/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5&quot;# Import the inception model from tensorflow.keras.applications.inception_v3 import InceptionV3# Create an instance of the inception model from the local pre-trained weightslocal_weights_file = path_inceptionpre_trained_model = InceptionV3(input_shape = (150,150,3), include_top = False, weights = None) # Your Code Herepre_trained_model.load_weights(local_weights_file)# Make all the layers in the pre-trained model non-trainablefor layer in pre_trained_model.layers: layer.trainable = False # Your Code Here # Print the model summarypre_trained_model.summary() 如上，加载了预训练模型后，我们可以通过pre_trained_model.summary()查看预训练模型中每个训练层的维度。其次，我们可以选择其中某一层作为接下来需要训练的连接层。当然，也可以将预训练模型的最后一层作为连接层。在这里，我们挑了mixed7层作为与接下来模型进行连接的层，该层的输出维度为(7,7,768)。 123456last_layer = pre_trained_model.get_layer(&apos;mixed7&apos;) # Your Code Here)print(&apos;last layer output shape: &apos;, last_layer.output_shape)last_output = last_layer.output # Your Code Here# Expected Output:# (&apos;last layer output shape: &apos;, (None, 7, 7, 768)) 为了尽快完成训练，在此添加了callback机制，当训练准确率达到97%时，即停止训练： 123456# Define a Callback class that stops training once accuracy reaches 97.0%class myCallback(tf.keras.callbacks.Callback): def on_epoch_end(self, epoch, logs=&#123;&#125;): if(logs.get(&apos;acc&apos;)&gt;0.97): print(&quot;\nReached 97.0% accuracy so cancelling training!&quot;) self.model.stop_training = True 好了，预训练模型加载完成后，我们需要在预训练模型的基础上继续搭建完善自己的模型。对于预训练模型这样一个庞大的神经网络，有时候也可能也会出现过拟合的现象，因此可以dropout层，减少不同层之间相似参数的传递，从而减小过拟合出现的概率。 123456789101112131415161718from tensorflow.keras.optimizers import RMSprop# Flatten the output layer to 1 dimensionx = layers.Flatten()(last_output)# Add a fully connected layer with 1,024 hidden units and ReLU activationx = layers.Dense(1024, activation=&apos;relu&apos;)(x)# Add a dropout rate of 0.2x = layers.Dropout(0.2)(x) # Add a final sigmoid layer for classificationx = layers.Dense(1, activation=&apos;sigmoid&apos;)(x) model = Model(pre_trained_model.input, x) model.compile(optimizer = RMSprop(lr=0.0001), loss = &apos;binary_crossentropy&apos;, metrics = [&apos;acc&apos;])model.summary() 这次我们采用的数据集是 Horses versas Humans数据集，首先将数据集下载： 1234567891011121314151617181920# Get the Horse or Human datasetpath_horse_or_human = f&quot;&#123;getcwd()&#125;/../tmp2/horse-or-human.zip&quot;# Get the Horse or Human Validation datasetpath_validation_horse_or_human = f&quot;&#123;getcwd()&#125;/../tmp2/validation-horse-or-human.zip&quot;from tensorflow.keras.preprocessing.image import ImageDataGeneratorimport osimport zipfileimport shutilshutil.rmtree(&apos;/tmp&apos;)local_zip = path_horse_or_humanzip_ref = zipfile.ZipFile(local_zip, &apos;r&apos;)zip_ref.extractall(&apos;/tmp/training&apos;)zip_ref.close()local_zip = path_validation_horse_or_humanzip_ref = zipfile.ZipFile(local_zip, &apos;r&apos;)zip_ref.extractall(&apos;/tmp/validation&apos;)zip_ref.close() 采用ImageDataGenerator对数据集不同类别图片划分并打上标签， 1234567891011121314151617181920212223242526272829303132# Define our example directories and filestrain_dir = &apos;/tmp/training&apos;validation_dir = &apos;/tmp/validation&apos;train_horses_dir = os.path.join(train_dir, &apos;horses&apos;) # Your Code Heretrain_humans_dir = os.path.join(train_dir, &apos;humans&apos;) # Your Code Herevalidation_horses_dir = os.path.join(validation_dir, &apos;horses&apos;) # Your Code Herevalidation_humans_dir = os.path.join(validation_dir, &apos;humans&apos;) # Your Code Heretrain_horses_fnames = os.listdir(train_horses_dir) # Your Code Heretrain_humans_fnames = os.listdir(train_humans_dir) # Your Code Herevalidation_horses_fnames = os.listdir(validation_horses_dir) # Your Code Herevalidation_humans_fnames = os.listdir(validation_humans_dir) # Your Code Hereprint(len(train_horses_fnames)) # Your Code Hereprint(len(train_humans_fnames))# Your Code Here)print(len(validation_horses_fnames)) # Your Code Here)print(len(validation_humans_fnames)) # Your Code Here)# Add our data-augmentation parameters to ImageDataGeneratortrain_datagen = ImageDataGenerator(rescale=1./255., rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True) # Your Code Here# Note that the validation data should not be augmented!test_datagen = ImageDataGenerator(rescale=1./255.) # Your Code Here )# Flow training images in batches of 20 using train_datagen generatortrain_generator = train_datagen.flow_from_directory(train_dir, batch_size=10, class_mode=&apos;binary&apos;, target_size=(150, 150)) # Your Code Here) # Flow validation images in batches of 20 using test_datagen generatorvalidation_generator = test_datagen.flow_from_directory(validation_dir, batch_size=10, class_mode=&apos;binary&apos;, target_size=(150, 150)) # Your Code Here) 最后训练模型，记得要把callbacks参数加上： 1234callbacks = myCallback() # Your Code Herehistory = model.fit_generator(train_generator, validation_data=validation_generator, steps_per_epoch=100, epochs=3, validation_steps=50, verbose=2, callbacks=[callbacks]) # Your Code Here (set epochs = 3)) 作图如下： 123456789101112131415%matplotlib inlineimport matplotlib.pyplot as pltacc = history.history[&apos;acc&apos;]val_acc = history.history[&apos;val_acc&apos;]loss = history.history[&apos;loss&apos;]val_loss = history.history[&apos;val_loss&apos;]epochs = range(len(acc))plt.plot(epochs, acc, &apos;r&apos;, label=&apos;Training accuracy&apos;)plt.plot(epochs, val_acc, &apos;b&apos;, label=&apos;Validation accuracy&apos;)plt.title(&apos;Training and validation accuracy&apos;)plt.legend(loc=0)plt.figure()plt.show() 可见，采用别人预训练得到的参数，对自己训练的精确度提升帮助极大。这也是迁移学习最大的优点。 Reference Rethinking the Inception Architecture for Computer Vision]]></content>
      <categories>
        <category>Coursera</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>学习笔记</tag>
        <tag>TensorFlow</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据增广在TensorFlow中的实现]]></title>
    <url>%2F2020%2F07%2F02%2F73-%E6%95%B0%E6%8D%AE%E5%A2%9E%E5%B9%BF%E5%9C%A8TensorFlow%E4%B8%AD%E7%9A%84%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[本文接着上篇文章的例子，主要讲解如何利用数据增广方法扩大训练集，并以此解决过拟合问题。 Introducing Augmentation什么是数据增广（Data Augmentation）？这个我们或许要从过拟合谈起（Overfitting）。在上篇文章的例子中，在经过一定次数的迭代之后，我们可以发现训练集的loss在持续下降而acc则持续上升，然而测试集并非如此，测试集的loss很难降下去且acc也不容易提高。这即是由过拟合所造成的。 举个例子，例如说模型中的训练集都是类似下图般的鞋子： 再给模型一张鞋子的图片，那么模型会很轻易能识别出来，因为鞋子类型十分相似： 但是，如果给模型一张高跟鞋的图片，那么模型想要正确识别出这也是一双鞋，则未必那么简单了。 这就是过拟合，在过去的博文中也多次有提及。过拟合问题在数据训练样本较少时容易发生，想要解决过拟合，数据增广是一个非常有效的方法。 例如在猫狗数据集训练样本中，猫的两只耳朵都是竖直的，如下图： 那么如果测试集样本中，猫是躺着的，则耳朵是歪的，模型则很可能判断出错。那要怎么解决这个问题呢？数据增广则给出了很好的解决办法，那就是将训练集的样本图片进行翻转、歪曲等多种方式，产生新的样本图片进行训练，增大训练样本。 在这样的情况下，不管猫的耳朵是竖直还是歪着的，训练集中都有相应的训练样本捕捉到相关特征，从而提高测试集的正确率。 The impact of augmentation on Cats vs. Dogs数据增广在TensorFlow的keras中如何实现呢？首先，我们先搭建卷积神经网络层（以上篇文章的数据为例）： 12345678910111213141516model = tf.keras.models.Sequential([# YOUR CODE HERE tf.keras.layers.Conv2D(32, (3,3), activation=&apos;relu&apos;, input_shape=(150, 150, 3)), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(64, (3,3), activation=&apos;relu&apos;), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(128, (3,3), activation=&apos;relu&apos;), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(128, (3,3), activation=&apos;relu&apos;), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(512, activation=&apos;relu&apos;), tf.keras.layers.Dense(1, activation=&apos;sigmoid&apos;)])model.compile(optimizer=RMSprop(lr=0.001), loss=&apos;binary_crossentropy&apos;, metrics=[&apos;acc&apos;]) 其次，采用ImageDataGenerator()对训练集样本进行数据增广，测试集保持不变。 12345678TRAINING_DIR = &quot;/tmp/cats-v-dogs/training/&quot; train_datagen = ImageDataGenerator(rescale=1.0/255, rotation_range=40, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode=&apos;nearest&apos;)train_generator = train_datagen.flow_from_directory(TRAINING_DIR, batch_size=10, class_mode=&apos;binary&apos;, target_size=(150,150))VALIDATION_DIR = &quot;/tmp/cats-v-dogs/testing/&quot; validation_datagen = ImageDataGenerator( rescale=1.0/255.) validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, batch_size=10, class_mode=&apos;binary&apos;, target_size=(150,150)) 在上述代码中，参数rotation_range=40表示将图片在[0,40]度区间范围内随机旋转的角度，width_shift_range和height_shift_range分别表示在水平或竖直方向上随机偏移的幅度，shear_range表示以弧度逆时针方向剪切的角度，具体的效果可见下图。zoom_range则表示图片随机缩放的程度。 原图如上图，在进行shear之后，变成这样子： 在进行数据增广之后，对模型进行训练： 1234history = model.fit_generator(train_generator, epochs=15, verbose=1, validation_data=validation_generator) 在这里采用15个迭代次数，并分别画得Training和Validation数据集的loss和acc值。 Reference 上篇文章 Keras的ImageDataGenerator文档说明]]></content>
      <categories>
        <category>Coursera</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>学习笔记</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[采用卷积神经网络进行图片分类——基于Kaggle数据集的简单例子]]></title>
    <url>%2F2020%2F06%2F24%2F72-%E9%87%87%E7%94%A8%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%BF%9B%E8%A1%8C%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8EKaggle%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E7%AE%80%E5%8D%95%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[在Keras这个深度学习框架下，神经网络的构建变得十分方便简单。本文开始介绍Tensorflow专项课程的第二门课《Convolutional Neural Networks in TensorFlow》，第一周的课程主要讲解了采用卷积神经网络对Kaggle上的一个猫狗图片集进行分类的简单例子。本课里还涉及到许多Python的小技巧，比如怎么将所有图片按比例划分到训练集和验证集、如何为图片自动贴标签等，学起来吧！ Training with the cats vs. dogs dataset123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181# 加载各类包import osimport zipfileimport randomimport tensorflow as tfimport shutilfrom tensorflow.keras.optimizers import RMSpropfrom tensorflow.keras.preprocessing.image import ImageDataGeneratorfrom shutil import copyfilefrom os import getcwd# 解压数据集（该数据集已下载好）path_cats_and_dogs = f&quot;&#123;getcwd()&#125;/../tmp2/cats-and-dogs.zip&quot;shutil.rmtree(&apos;/tmp&apos;)local_zip = path_cats_and_dogszip_ref = zipfile.ZipFile(local_zip, &apos;r&apos;)zip_ref.extractall(&apos;/tmp&apos;)zip_ref.close()# 查看数据集中图片的样本量print(len(os.listdir(&apos;/tmp/PetImages/Cat/&apos;)))print(len(os.listdir(&apos;/tmp/PetImages/Dog/&apos;)))# Expected Output:# 1500# 1500# 构建训练集和样本集的文件路径# Use os.mkdir to create your directories# You will need a directory for cats-v-dogs, and subdirectories for training# and testing. These in turn will need subdirectories for &apos;cats&apos; and &apos;dogs&apos;try: #YOUR CODE GOES HERE base_dir =&apos;/tmp/cats-v-dogs&apos; training = os.path.join(base_dir, &apos;training&apos;) testing = os.path.join(base_dir, &apos;testing&apos;) # Directory with our training cat/dog pictures train_cats = os.path.join(training, &apos;cats&apos;) train_dogs = os.path.join(training, &apos;dogs&apos;) # Directory with our validation cat/dog pictures test_cats = os.path.join(testing, &apos;cats&apos;) test_dogs = os.path.join(testing, &apos;dogs&apos;) os.mkdir(base_dir) os.mkdir(training) os.mkdir(testing) os.mkdir(train_cats) os.mkdir(train_dogs) os.mkdir(test_cats) os.mkdir(test_dogs)except OSError:pass# 将原数据集中的所有图片按比例分配训练集和测试集文件路径中# Write a python function called split_data which takes# a SOURCE directory containing the files# a TRAINING directory that a portion of the files will be copied to# a TESTING directory that a portion of the files will be copie to# a SPLIT SIZE to determine the portion# The files should also be randomized, so that the training set is a random# X% of the files, and the test set is the remaining files# SO, for example, if SOURCE is PetImages/Cat, and SPLIT SIZE is .9# Then 90% of the images in PetImages/Cat will be copied to the TRAINING dir# and 10% of the images will be copied to the TESTING dir# Also -- All images should be checked, and if they have a zero file length,# they will not be copied over## os.listdir(DIRECTORY) gives you a listing of the contents of that directory# os.path.getsize(PATH) gives you the size of the file# copyfile(source, destination) copies a file from source to destination# random.sample(list, len(list)) shuffles a listdef split_data(SOURCE, TRAINING, TESTING, SPLIT_SIZE):# YOUR CODE STARTS HERE files_list = os.listdir(SOURCE) #index = [i for i in range(len(files_list))] train = random.sample(files_list, int(SPLIT_SIZE * len(files_list))) #test = [x for x in files_list if x not in train] for i in files_list: file_name = os.path.join(SOURCE, i) if i in train: copyfile(file_name, TRAINING+i) else: copyfile(file_name, TESTING+i)# YOUR CODE ENDS HERECAT_SOURCE_DIR = &quot;/tmp/PetImages/Cat/&quot;TRAINING_CATS_DIR = &quot;/tmp/cats-v-dogs/training/cats/&quot;TESTING_CATS_DIR = &quot;/tmp/cats-v-dogs/testing/cats/&quot;DOG_SOURCE_DIR = &quot;/tmp/PetImages/Dog/&quot;TRAINING_DOGS_DIR = &quot;/tmp/cats-v-dogs/training/dogs/&quot;TESTING_DOGS_DIR = &quot;/tmp/cats-v-dogs/testing/dogs/&quot;split_size = .9split_data(CAT_SOURCE_DIR, TRAINING_CATS_DIR, TESTING_CATS_DIR, split_size)split_data(DOG_SOURCE_DIR, TRAINING_DOGS_DIR, TESTING_DOGS_DIR, split_size)# 查看训练集和测试集中的样本量print(len(os.listdir(&apos;/tmp/cats-v-dogs/training/cats/&apos;)))print(len(os.listdir(&apos;/tmp/cats-v-dogs/training/dogs/&apos;)))print(len(os.listdir(&apos;/tmp/cats-v-dogs/testing/cats/&apos;)))print(len(os.listdir(&apos;/tmp/cats-v-dogs/testing/dogs/&apos;)))# 搭建卷积神经网络模型# DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS# USE AT LEAST 3 CONVOLUTION LAYERSmodel = tf.keras.models.Sequential([# YOUR CODE HERE tf.keras.layers.Conv2D(16, (3,3), activation=&apos;relu&apos;, input_shape=(150, 150, 3)), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(32, (3,3), activation=&apos;relu&apos;), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(64, (3,3), activation=&apos;relu&apos;), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(512, activation=&apos;relu&apos;), tf.keras.layers.Dense(1, activation=&apos;sigmoid&apos;)])model.compile(optimizer=RMSprop(lr=0.001), loss=&apos;binary_crossentropy&apos;, metrics=[&apos;acc&apos;])# 采用ImageDataGenerator对训练集和测试集贴标签TRAINING_DIR = &quot;/tmp/cats-v-dogs/training/&quot; #YOUR CODE HEREtrain_datagen = ImageDataGenerator( rescale=1.0/255.) #YOUR CODE HERE# NOTE: YOU MUST USE A BATCH SIZE OF 10 (batch_size=10) FOR THE # TRAIN GENERATOR.train_generator = train_datagen.flow_from_directory(TRAINING_DIR, batch_size=10, class_mode=&apos;binary&apos;, target_size=(150,150))#YOUR CODE HEREVALIDATION_DIR = &quot;/tmp/cats-v-dogs/testing/&quot; #YOUR CODE HEREvalidation_datagen = ImageDataGenerator( rescale=1.0/255.) #YOUR CODE HERE# NOTE: YOU MUST USE A BACTH SIZE OF 10 (batch_size=10) FOR THE # VALIDATION GENERATOR.validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR, batch_size=10, class_mode=&apos;binary&apos;, target_size=(150,150))#YOUR CODE HERE# Expected Output:# Found 2700 images belonging to 2 classes.# Found 300 images belonging to 2 classes.# 训练模型history = model.fit_generator(train_generator, epochs=2, verbose=1, validation_data=validation_generator)# 画出损失和精确度图# PLOT LOSS AND ACCURACY%matplotlib inlineimport matplotlib.image as mpimgimport matplotlib.pyplot as plt#-----------------------------------------------------------# Retrieve a list of list results on training and test data# sets for each training epoch#-----------------------------------------------------------acc=history.history[&apos;acc&apos;]val_acc=history.history[&apos;val_acc&apos;]loss=history.history[&apos;loss&apos;]val_loss=history.history[&apos;val_loss&apos;]epochs=range(len(acc)) # Get number of epochs#------------------------------------------------# Plot training and validation accuracy per epoch#------------------------------------------------plt.plot(epochs, acc, &apos;r&apos;, &quot;Training Accuracy&quot;)plt.plot(epochs, val_acc, &apos;b&apos;, &quot;Validation Accuracy&quot;)plt.title(&apos;Training and validation accuracy&apos;)plt.figure()#------------------------------------------------# Plot training and validation loss per epoch#------------------------------------------------plt.plot(epochs, loss, &apos;r&apos;, &quot;Training Loss&quot;)plt.plot(epochs, val_loss, &apos;b&apos;, &quot;Validation Loss&quot;)plt.title(&apos;Training and validation loss&apos;) 。。。迭代次数epoch只训练了两次，有点少，所以画的图也不太好评价训练效果怎样，在model.fit()中可将epoch调大一些，能较好得查看模型的训练效果。 Reference Kaggle数据集]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>学习笔记</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[投资者的处置效应]]></title>
    <url>%2F2020%2F04%2F25%2F71-%E6%8A%95%E8%B5%84%E8%80%85%E7%9A%84%E5%A4%84%E7%BD%AE%E6%95%88%E5%BA%94%2F</url>
    <content type="text"><![CDATA[很久没更新博客了，由于临近毕业，事情比较多。虽然疫情给足了我时间独自在家好好做研究，但效率还是不高。不管怎样，该干的事还会干，该写的博客不会停。最近读了一篇文章，行为金融领域中十分经典的论文，是Odean于1998年发表在 The Journal of Finance 的《Are Investors Reluctant to Realize Their Losses?》。 Abstract I test the disposition effect, the tendency of investors to hold losing investments too loong and sell winning investments too soon, by analyzing trading records for 10,000 accounts at a large discount brokerage house. These investors demonstrate a strong preference for realizing winners rather than losers. Their behavior does not appear to be motivated by a disire to rebalance portfolios, or to avoid the higher trading costs of low priced stocks. Nor is it justified by subsequent portfolio performance. For taxable investments, it is suboptimal and leads to lower after-tax returns. Tax-motivated selling is most evident in December. 摘要主要介绍了作者对投资者处置效应（Disposition effect）的检验。处置效应指的是投资者保持亏损投资（Losing investments）持有和盈利投资（Wining Investments）出售的倾向。通过对一个大型经纪商中1万个账户的交易记录分析，发现投资者表现出对实现盈利的强烈便好。而这种行为偏好并非由对投资组合再平衡的需求所驱动的，亦非避免低价股票的高交易成本的原因。同样也不能用随之的投资组合绩效来解释。此外，应税投资是次优选择，因为它导致了更低的税后回报，而这种税务驱动的抛售在12月份中最为明显。 The Dispostion Effect作者首先从四个方面来对处置效应进行了综述，我们也对此进行回顾，了解处置效应的来龙去脉。 Prospect Theory自Kahneman和Tversky于1979年提出前景理论以来，其在投资领域的扩展启示即处置效应。前景理论指出，人们面临决策时其行为会满足S型效用函数（如下图所示）。在该函数中，当实现获益时，效用函数呈凹函数形式；当发生亏损时，则呈现凸函数形式。此外，亏损时的函数斜率会远大于获益时的斜率，表明人们普遍是风险厌恶的。 举个例子，假设一个投资者购买了一只他认为有足够高的预期回报率来抵消其风险的股票。如果投资者将购买价格作为参考点，那么会有两种情况： 当股票升值时，其价格将处于投资者效用函数中的风险厌恶部分。当升得越高时，其效用函数就会越凹，且越加风险厌恶。那么此时，投资者只要降低他对股票回报的期望（即投资者认为股票不会涨得更高了，或者股票回报已经抵消不了风险了），他就会倾向于将这只股票卖出。 若股票下跌时，其价格则处于效用函数中的风险偏好部分。此时投资者将继续持有该股，即使其预期回报率低于他最初购买该股票所付出的必要成本。因为投资者认为预期收益得降得更低会更加刺激亏损股票的销量，使其大于盈利股票的销量（俗称“抄底”），所以他会继续保留亏损股票的持有。 而如果投资者拥有两只股票，一只上涨，一只下跌。当这个投资者面临资产流动需求的话，且他没有关于任何一只股票的内幕消息，那么他会倾向于卖出上涨的股票而非下跌的股票。显然，正在这种风险厌恶，使得投资者更加愿意去实现自己盈利而非亏损。 在本文研究中，投资者的参考点将设为购买价格。然而购买价格并不是唯一的参考点，价格变化会导致人们对参考点选择的变化。比如说，一个房主花了一百万买了一套房子，当房地产过热时，该房子上涨到两百万。那么该房主一百万卖出这套房子时，是不会感觉到收支平衡的。因此说购买价格是一个主要的参考点，但绝不是单一的参考点。 An Alaternative Behavioral Theory投资者选择保留亏损股票而售出盈利股票，可能并不是因为投资者不愿意实现亏损，而是因为他们认为现在的亏损股票迟早会比盈利股票表现更好。如果未来亏损股票的预期收益的确高于盈利股票，那么投资者的信念是理性的。但是若未来亏损股票的预期收益仍低于盈利股票，且投资者置亏损于不顾继续抱着相信其会涨的念头，那么这种信念则是非理性的。这种信念即是均值回归信念（Belief in mean reversion）。 很多时候投资者选择保留亏损股票，到底是因为他认为亏损股票总有一天会涨上来的？还是因为不愿意去接受卖出亏损股票而导致的亏损？这个问题（均值回归信念 v.s. 前景理论）在很多研究中都难以区分，甚至连投资者自己内心也没有很明确的定义。 Taxes对于应税投资，投资者不愿实现亏损是和最优税损抛售（tax-loss selling）相冲突的。在一定程度上说，人们继续持有盈利投资的话，那么就可以相应地避免卖出时应交的税款。他们应该通过出售亏损投资来避免税收损失，尽管不一定以固定的税率。众多研究者也发现，在年底的时候，税损买盘会更加明显。 尽管投资者不愿意实现亏损，但在税务上能获益还是非常愿意的。而年底则是税损抛售的最后时期。因此在每年中，投资者都会推迟卖出亏损股票，直到12月份当deadline将至时他们才会抛售亏损股票。 Previous Studies除了先前提到的前景理论和均值回归信念，先前研究对处置效应还存在其他的解释： 当股市价格普遍上涨时，缺少市场投资组合的投资者会卖出一些升值的股票来维持他们投资组合的多样性（即投资组合的再平衡）。 当投资者对购买的股票掌握一定内幕消息时，若股票上涨，那么他们会认为股票价格正反映着他所掌握的信息，因此他们会马上卖掉。若股票下跌，那么他们会认为他所掌握的信息还未在股价中体现，因此会保持继续持有。 低价股票的交易成本会更高，且亏损股票相较于盈利股票更可能被价格低估，因此投资者会继续持有亏损股票以避免高交易成本。 Empirical StudyMethodology数据方面就不详细讲了，感兴趣可以看看原文。原文还是采用了很常规的实证分析方法。在这里讲讲作者是如何进行检验的。在每天投资组合的两只或多只股票的销售中，作者比较了每只股票卖出价格和平均买入价格来确定该只股票是卖得赚了（Realized gain）还是亏了（Realized loss）。如果股票没有被卖出，那么其盈利或是亏损都是账面的，而非实现的，即账面盈利（Paper gain）和账面损失（Paper loss）。那么账面是盈利还是亏损取决于该股票当天最高价与最低价和平均购买价格的比较。如果最高价和最低价都高于平均购买价格，那么记为账面盈利。如果两个价格均低于平均购买价格，则记为账面亏损。若平均购买价格处于最低价和最高价之间，则不算盈利也不算亏损。 \frac{Realized\ Gains}{Realized\ Gains+Paper\ Gains}=Proportion\ of\ Gains\ Realized\ (PGR) \\ \frac{Realized\ Losses}{Realized\ Losses+Paper\ Losses}=Proportion\ of\ Losses\ Realized\ (PLR) \\据此作者便提出两个假设进行联合检验，以证实处置效应。 假设一：Proportion of Gains Realized &gt; Proportion of Losses Realized (for the entire year) 假设二：Proportion of Losses Realized - Proportion of Gains Realized in December &gt; Proportion of Losses Realized - Proportion of Gains Realized in January~November 假设一的零假设为PGR $\leq$ PLR，而假设二的零假设即为PLR-PGR in December $\leq$ PLR-PGR in January ~ November. Results下图展示了全年，1至11月，12月份的PGR和PLR，可见全年中投资者的确售出盈利股票的比例大于卖出亏损股票，且假设一和假设二的零假设均显著拒绝。 然而，这些检验都是将每天中每笔股票的销售视为独立观测，但实际上每观测值却是不同投资者之间售出的总和，因此并不满足独立性假设。例如，假设一个投资者不会重复卖出同一只股票，那么该投资者今天卖出某股票和另一天卖出某股票并非为独立的。又或者，两个投资者可能收到同样的内部消息而卖出相同的股票，这也是非独立的。 因此，作者继续做了另一个检验。首先作者假设独立性存在于每个账户中而非每笔交易，即假设每个账户的PGR和PLR是独立的，那么检验结果得到平均账户PGR为0.57，平均账户PLR为0.36，平均PGR-PLR为0.21，同样是显著拒绝零假设的。该检验就是为了控制相同内幕信息而导致的不独立。具体做法是一只股票的售出只有当其在销售当天一周前和一周后没有售出记录才会被统计。这样的话就能保持每个账户的权重一致。但这种方法也会导致我们忽略一个事实，即拥有更多交易记录的账户可更加精确地估计实际的PGR和PLR。也就是中，本检验假设了观测账户的PGR和PLR都是同方差的，即使实际上它们是异方差。 上图展示了每个月的PGR与PLR之比，从1月份至12月，该比值从2.1将至0.85。这个下降和税损卖盘是一致的，表明部分投资者在全年中都存在税务动机的抛售。 为检验以上结果的鲁棒性，作者还将数据集分别分为两时段和两组交易者。下图展示了不同阶段，以及不同类型交易者的结果。 在数据集中，最活跃的10%交易者占了57%的股票交易量。在不同阶段和不同类别交易者中，全年度的PGR都显著大于PLR。而相较于全年度，12月的PLR则高于PGR，说明投资者在12月份会进行税损抛售。 下表展示了实现和未实现的亏损股票和赢利股票的投资回报，发现12月份的亏损是远远高于全面的，这也侧面证明了12月份中投资者的确参与了税损抛售。 之前文献提到，处置效应的存在可能出于投资者对投资组合的再平衡需求。作者认为如果投资者需要进行投资组合的再平衡，那么他们只会卖出部分股票，而不会将所有的持有股票清空。因此，为了反驳再平衡这一观点，作者仅计算了清空股票的账户中的PGR和PLR。结果如下表所示，和先前结果相比并无发生太大变化。 如果投资者是为了再平衡投资组合的话，那么他们很可能会继续买入股票。为了解决投资者为再平衡而继续进行买入交易的问题，作者在此计算了在售出当天后三周内无新交易的账户的PGR和PLR，如下表所示，结果还是保持不变。（不得不说作者非常严谨） 处置效应的另外一个原因，就是投资者掌握着股票的内幕消息。下表展示了售出的赢利股票和未售出的亏损股票的超额收益。检验从三个投资跨度分别进行，84个交易日（大约是样本中所有股票持有天数的中位数），254个交易日（一年），504个交易日（两年）。对于被卖了的赢利股票，其来年的超额收益比没被卖出的亏损股票的超额收益高出3.4%。显然，投资者认为亏损股票未来会比赢利股票绩效要好，这种预期基本是错误的。 有文献同样提到投资者之所以不愿意卖出亏损股票是因为低价股票的交易成本较高。下表展示了1月至11月不同价格范围和不同回报范围中的PGR和PLR，在一共12个分区中，有11个分区是PGR高于PLR的，显著性只有最后一个不显著，其余分区均显著。由此可见，不管是哪个价格区间中，回报大还是小，投资者都是倾向于卖出赢利股票，显然交易成本并不是造成处置效应的原因。 作者还从另一个角度对两个假设进行了验证，在此他们主要关注于投资者对已拥有股票的额外股份的购买率。那么复购赢利股票比例（PGPA）与复购亏损股票比例（PLPA）的计算方法与PGR和PLR相似。其中，在购买日中，投资组合内没有进行复购的股票则记为潜在复购（Potentially Purchased Again）。 如果投资者为了避免低价股票的高交易成本，那么PLPA理应小于PGPA，因为他们不会复购低价股票。然而，根据前景理论（对亏损股票的风险偏好）或均值回归信念（相信股票价格会回涨），那么PLPA理应高于PGPA。在样本中，计算结果为PLPA=0.135，而PGPA=0.094，假设一和假设二均能得到支持。交易成本假设不支持。 Discussion本文检验了个人投资者行为，并发现了投资者中存在的处置效应，即除了12月份，他们实现赢利投资的比例远高于实现亏损投资。 处置效应有助于影响供给来维持市场稳定性。如果众多投资者以一定价格买入股票，那么这个这个价格可成为其参考点。每当股价跌到参考点以下，那么投资者将会继续持有这些亏损股票，从而减少了亏损股票的大量抛售，延缓了价格的进一步下跌。而另一方面，如果股价上涨到参考点以上，投资者会更加愿意卖出，从而增加了赢利股票的供给，降低了价格的增高。 Conclusion本文发现了个人投资者的处置效应，12月份税务驱动的抛售流行除外。投资者行为并非由投资组合再平衡需求驱动，也不是由低价股票的高交易成本所造成的，更不是受来年的投资组合绩效的影响。 Reference Odean T . Are Investors Reluctant to Realize Their Losses?[J]. Journal of Finance, 1998, 53(5):1775-1798.]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>处置效应</tag>
        <tag>金融</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introduction to TensorFlow - Week 4]]></title>
    <url>%2F2019%2F12%2F27%2F70-Introduction-to-TensorFlow-Week-4%2F</url>
    <content type="text"><![CDATA[TensorFlow第一门专项课程的最后一节课：Using Real-world Images，讲解图片生成器（image generator）。 Understanding Image Generator我们之前所用的数据集 (如Mnist等)都是非常标准化的图片，28*28。若遇到更大的图，且特征处于图的不同位置不同角度，或图中存在多种物体，应该如何处理呢？此外，之前的数据集都可以很方便得划分为训练集和测试集，且标签已标好。而在很多场景中，不会有这么方便，你必须自己对数据进行处理。这节课就主要讲解一些数据预处理的API，尤其是可用于TensorFlow的图片生成器 (image generator)。 图片生成器的作用之一就是在你指定的路径的二级路径中为你自动生成标签。举个例子，在下图的路径结构中，存在了一个images的一级路径，在此一级文件路径里面，包含了training和validation的二级路径，当你在二级路径中放入分别包含了不同类别图片的三级文件夹路径，那么图片生成器就会自动为三级路径各个类别文件夹里的图片打标签。 例如，我们对training文件夹路径设置图片生成器，在training路径下包含了三级路径Horses和Humans，分别代表两种类别的图片，那么三级路径下的所有图片即会被图片生成器很方便地加载并分别打上Horses和Humans的标签。 1234567891011# 导入图片生成器from tensorflow.keras.preprocessing.imageimport ImageDataGenerator# 用图片生成器加载训练集数据并打标签train_datagen = ImageDataGenerator(rescale=1./255)train_generator = train_datagen.flow_from_directory( train_dir, target_size=(300, 300), batch_size=128, class_mode=&apos;binary&apos;) You should always point it at the directory that contains sub-directories that contain your images. The names of the sub-directories will be the labels for your images that are contrained within them. 图片可能形状各异，因此图片生成器的第二个参数即设置图片输入的size，以保证一致。第三个参数可批量加载数据。第四个参数是binary，表示图片是二分类。多分类的参数值在后续课程会讲解到。验证集的数据处理方式与训练集相同。 123456test_datagen = ImageDataGenerator(rescale=1./255)validation_generator = test_datagen.flow_from_directory( validation_dir, target_size=(300, 300), batch_size=32, class_mode=&apos;binary&apos;) Defining a ConvNet to use complex images1234567891011model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(16, (3,3), activation=&apos;relu&apos;, input_shape=(300, 300, 3)), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(32, (3,3), activation=&apos;relu&apos;), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(64, (3,3), activation=&apos;relu&apos;), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(512, activation=&apos;relu&apos;), tf.keras.layers.Dense(1, activation=&apos;sigmoid&apos;)]) Training the ConvNet with fit_generator12345# 模型编译from tensorflow.keras.optimizers import RMSpropmodel.compile(loss=&apos;binary_crossentropy&apos;, optimizer=RMSprop(lr=0.001), metrics=[&apos;acc&apos;]) 12345678# 采用图片生成器进行model.fit_generatorhistory = model.fit_generator( train_generator, steps_per_epoch=8, epochs=15, validation_data=validation_generator, validation_steps=8, verbose=2) 在model.fit_generator函数中，第一个参数training generator即为设置了图片生成器的训练集。注意第二个参数steps_per_epoch，训练集共有1024张图片，而在图片生成器中设定了batch_size参数为128，因此需要将steps_per_epoch设置为8才能将所有图片加载完。第三个参数epochs决定训练次数，第四个参数定为设置了图片生成器的验证集，由于验证集包含256张图片，而batch_size为32，因此第五个参数设置为8。最后一个参数verbose表示训练时展示信息的量，verbose=2，展示的信息较少。 123456789101112131415161718192021# 预测图片import numpy as npfrom google.colab import filesfrom keras.preprocessing import imageuploaded = files.upload()for fn in uploaded.keys(): # predicting images path = &apos;/content/&apos; + fn img = image.load_img(path, target_size=(300, 300)) x = image.img_to_array(img) x = np.expand_dims(x, axis=0) images = np.vstack([x]) classes = model.predict(images, batch_size=10) print(classes[0]) if classes[0]&gt;0.5: print(fn + &quot; is a human&quot;) else: print(fn + &quot; is a horse&quot;) img_to_array()函数可将图片转化为向量，且转换后元素为浮点型。np.expand_dimsl()函数可添加维度。 Exercise 4 (Handling complex images)1234567891011121314# 下载数据集并解压import tensorflow as tfimport osimport zipfilefrom os import path, getcwd, chdir# DO NOT CHANGE THE LINE BELOW. If you are developing in a local# environment, then grab happy-or-sad.zip from the Coursera Jupyter Notebook# and place it inside a local folder and edit the path to that locationpath = f&quot;&#123;getcwd()&#125;/../tmp2/happy-or-sad.zip&quot;zip_ref = zipfile.ZipFile(path, &apos;r&apos;)zip_ref.extractall(&quot;/tmp/h-or-s&quot;)zip_ref.close() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556def train_happy_sad_model(): # Please write your code only where you are indicated. # please do not remove # model fitting inline comments. DESIRED_ACCURACY = 0.999 class myCallback(tf.keras.callbacks.Callback): def on_epoch_end(self, epoch, logs=&#123;&#125;): if(logs.get(&apos;acc&apos;)&gt;DESIRED_ACCURACY): print(&quot;\nReached 99% accuracy so cancelling training!&quot;) self.model.stop_training = True callbacks = myCallback() # This Code Block should Define and Compile the Model. Please assume the images are 150 X 150 in your implementation. model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(16, (3,3), activation=&apos;relu&apos;, input_shape=(150, 150, 3)), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(32, (3,3), activation=&apos;relu&apos;), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Conv2D(64, (3,3), activation=&apos;relu&apos;), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(512, activation=&apos;relu&apos;), tf.keras.layers.Dense(1, activation=&apos;sigmoid&apos;) ]) from tensorflow.keras.optimizers import RMSprop model.compile(loss=&apos;binary_crossentropy&apos;, optimizer=RMSprop(lr=0.001), metrics=[&apos;acc&apos;]) # This code block should create an instance of an ImageDataGenerator called train_datagen # And a train_generator by calling train_datagen.flow_from_directory from tensorflow.keras.preprocessing.image import ImageDataGenerator train_datagen = ImageDataGenerator(rescale=1./255) # Please use a target_size of 150 X 150. train_generator = train_datagen.flow_from_directory( &quot;/tmp/h-or-s&quot;, target_size=(150, 150), batch_size=10, class_mode=&apos;binary&apos;) # Expected output: &apos;Found 80 images belonging to 2 classes&apos; # This code block should call model.fit_generator and train for # a number of epochs. # model fitting history = model.fit_generator( train_generator, steps_per_epoch=8, epochs=15, callbacks=[callbacks], verbose=2) # model fitting return history.history[&apos;acc&apos;][-1] 12# 训练train_happy_sad_model() Certificate哈哈，完成课程后，立马就收到颁发课程证书的邮件啦！ Reference 课程资料Github]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>学习笔记</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introduction to TensorFlow - Week 3]]></title>
    <url>%2F2019%2F12%2F11%2F69-Introduction-to-TensorFlow-Week-3%2F</url>
    <content type="text"><![CDATA[此周课程主要讲解在深度学习中卷积层 (convolution ) 和池化层 (max-pooling) 的应用。 What are convolutions and pooling?卷积 (convolution)： 卷积的效果由filter决定： 池化 (max-pooling): Implementing convolutional and pooling layers1234567891011model = tf.keras.model.Sequential([ tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)), tf.keras.layers.MaxPooling2D(2, 2), tf.keras.layers.Conv2D(64, (3,3), activation='relu'), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(128, activation='relu'), tf.keras.layers.Dense(10, activation='softmax')])# summary函数可查看每一层output的具体维度model.summary() 若对convolution层和pooling层的输出维度有疑惑，可回到 Deep Learning 课程. Improving the Fashion classifier with convolution123456789101112131415161718192021import tensorflow as tfprint(tf.__version__)mnist = tf.keras.datasets.fashion_mnist(training_images, training_labels), (test_images, test_labels) = mnist.load_data()training_images=training_images.reshape(60000, 28, 28, 1)training_images=training_images / 255.0test_images = test_images.reshape(10000, 28, 28, 1)test_images=test_images/255.0model = tf.keras.models.Sequential([ tf.keras.layers.Conv2D(64, (3,3), activation=&apos;relu&apos;, input_shape=(28, 28, 1)), tf.keras.layers.MaxPooling2D(2, 2), tf.keras.layers.Conv2D(64, (3,3), activation=&apos;relu&apos;), tf.keras.layers.MaxPooling2D(2,2), tf.keras.layers.Flatten(), tf.keras.layers.Dense(128, activation=&apos;relu&apos;), tf.keras.layers.Dense(10, activation=&apos;softmax&apos;)])model.compile(optimizer=&apos;adam&apos;, loss=&apos;sparse_categorical_crossentropy&apos;, metrics=[&apos;accuracy&apos;])model.summary()model.fit(training_images, training_labels, epochs=5)test_loss = model.evaluate(test_images, test_labels) 这里同样可以加入callback机制，当达到一定准确率后，可终止训练。在训练中加入卷积层和池化层，可大大提高训练精确度，但训练时间也有所增加。 Reference 课程资料Github]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>学习笔记</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introduction to TensorFlow - Week 2]]></title>
    <url>%2F2019%2F12%2F05%2F68-Introduction-to-TensorFlow-Week-2%2F</url>
    <content type="text"><![CDATA[这周课程仍比较简单，没什么要记的，放上几段代码吧。重点关注 CallBack！ Writing code to load training data12fashion_minist = keras.datasets.fashion_minist(train_images, train_labels), (test_image, test_labels) = fasion_minist.load_data() The structure of Fashaion MNIST data Fashion MNIST Coding a Computer Vision Neural Network12345model = keras.Sequential([ keras.layers.Flatten(input_shape=(28, 28)), keras.layers.Dense(128, activation=tf.nn.relu), keras.layers.Dense(10, activation=tf.nn.softmax)]) Walk through a Notebook for computer vision123456789101112131415161718192021222324252627282930313233343536import tensorflow as tf# print(tf.__version__)# 导入数据mnist = tf.keras.datasets.fashion_mnist(training_images, training_labels), (test_images, test_labels) = mnist.load_data()# 查看图片import matplotlib.pyplot as pltplt.imshow(training_images[0])print(training_labels[0])print(training_images[0])# 标准化training_images = training_images / 255.0test_images = test_images / 255.0# 搭建模型model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), tf.keras.layers.Dense(128, activation=tf.nn.relu), tf.keras.layers.Dense(10, activation=tf.nn.softmax)]) # 模型训练# TF 1.13.1model.compile(optimizer = tf.train.AdamOptimizer(), loss = &apos;sparse_categorical_crossentropy&apos;, metrics=[&apos;accuracy&apos;])# TF 2.0.0model.compile(optimizer = tf.Optimizer.Adam(), loss = &apos;sparse_categorical_crossentropy&apos;, metrics=[&apos;accuracy&apos;])model.fit(training_images, training_labels, epochs=5)# 评估及预测model.evaluate(test_images, test_labels)classifications = model.predict(test_images) 调试模型可尝试的几点： 去标准化； 修改网络层节点； 增加网络层（对简单的数据集用处不大，但对复杂的数据集能起到较好的提升作用，如彩色图片） 增加epochs训练次数 …… Using Callbacks to control training12345678910111213141516171819202122232425262728293031323334import tensorflow as tfprint(tf.__version__)class myCallback(tf.keras.callbacks.Callback): def on_epoch_end(self, epoch, logs=&#123;&#125;): if(logs.get(&apos;loss&apos;)&lt;0.4): print(&quot;\nLoss is low so cancelling training!&quot;) self.model.stop_training = True# 或者class myCallback(tf.keras.callbacks.Callback): def on_epoch_end(self, epoch, logs=&#123;&#125;): if(logs.get(&apos;acc&apos;)&gt;0.6): print(&quot;\nReached 60% accuracy so cancelling training!&quot;) self.model.stop_training = True# 注意：TF 1.13.1: logs.get(&apos;acc&apos;)TF 2.0.0: logs.get(&apos;accuracy&apos;)mnist = tf.keras.datasets.fashion_mnist(x_train, y_train),(x_test, y_test) = mnist.load_data()x_train, x_test = x_train / 255.0, x_test / 255.0callbacks = myCallback()model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(input_shape=(28, 28)), tf.keras.layers.Dense(512, activation=tf.nn.relu), tf.keras.layers.Dense(10, activation=tf.nn.softmax)])model.compile(optimizer=&apos;adam&apos;, loss=&apos;sparse_categorical_crossentropy&apos;, metrics=[&apos;accuracy&apos;])model.fit(x_train, y_train, epochs=10, callbacks=[callbacks]) 有个问题，当我们在模型训练时，训练到一定epoch，loss已经很低或者accuracy已经非常高了，没有必要再干等着训练下去了，那我们该怎么停止训练呢？这就是callback的作用了，callback能够使模型在达到一定条件后终止其训练，并输出达到条件的结果。 Reference 课程资料Github]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>学习笔记</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Introduction to TensorFlow - Week 1]]></title>
    <url>%2F2019%2F11%2F28%2F67-Introduction-to-TensorFlow-Week-1%2F</url>
    <content type="text"><![CDATA[最近在Cousera开始上一门新的专项课程《TensorFlow in practice》，主要介绍深度学习框架 TensorFlow的使用，由 deeplearning.ai 出品。 该专项课程的第一门课为《Introduction to TensorFlow for Artificial Intelligence, Machine Learning and Deep Learning》。课程所有代码资料可见这里。 A primer in machine learning The traditional paradigm of expressing rules in a coding language may not always work to solve a problem. As such, scenarios such as Computer Vision are very difficult to solve with rules-based programming. Instead, if we feed a computer with enough data that we describe (or label) as what we want it to recognize, given that computers are really good at processing data and finding patterns that match, then we could potentially ‘train’ a system to solve a problem. The “Hello World” of neural networks12345678910# main part of this networkmodel = keras.Sequential([keras.layers.Dense(unit=1, input_shape=[1])])model.compile(optimizer=&apos;sgd&apos;, loss=&apos;mean_squared_error&apos;)xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)model.fit(xs, ys, epochs=500)print(model.predict([10.0])) 简单的一个神经网络，用于拟合两个向量，网络层中仅有一个节点。随着训练迭代次数的增加，loss会越来越小。在模型预测中，当你输入10，预期会输出19，然而模型会输出一个十分接近19的数字，却不会精确输出19. 为什么呢？主要有两个原因。 尽管在该两个向量的六个元素中，呈现 $y=2x-1$ 的线性规律，然而向量太短，并不能保证在向量范围外仍是 $y=2x-1$ 的关系. 神经网络主要通过概率去 figure out the answers for everything，因此其预测结果仅能表现当 $x$ 为10时，$y$ 有很大可能为19，而不能百分之百精确预测 $y$ 为19. 12345678910111213141516import tensorflow as tfimport numpy as npfrom tensorflow import keras# 封装成函数def house_model(y_new): xs = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0], dtype=float) ys = np.array([1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0], dtype=float) model = keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])]) model.compile(optimizer=&apos;sgd&apos;, loss=&apos;mean_squared_error&apos;) model.fit(xs, ys, epochs=500) return model.predict(y_new)[0]# 给定参数prediction = house_model([7.0])print(prediction) 课程作业相对简单，在此不提。 Reference 课程资料Github]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>学习笔记</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python玩转百度地图API]]></title>
    <url>%2F2019%2F08%2F22%2F66-%E7%8E%A9%E8%BD%AC%E7%99%BE%E5%BA%A6%E5%9C%B0%E5%9B%BEAPI%2F</url>
    <content type="text"><![CDATA[最近做了一个项目，其中涉及到寻找一些地标的具体位置及相关信息，例如地标的准确坐标、地标周围的POI信息等，看起来好像很难的样子，但实际上非常简单，这里主要调用了百度地图开放平台实现我们的目的，给大家分享一下相关使用技巧。 首先介绍一下这个百度地图开放平台吧！ 首页：http://lbsyun.baidu.com API：http://lbsyun.baidu.com/index.php?title=webapi 百度地图开放平台提供了许多功能，诸如地点检索、正/逆地理编码、路线规划、实时路况查询等等，详见百度地图API。由于我们的项目数据量非常庞大，共计几十万条吧，都是一些地标的文本地址，我们需要的是根据这些地址，进一步挖掘出与这些地址相关的信息，因此首先涉及到地理编码，即将文本地址转化为地理坐标，再根据地理坐标进行地点检索，查询相应的POI信息。在这里就简单介绍一下这两项服务。 百度地图批量地理编码在使用百度地图的各种服务之前，需要申请一个AK码。首先我们注册一个百度地图账号，如果有百度账号也可以直接登录。在百度地图首页进入控制台，创建应用，应用名称随便填，应用类型选“浏览器端”，Referer白名单设为*，这样不管是任何网站都能够调用百度地图服务了。 AK码申请下来后，可以申请认证用户，认证用户的免费访问额度比较多，地理编码是30万次/天，地点检索是3万次/天。我果断申请了认证用户，哈哈，申请方法按流程和指引走就行了，在这里不再具体介绍。 好了，申请完AK之后，就马上开始我们的任务了。数据在一个Excel当中，只有1列，即文本地址，我们需要批量读取每一条地址，访问百度地图地理编码，将其转化为坐标，再批量写入Excel当中。不多说了，直接上代码吧。 1234567891011121314151617181920212223242526272829303132333435363738import xlrdimport jsonimport pandas as pdfrom urllib.request import urlopen, quote#获取坐标函数#其中status是获取状态，成功返回0，错误返回其他数字，表示错误原因，具体可见API文档def get_coordinates(address): url = &apos;http://api.map.baidu.com/geocoding/v3/&apos; output = &apos;json&apos; ak = &apos;替换为你的ak码&apos; address = quote(address) uri = url + &apos;?&apos; + &apos;address=&apos; + address + &apos;&amp;output=&apos; + output + &apos;&amp;ak=&apos; + ak req = urlopen(uri) res = req.read().decode() temp = json.loads(res) status = temp[&apos;status&apos;] if status == 0: lng = temp[&apos;result&apos;][&apos;location&apos;][&apos;lng&apos;] lat = temp[&apos;result&apos;][&apos;location&apos;][&apos;lat&apos;] coordinate = (status, lng, lat) else: coordinate = (status,&apos;Unknown&apos;, &apos;Unknown&apos;) return coordinate#用pandas的read_excel()函数直接读取excel会更方便点data = xlrd.open_workbook(&apos;address.xlsx&apos;)rtable = data.sheets()[0]values = rtable.col_values(0)row = 0coordinates = []for value in values: coordinate = get_coordinates(value) coordinates.append(coordinate)#用pandas直接写入excelcoordinates_dataframe = pd.DataFrame(coordinates, columns=[&apos;status&apos;, &apos;lng&apos;, &apos;lat&apos;])coordinates_dataframe.to_excel(&apos;address_scoordinates.xlsx&apos;) 百度地图批量获取POI信息第二个任务会稍稍繁重一点，我们需要根据坐标去进行地点检索，将地标周围的各类型的建筑物和店铺信息（即POI信息）都抓取下来，然后统计各个类别的POI数量，比如说附近 美食 有多少家？酒店 有多少间等等，批量统计完之后将其写入Excel当中。 百度的POI类型可见：http://lbsyun.baidu.com/index.php?title=lbscloud/poitags 好了，再次上代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687import mathimport xlrdimport jsonimport pandas as pdfrom urllib.request import urlopen, quote#获取详细POI信息def get_poi(lat, lng, radius): lat = str(lat) lng = str(lng) radius = str(radius) url = &apos;http://api.map.baidu.com/place/v2/search?&apos; query= quote(&apos;美食$酒店$购物$休闲娱乐$教育$医疗$交通设施$金融$公司企业$政府机构&apos;) page_num = &apos;0&apos; ak = &apos;替换为你的ak码&apos; uri = url + &apos;query=&apos; + query + &apos;&amp;location=&apos; + lat + &apos;,&apos; + lng + &apos;&amp;radius=&apos; + radius + &apos;&amp;output=json&amp;scope=2&amp;filter=sort_name:dostance|sort_rule:1&amp;page_size=20&amp;page_num=&apos; + page_num + &apos;&amp;ak=&apos; + ak req = urlopen(uri) res = req.read().decode() temp = json.loads(res) status = temp[&apos;status&apos;] message = temp[&apos;message&apos;] poi_dict = &#123;&#125; if status == 0: total = temp[&apos;total&apos;] pages = math.ceil(total/20) results = temp[&apos;results&apos;] for i in range(1,pages): pages_num = str(i) uri_i = url + &apos;query=&apos; + query + &apos;&amp;location=&apos; + lat + &apos;,&apos; + lng + &apos;&amp;radius=&apos; + radius + &apos;&amp;output=json&amp;scope=2&amp;filter=sort_name:dostance|sort_rule:1&amp;page_size=20&amp;page_num=&apos; + pages_num + &apos;&amp;ak=&apos; + ak req_i = urlopen(uri_i) res_i = req_i.read().decode() temp_i = json.loads(res_i) result_i = temp_i[&apos;results&apos;] results = results + result_i tag_dict = types_count(total, results) tag_dict[&apos;status&apos;] = status tag_dict[&apos;total&apos;] = total poi_dict = tag_dict else: poi_dict[&apos;status&apos;] = status poi_dict[&apos;message&apos;] = message return poi_dict#对各类别POI进行统计def types_count(total, results): tag_dict = &#123;&#125; for i in range(len(results)): if &apos;tag&apos; in results[i][&apos;detail_info&apos;]: tags = results[i][&apos;detail_info&apos;][&apos;tag&apos;] if tags not in tag_dict: tag_dict[tags] = 1 else: tag_dict[tags] += 1 return tag_dict# 读取excel坐标data = xlrd.open_workbook(&apos;coordinates.xlsx&apos;)rtable = data.sheets()[0]#nrows = rtable.nrowsvlats = rtable.col_values(0)vlngs = rtable.col_values(1)#由于每访问一条数据，返回的各类别POI顺序都不一致，且POI类型也不一定相同，需要构建一个字典，将所有类别覆盖。POI = []for t in range(len(vlats)): ppoi = get_poi(vlats[t],vlngs[t], 1000) POI.append(ppoi)POIs = &#123;&#125;for j in range(len(POI)): poi_dict = POI[j] POIs = dict(POIs, **poi_dict)#最终将每条数据的所有POI类别定序填入字典，转化为dataframe写入excelPOIs_final = []for k in range(len(POI)): for n in POIs.keys(): POIs[n] = 0 poi_dict = POI[k] for key in poi_dict.keys(): if key in POIs.keys(): POIs[key] = poi_dict[key] poi_final = list(POIs.values()) POIs_final.append(poi_final)POI_dataframe = pd.DataFrame(POIs_final, columns=list(POIs.keys()))POI_dataframe.to_excel(&apos;pois.xlsx&apos;) 可能会有些细节大家看不懂，那是因为百度地点检索的限制，因为百度地图每输入一个坐标，其周围1公里的POI数量可能高达几百条（出于数据保护的原因，百度地图最多返回400条），而每次其页面返回的数量最多20条，因此一个坐标可能需要十几次访问才能将其所有的POI给完全获取下来。还有其他很多一些细节需要考究，但都是出于对百度地图访问的限制所作的考虑，因此看不懂的同学要好好结合百度地图API来看，哈哈。 Excel拼接最后还有一个小问题，就是我每天的访问限额只有3万次/天，要是数据量比较大，那么在不花钱的情况下，只好连续多天进行访问了。然而每天访问后获取的多个excel文件，其每一列都是不同的，比如说今天得到的excel，第1列是 美食 数量，第2列是 酒店 数量。明天得到的excel，第1列是 图书馆 数量，第2列是 便利店 数量等等。由于POI类别很多，每个excel可能都有好几十列乃至上百列，靠人工将这些excel合并，那得折腾多久。。。想想我都觉得可怕。 嘻嘻，但是不用急，没有什么是python程序不能实现的，看代码吧： 123456789101112131415161718192021222324252627282930313233343536from os import walkimport pandas as pdimport numpy as np#遍历所有excel文件for root, dirs, files in walk(&apos;excel_file(即包含所有要处理excel的文件夹路径)&apos;, topdown=False): print(files)files.sort()num = len(files)alldata = []#读取后全部转化为字典for i in range(num): newexcel = pd.read_excel(&apos;excel_file/%s&apos; %files[i]) newdata = newexcel.to_dict(orient = &apos;list&apos;) alldata.append(newdata) all_dict = &#123;&#125;for j in range(num): data_dict = alldata[j] all_dict = dict(all_dict, **data_dict)#读入字典，按多个excel的字典键值一一对应for key in all_dict.keys(): all_dict[key] = [] for k in range(num): data_dict = alldata[k] if key not in data_dict.keys(): data_dict[key] = list(np.zeros(len(data_dict[&apos;status&apos;]))) all_dict[key] += data_dict[key]# 再将统一整合的字典导出到excelpois_df = pd.DataFrame(all_dict)pois_df1 = pois_df.sort_index(axis = 1, ascending = True)pois_df1.to_excel(&apos;pois_combine.xlsx&apos;) 以上只是项目的一小部分，但又让我学习到了很多东西，所以说实践还是非常重要的。很多东西你并不知道自己学会了没有，这时候往往需要实践来检验一下。哈哈，今天就到这里，没有什么新东西，只是将我近期的工作整理了一下，开学要好好回到苦读文献的状态了。 谢谢大家！]]></content>
      <categories>
        <category>Work</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>经验</tag>
        <tag>百度地图API</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SAS日期处理小技巧]]></title>
    <url>%2F2019%2F08%2F22%2F65-SAS%E6%97%A5%E6%9C%9F%E5%A4%84%E7%90%86%E5%B0%8F%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[最近好久没出现了，哈哈，跑到银行实习捣鼓了两个月。一般大银行或大企业都习惯以SAS作为大型数据分析的首选软件之一，毕竟SAS是相当成熟的商业软件。自大三以来，我已经好久没玩过了SAS了，有些小技巧忘得一干二净，在此赶紧做个记录贴，日后还有更多技巧也会不断更新。 SAS 文本变量转化日期变量假设SAS数据集 raw_data 中包含类似 “2010年01月01日” 的字符型变量 string_date ，那么如何将其转化为日期型变量？ 12345data string_2_date;set raw_data;new_date = input(compress(string_date, &apos;1234567890&apos;, &apos;k&apos;), yymmdd10.)format new_date yymmdd10.run; 其中的原理就是采用 compress() 函数将所有数字保留，剔除其余的中文字符，留下数字的年月日，再采用 input() 函数将数字转化为日期格式，就是这么简单。 SAS筛选日期如果要提取某年段或某日期段内的数据，那也十分简单： 12345data new;set string_2_date;where year(date)&gt;2000;/*where date between &apos;01Jan2010&apos;d and &apos;31Dec2010&apos;d */run; SAS转换日期格式如果上面得到的日期变量想要转化其他格式，例如只保留年和月： 123456data new1;set new;year_month = date;/*采用format语句转换为你想要的各种格式*/format year_month yymon7.;run;]]></content>
      <categories>
        <category>Work</category>
      </categories>
      <tags>
        <tag>经验</tag>
        <tag>SAS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浮生六记之坎坷记愁]]></title>
    <url>%2F2019%2F05%2F29%2F64-%E6%B5%AE%E7%94%9F%E5%85%AD%E8%AE%B0%E4%B9%8B%E5%9D%8E%E5%9D%B7%E8%AE%B0%E6%84%81%2F</url>
    <content type="text"><![CDATA[今读《浮生六记》卷三之坎坷记愁，念芸之香消玉殒，动情至已，感概万千！ 原文 余欲延医诊治，芸阻曰：“妾病始因弟亡母丧，悲痛过甚；继为情感，后由岔激。而平素又多过虑，满望努力做一好媳妇，而不能得，以至头眩怔忡，诸症毕备；所谓病入膏肓，良医束手，请勿为无益之费。忆妾唱随二十三年，蒙君错爱，百凡体恤，不以顽劣见弃。知已如君，得婿如此，妾已此生无憾！若布衣暖，菜饭饱，一室雍雍，优游泉石，如沧浪亭、萧爽楼之处境，真成烟火神仙矣。神仙几世才能修得，我辈何人，敢望神仙耶？强而求之，致干造物之忌，即有情魔之扰。总因君太多情，妾生薄命耳！”因又呜咽而言曰：“人生百年，终归一死。今中道相离，忽焉长别，不能终奉箕帚，目睹逢森娶妇，此心实觉耿耿。”言已，泪落如豆。余勉强慰之曰：“卿病八年，恹恹欲绝者屡矣，今何忽作断肠语耶？”芸曰：“连日梦我父母放舟来接，闭目即飘然上下，如行云雾中，殆魂离而躯壳存乎？”余曰：“此神不收舍，服以补剂，静心调养，自能安痊。”芸又唏嘘曰：“妾若稍有生机一线，断不敢惊君听闻。今冥路已近，苟再不言，言无日矣。君之不得亲心，流离颠沛，皆由妾故，妾死则亲心自可挽回，君亦可免牵挂。堂上春秋高矣，妾死君宜早归。如无力携妾骸骨归，不妨暂厝于此，待君将来可耳。愿君另续德容兼备者，以奉双亲，抚我遗子，妾亦瞑目矣。”言至此，痛肠欲裂，不觉惨然大恸。余曰：“卿果中道相舍，断无再续之理。况‘曾经沧海难为水，除却巫山不是云’耳。”芸乃执余手而更欲有言，仅断续叠言“来世”二字，忽发喘，口噤，两目瞪视，千呼万唤，已不能言。痛泪两行，涔涔流溢。既而喘渐微，泪渐干，一灵缥缈，竟尔长逝！时嘉庆癸亥三月三十日也。 译文我想请医生来诊治，芸阻拦道：“我的病最初是因为弟弟出走和母亲去世而悲伤过度，接着是因为感情，后来又由于过度生气激动。而且平时还过于多虑，满心期待努力做一个好媳妇，终未能实现，以至于头晕目眩、心悸惊慌等各种症状都有了，正所谓病入膏肓，良医束手，请不要再花没用的钱了。想我伴随夫君二十三年，承蒙夫君错爱，对我百般关照，没有因为我的顽劣而抛弃我。有这样知心知意的夫君相伴，我此生无憾了。如果我们能吃饱穿暖，家庭和睦，闲时能游赏山水，看一看像沧浪亭、萧爽楼那样的美景，那真的是神仙眷恋了。可是神仙要几世才能修得，我们凡人又怎敢奢望成仙呢？如果强求，就会触犯上天的禁忌，从而被情所困。总之是因为君太多情，而我此生命太薄啊！”然后又哭着说：“人活一世，终有一死。如今你我半路分离，忽然就此永别，我不能够侍奉你而终，不能亲眼看见逢森娶妻生子了，对此我始终耿耿于怀，难以放下。”说完，泪如雨下。我勉强安慰她说：“你已经病了八年了，好多次都恹恹欲绝，今天为什么忽然说这些让人肝肠寸断的话呢？”芸说：“近日来我总梦见我的父母开船来接我，闭上眼睛就飘飘然如走在云雾中，大概是灵魂已经出窍了吧！”我说：“这是你精神不济，服些补药，安心调养些日子就会痊愈了。”芸又哽咽着说：“我如果还有一线生机，也绝不敢对你说这些惊心动魄的话。如今黄泉已近，如果再不说，恐怕就没机会再说了。夫君你不得父母亲的欢心，过这颠沛流离的生活，都是因我而起，我死后你自会挽回父母之心，也免再去牵挂他们。公婆年事已高，我死后你应该早点回去。如果无法带着我的骸骨回去，不妨就暂时埋在这里，等将来再带回去。希望夫君再娶一位德容兼备的人，侍奉双亲，抚育我的孩子，我也可以瞑目了。”说到这里，我们痛肠欲裂，不禁悲痛地大哭起来。我说：“你如果真的中途舍我而去，我也再无续弦之理。更何况‘曾经沧海难为水，除去巫山不是云’。”芸于是拉着我的手还想再说些什么，可是却只能断断续续得重复着“来世”二字，突然紧闭嘴唇用力喘息，两眼空瞪着，我千呼万唤，可她却不能说话，只涔涔流出两行泪。然后喘息渐渐平息了，泪也渐渐流干了，一缕香魂缥缈而逝。时间是嘉庆癸亥年（1803年）三月三十日。 译文出处 沈复 等. 浮生六记 : 外三种[M]. 中国文史出版社, 2016.]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>文学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[情绪指标和投资者需求（上）]]></title>
    <url>%2F2019%2F04%2F10%2F63-%E6%83%85%E7%BB%AA%E6%8C%87%E6%A0%87%E5%92%8C%E6%8A%95%E8%B5%84%E8%80%85%E9%9C%80%E6%B1%82_%E4%B8%8A%2F</url>
    <content type="text"><![CDATA[关于投资者情绪的相关文献，过去多认为价格的偏离是由“公众心理”产生的情绪所驱动的，即个人投资者应为这种情绪导致的错误定价 (sentiment-induced mispricing) 所负责。这是传统的投资者情绪假设。然而，反映个人投资者需求的情绪指标仅是该传统假设的必要条件，而非充分条件。机构是否也会受到投资者情绪的影响，从而导致机构投资者投资决策的变化？本文旨在挖掘投资者情绪指标是否能够捕捉机构投资者的需求冲击。 Contrary to this widely held assumption, in this paper, we demostrate that sentiment metrics capture the demand shocks of institutional, rather than individual, investors. 今天的这篇文章是 Sentiment Metrics and Investor Demand (Devault et al., 2019)，来源于 “Jouranal of Finance”，主要讲的是机构需求冲击 (institutional demand shocks)、投资者情绪 (investor sentiment)和股票收益 (equity returns)之间的关系。 Data作者选取了6个投资者情绪代理变量：封闭式基金折价 (closed-end fund discounts)、NYSE股票交易总量 (NYSE share turnover)、上市公司数量 (the number of IPOs)、上市第一天的平均收益 (the average first-day IPO return)、股本发行在总债务中的份额和股本发行量 (the share of equity issues in total debt and equity issues)、股息溢价 (dividend premium)。根据这些代理变量，计算其改变（原文为change，经过后文推断，应该是时序上的季度差分）的第一主成分以衡量投资者情绪的改变。这个情绪指标是基于季度，即计算的是投资者情绪季度的改变。Baker &amp; Wurgler (2007) 提到，情绪指标有两种算法，一种是“raw sentiment”，即直接计算6个代理变量的第一主成分作为投资者情绪；另一种是“orthogonalized sentiment”，即根据6个代理变量与一系列宏观经济变量 (business cycle variables)的回归得到的残差，再取残差的第一主成分作为正交化投资者情绪。本文中作者在BW的基础上，计算6个代理变量的差分后，再以其第一主成分作为投资者情绪的改变。 作者选择了一些普通股票作为样本 (CRSP share code 10 or 11)，并采用月收益波动率（前12个月内至少有9个月收益的股票）来捕捉股票的投机特点。其次，采用季度 13(f) 报告来反映每只股票自1980至2010每季度的部分机构所有制水平 (fractional institutional ownership levels) 和机构需求冲击 。 机构所有制水平=\lbrace \frac{机构持有股票数量}{已发行股票数量}\rbrace \\ 机构需求冲击=change\ of\ \lbrace \frac{机构持有股票数量}{已发行股票数量}\rbrace作者假设机构需求冲击的负值可代理为个人投资者的需求冲击。作者还采用了两种13(f) 基金经理的分类方式（13(f)见下段引用）。样本中对3945只股票自1980年6月至2010年12月（共123个季度）每季度的价格取了均值。 “In the United States, institutional investors are required to report their equity positions quarterly in 13-F filings to the Securities and Exchange Commission (SEC). These quarterly data show that changes in institutional equity holdings are positively serially correlatred and positively correlated with future stock returns, and institutional purchases appear to be positively correlated with lagged stock returns.” ——Campbell et al., 2009 Dose the BW Metric Capture Institutions’ or Individuals’ Demand Shocks?作者首先检验了情绪的季度改变与13(f)季度需求冲击之间的关系，以确认谁（机构vs. 个人）的需求冲击能够被情绪指标所捕捉。 由上表可见，在第一列中，当情绪上涨时，机构会从个人投资者（散户）中买入高波动的股票（高波动股票的机构需求冲击与情绪改变的相关性高达31.5%），并向散户卖出低波动股票（第1列最上面1行的相关性为-28.7%）。由此说明，情绪指标捕捉的是机构的总需求冲击，而非散户的。 其次，作者构建了两步法对所有样本进行了测试。在第一步测试中，以机构需求冲击和股票收益波动的截面相关性作为每一季度机构从散户中购买（或向散户卖出）风险股票的程度。正值表示机构可从散户中购买高波动股票，而负值表示散户从机构中购买高波动股票。 上表中的Panel A展示出截面相关性随着时间而发生巨大变化，低至-16.86%（即机构极力卖出高波动股票的季度），高达17.65%（即机构强烈买入高波动股票的季度）。在第二步中作者计算了情绪季度改变与机构从散户中购买风险股票的时序变化程度（即上一步测试估计的123个截面相关性的序列）的相关性，用于检验当情绪上涨时，机构投资者是否也会提高对风险股票的偏好。和之前的测试结果保持一致，情绪的改变能够捕捉机构投资者的需求冲击，机构吸引高波动股票的时序变化程度与纯情绪改变的相关性为37.34%，与正交情绪改变的相关性为37.27%（均在1%水平显著）。 然而，上述检验的不足之处在于股票的风险在一个季度内是不断变化的，例如当情绪上涨时，机构会倾向买入高波动股票，而当到达季度后期时，股票波动发生均值回归(mean reversion)，那么机构新持有股票的波动性会保持不变，甚至会降低。于是，作者根据三个不同季度的日收益去估计非重复的风险，即由季度 $t-1(\sigma_{i,t-1})$，季度 $t(\sigma_{i,t})$，季度 $t+1(\sigma_{i,t+1})$ 的日收益的平方计算得到的月度收益标准差的自然对数。通过这种方法能够更好得反映真实的波动和风险。 作者进行了4项测试去检验公司股票的风险变化是否还能重新解释情绪指标捕捉散户的需求冲击。第一，当情绪上涨时机构买入的股票比卖出的股票风险更低，那么情绪改变与机构需求冲击的相关性应为负数，在采用季度末期的风险水平时。下表中的Panel A展示了情绪改变和机构持有改变量和波动水平之间相关性的相关性，其中波动基于季度 $t-1$,$t$,$t+1$ 的日收益来衡量。该结果与Table II 中的Panel B相似。作者推断风险可能会在情绪对机构需求的影响中起作用，事实上，不管是 $t-1$,$t$,还是 $t+1$ 季度的风险，两者关系都基本保持一致。 第二个测试进一步得检验了当情绪上涨时机构买入的股票风险降低的可能性。Panel B同样反映风险改变并不能解释情绪指标捕捉散户的需求冲击。结果的两列均为正值，且第一列显著，说明当情绪上涨时，机构买入的股票会倾向于风险更大。 机构对风险股票的偏好增长主要有两个方面：(1) 机构将其投资组合转移到风险更大的股票中；(2) 增加机构已持有的相对高风险的股票。因此，在第三个测试中，作者检验了当情绪上涨时，机构持有的股票是否变得风险更小。上表中的Panel C中第一行和第二行分别衡量季度 $t$ 的首期和末期的风险。结果第一列表明情绪改变和机构持有证券风险的上涨和下跌并无关联，而第二列表明当情绪上涨时，机构持有的股票会变得风险更大。 最后，作者考虑了另一种方法用于衡量高波动股票对机构投资者的吸引力的改变。具体地，即在季度 $t$ 的结束与开始的机构持有水平和风险水平相关性之差： \rho (Inst_{i,1},\sigma_{i,1})- \rho (Inst_{i,0},\sigma_{i,0})Panel D展示了这些相关性与情绪改变的相关性，尽管第一列表明了无依据显示情绪改变和相关性之差之间存在关系，但第二列的结果却支持了情绪捕捉机构需求冲击的假设。此外，该结果也与情绪指标捕捉个人需求冲击的假设不一致。 Alternative Measures of Sentiment and Institutional Investor Demand尽管BW情绪指标体系在现有研究中经常被使用，然而还存在其他代理变量能够更好地捕捉散户由情绪引发的需求冲击。作者考虑了另外的6个代理变量：BW情绪指标的个人部分 (the individual components of the BW sentiment metric)、基金流量 (mutual fund flows)、消费者信心 (consumer confidence)、散户情绪 (a survey-based measure of individual investor sentiment)、风险资本流量 (venture capital flows)以及经济条件的改变 (changes in economic conditions)。作者主要采用这些变量检验了两个问题，(1)这些指标是否能和BW指标体系一样捕捉同时及随后的收益模式。(2) 这些指标是否能捕捉机构或散户的需求冲击。 为了构建基于共同基金流量的情绪指标，作者根据7种共同基金的种类 (aggressive growth, growth, balanced, growth and income, sector, imcome equity and income mixed)，计算了共同基金流量改变中的前两个主成分，并将其视为一般需求 (“general demand”)和投机需求 (“speculative demand”)。数据从 Investment Company Institute (ICI)获得，自1984至2010。和BW指标一致，第一主成分与所有的基金种类呈正相关，而第二主成分仅与极速增长型基金 (aggressive fund)呈正相关。 关于消费者信息，作者采用两个指数进行衡量，the University of Michigan Survey of Consumer Expectations and the Conference Board Consumer Confidence Index. 关于风险资本流量，作者采用 PWC/National Venture Capital Association data 计算了：(i) the percentage change in the dollar value of “cash-for-equity investments by the professional venture capital community in private emerging companies in the U.S.” (ii) the change in the number of venture capital deals. 而对于经济条件，作者采用了两个指数的变化（差分）：the Chicago Fed’s National Activity Index and St. Louis Fed’s Financial Stress Index. 上表为其它代理情绪指标的检验结果。首先，由第1列来看大部分指标和BW情绪指标呈正相关。其次，现时收益（第2列）和随后收益（第3列）与BW指标的结果大部分保持一致。特别地，当情绪上涨时，风险股票表现得比稳定股票更好，因为第2列17个系数中有13个均为正值，且有6个显著异于0。相反，第2列中估计的4个负相关系数均不显著异于0。和BW指标一致，在高情绪水平时，风险股票比稳定股票表现得更差，因为第3列中17个系数有14个为负，且有6个显著异于0。前3列中并不显著的系数表明：(1) 这些指标并没有捕捉到投资者情绪；(2) 情绪交易者的需求冲击不会导致风险股票和稳定股票在收益上的差别；(3) 这些指标的噪声太大，就像BW指标中，每一个情绪代理变量都包含情绪的部分和特殊无效的部分。 最后1列检验的是这些情绪指标是否捕捉了机构或散户的需求冲击。正值表示的是当情绪上涨时机构倾向于增加对风险股票的需求，负值表示当情绪上涨时散户倾向于增加对风险股票的需求。这些结果表明情绪指标捕捉的是机构而不是散户的需求冲击。特别地，17个相关系数中有13个为正值，且在这13个中有9个显著异于0，而4个负相关系数均不显著异于0。 前面的结果均反映了情绪指标捕捉的是机构冲击需求，而且散户的。那么为什么情绪能够反映机构的需求呢？本博文只讲了文章的上半部分，下半部分可见下篇博文。 Reference DeVAULT L, Sias R, Starks L. Sentiment metrics and investor demand[J]. The Journal of Finance, 2019, 74(2): 985-1024. Baker M , Wurgler J . Investor Sentiment in the Stock Market[J]. Journal of Economic Perspectives, 2007, 21.]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>实证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中文Beamer小技巧——Latex]]></title>
    <url>%2F2018%2F12%2F28%2F62-%E4%B8%AD%E6%96%87Beamer%E5%B0%8F%E6%8A%80%E5%B7%A7%E2%80%94%E2%80%94Latex%2F</url>
    <content type="text"><![CDATA[转眼间2019年就要来临了，这个博客搭建起来还不到一年，已经有60多篇博文的产出，或许记下来的很多东西很水、很无聊，但至少也花费了一定的时间和精力。想起第一篇博文中所列举的种种目标，不禁莞尔一笑。目标那么容易完成，又怎么能叫目标呢？没完成自当更加努力。今年也不想再罗列其它各种目标和计划了，科研是实实在在的，记录下自己努力的过程才是最重要的。 —— 和本文无关的前言 正文来了！！今天要介绍的是Latex的小技巧，更确切得说，说Beamer中文模板的小技巧，聪明的你千万别跟我说，你不知道什么是Beamer。。。好吧，还是简单打个比喻，Beamer就是用Latex排版的PPT！ 最近刚结束开题答辩，于是乎就把制作开题Beamer的模板拿上来讲了，顺便记录自己在制作Beamer时的一些问题。 Beamer 内置主题说实话，Beamer自带的主题很多，尽管看起来大同小异，但是都挺好看的，该有的格式设计都有。我一般都是直接采用Beamer自带的主题模板，省了自己去找其它花里胡哨的模板。 Beamer自带主题在其官网中都能找到，多达26种，详见Beamer themes . Beamer 模板代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133\documentclass[hyperref]&#123;beamer&#125;\usepackage&#123;lmodern&#125;% 使用Ilmenua主题\usetheme&#123;Ilmenau&#125;\title&#123;Beamer Class Usetheme Ilmenau&#125; \author&#123;Sascha Frank&#125; \date&#123;\today&#125; \begin&#123;document&#125;\logo&#123;\includegraphics[scale=0.14]&#123;logo-SF&#125;&#125;\begin&#123;frame&#125;\titlepage\end&#123;frame&#125; \begin&#123;frame&#125;\frametitle&#123;Table of contents&#125;\tableofcontents\end&#123;frame&#125; \section&#123;Section no.1&#125; \begin&#123;frame&#125;\frametitle&#123;frame title&#125; Each frame should have a title.\end&#123;frame&#125;\subsection&#123;Subsection no.1.1 &#125;\begin&#123;frame&#125;Without title somethink is missing. \end&#123;frame&#125;\section&#123;Section no. 2&#125; \subsection&#123;Lists I&#125;\begin&#123;frame&#125;\frametitle&#123;unnumbered lists&#125;\begin&#123;itemize&#125;\item Introduction to \LaTeX&#123;&#125; \item Course 2 \item Termpapers and presentations with \LaTeX&#123;&#125; \item Beamer class\end&#123;itemize&#125; \end&#123;frame&#125;\begin&#123;frame&#125;\frametitle&#123;lists with single pauses&#125;\begin&#123;itemize&#125;\item Introduction to \LaTeX&#123;&#125; \pause \item Course 2 \pause \item Termpapers and presentations with \LaTeX&#123;&#125; \pause \item Beamer class\end&#123;itemize&#125; \end&#123;frame&#125;\begin&#123;frame&#125;\frametitle&#123;lists with pause&#125;\begin&#123;itemize&#125;[&lt;+-&gt;]\item Introduction to \LaTeX&#123;&#125; \item Course 2\item Termpapers and presentations with \LaTeX&#123;&#125; \item Beamer class\end&#123;itemize&#125; \end&#123;frame&#125;\subsection&#123;Lists II&#125;\begin&#123;frame&#125;\frametitle&#123;numbered lists&#125;\begin&#123;enumerate&#125;\item Introduction to \LaTeX&#123;&#125; \item Course 2 \item Termpapers and presentations with \LaTeX&#123;&#125; \item Beamer class\end&#123;enumerate&#125;\end&#123;frame&#125;\begin&#123;frame&#125;\frametitle&#123;numbered lists with single pauses&#125;\begin&#123;enumerate&#125;\item Introduction to \LaTeX&#123;&#125; \pause \item Course 2 \pause \item Termpapers and presentations with \LaTeX&#123;&#125; \pause \item Beamer class\end&#123;enumerate&#125;\end&#123;frame&#125;\begin&#123;frame&#125;\frametitle&#123;numbered lists with pause&#125;\begin&#123;enumerate&#125;[&lt;+-&gt;]\item Introduction to \LaTeX&#123;&#125; \item Course 2\item Termpapers and presentations with \LaTeX&#123;&#125; \item Beamer class\end&#123;enumerate&#125;\end&#123;frame&#125;\section&#123;Section no.3&#125; \subsection&#123;Tables&#125;\begin&#123;frame&#125;\frametitle&#123;Tables&#125;\begin&#123;tabular&#125;&#123;|c|c|c|&#125;\hline\textbf&#123;Date&#125; &amp; \textbf&#123;Instructor&#125; &amp; \textbf&#123;Title&#125; \\\hlineWS 04/05 &amp; Sascha Frank &amp; First steps with \LaTeX \\\hlineSS 05 &amp; Sascha Frank &amp; \LaTeX \ Course serial \\\hline\end&#123;tabular&#125;\end&#123;frame&#125;\begin&#123;frame&#125;\frametitle&#123;Tables with pause&#125;\begin&#123;tabular&#125;&#123;c c c&#125;A &amp; B &amp; C \\ \pause 1 &amp; 2 &amp; 3 \\ \pause A &amp; B &amp; C \\ \end&#123;tabular&#125; \end&#123;frame&#125;\section&#123;Section no. 4&#125;\subsection&#123;blocs&#125;\begin&#123;frame&#125;\frametitle&#123;blocs&#125;\begin&#123;block&#125;&#123;title of the bloc&#125;bloc text\end&#123;block&#125;\begin&#123;exampleblock&#125;&#123;title of the bloc&#125;bloc text\end&#123;exampleblock&#125;\begin&#123;alertblock&#125;&#123;title of the bloc&#125;bloc text\end&#123;alertblock&#125;\end&#123;frame&#125;\end&#123;document&#125; Beamer 排版技巧使用中文字体12345\usepackage&#123;xeCJK&#125;% 设置英文默认字体\setmainfont&#123;Times New Roman&#125; % 设置中文默认字体\setCJKmainfont[BoldFont=楷体-简 粗体]&#123;楷体-简&#125; 使用xeCJK包时，需要使用xeLaTex进行编译，选择中文字体时，在mac下直接查字体册中想要的字体名称即可。 另外，章节名称为中文时，为保证显示正常，需要使用hyperref包，即： 1\usepackage&#123;hyperref&#125; 完整呈现目录有时候，如果章节名设置太多，一张beamer放不下所有目录章节时，后面的章节就显示不出来，只要在frame中添加一个参数[shrink]即可解决： 1234\begin&#123;frame&#125;[shrink]\frametitle&#123;目录&#125;\tableofcontents\end&#123;frame&#125; 分栏这里提供两种分栏方法： 123456789101112% 第一种方法：无法自定义每栏宽度\usepackage&#123;multicol&#125;\begin&#123;multicols&#125;&#123;2&#125;双栏内容\end&#123;multicols&#125;% 第二种方法：可以自定义每栏宽度\begin&#123;columns&#125;\column&#123;8cm&#125;第一栏内容\column&#123;3cm&#125;第二栏内容 添加脚注直接在想要解释的内容添加命令\fotenote{}. 增加行间距离\vskip2mm 多行多列不规则三线表写表格的方式还是要看看相关的规则，但最基本的三个包最好要记住： 12345678910111213141516171819202122\usepackage&#123;multicol&#125;\usepackage&#123;multirow&#125;\usepackage&#123;booktabs&#125;% 举例\begin&#123;table&#125;\caption&#123;Combinations of predictive values and true values&#125;\label&#123;tab:2&#125; \begin&#123;tabular&#125;&#123;cccc&#125;\hline\noalign&#123;\smallskip&#125;% 上一句可直接使用 \toprule 替换，表示表格的顶行线\multicolumn&#123;2&#125;&#123;c&#125;&#123;\multirow&#123;2&#125;&#123;*&#125;&#123;&#125;&#125; &amp; \multicolumn&#123;2&#125;&#123;c&#125;&#123;$y_t$&#125; \\\cmidrule(lr)&#123;3-4&#125;\multicolumn&#123;2&#125;&#123;c&#125;&#123;&#125; &amp; 1 &amp; 0 \\\noalign&#123;\smallskip&#125; \hline\noalign&#123;\smallskip&#125;% 上一句可直接使用 \midrule 替换，表示表格中的行\multirow&#123;2&#125;&#123;*&#125;&#123;$\hat&#123;y_t&#125;$&#125; &amp; 1 &amp; True Positive $(tp)$ &amp; False Positive $(fp)$ \\&amp; 0 &amp; False Negative $(fn)$ &amp; True Negative $(tn)$ \\\noalign&#123;\smallskip&#125;\hline% 上一句可直接使用 \bottomrule 替换，表示表格的底行线\end&#123;tabular&#125;\end&#123;table&#125; 效果如图：]]></content>
      <categories>
        <category>Work</category>
      </categories>
      <tags>
        <tag>经验</tag>
        <tag>Latex</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[共享经济下的顾客可持续消费行为：基于社会交换理论]]></title>
    <url>%2F2018%2F11%2F24%2F61-%E5%85%B1%E4%BA%AB%E7%BB%8F%E6%B5%8E%E4%B8%8B%E7%9A%84%E9%A1%BE%E5%AE%A2%E5%8F%AF%E6%8C%81%E7%BB%AD%E6%B6%88%E8%B4%B9%E8%A1%8C%E4%B8%BA%EF%BC%9A%E5%9F%BA%E4%BA%8E%E7%A4%BE%E4%BC%9A%E4%BA%A4%E6%8D%A2%E7%90%86%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[今天要看的是一篇来自 Journal of cleaner production 的文章，因为最近的研究方向有意向投这本期刊，因此看看这本期刊的风格。这篇文章是 Unraveling customer sustainable consumption behaviors in sharing economy: A socio-economic approach based on social exchange theory，主要讲的是顾客可持续消费行为在共享经济中所扮演的角色和发挥的作用是什么，社会因素和经济因素又是怎么影响顾客可持续消费行为的。 Abstract顾客的可持续性消费行为越来越受人们的关注，然而当前的研究都关注于传统经济背景下的个人可持续消费行为，例如能源节约、循环使用和绿色产品消费等，很少人关注其在共享经济下的角色。本研究采用社会交换理论 (social exchange theory)，提出了一个概念模型去挖掘在共享经济背景下顾客可持续消费行为是怎么促进起来的。通过爬取 小猪短租 住宿平台的数据（有效样本=2967），文章检验了模型。根据社会交换理论的互惠原则，文章发现社会因素（如社会影响）对顾客可持续消费行为发挥正向影响，而经济因素（如价格）对顾客可持续消费行为产生负向影响。提高顾客可持续消费行为可提升销售表现。其次，一个服务提供商的策略（如名声 reputation 和反应率 response rate）可以正向提高社会因素对顾客可持续消费行为的作用，而这些策略在价格对顾客可持续消费行为的影响却是有限的，且不显著。 Introduction可持续消费行为是指在消费中，顾客在基于环保和社会影响的认知下支持可持续的自愿行为。顾客可持续消费行为有助于未充分利用资源 (under-utilized resources, e.g. sharing spare household resource) 的有效使用，提高一些产品的生命周期（如将物品保存在良好的条件中），这些都是共享经济下可持续性的表现。例如，爱彼迎 (Airbnb)的分析报告表示美国92%的顾客会比在自己的家产生更少的浪费并保持更整洁的环境，94%的顾客在租房中会循环使用物品等。 因此，促进共享经济的可持续消费行为对平台或社会的可持续性是很重要的。而共享经济下特定的可持续消费行为还需要实际验证和研究。因此本文提出了如下研究问题：(1) 如何提高共享经济下的顾客可持续消费行为？提高的边界条件在哪？(2) 顾客可持续性消费行为的成果和影响是什么？ 可持续性消费行为包括两个方面：环保的最小浪费和维持产品周期的自愿行为。这些方面其实可以认为是顾客与服务提供商的互惠行为，可以用社会交换理论来理解。社会交换理论的互惠原则表明在双边的关系中，一方的有益行为会带来另一方的友善回应。而且，在一种关系中社会资源和经济资源的交换，会使得这种交互关系更为紧密，从而促进合作和有利行为。P2P住宿是共享经济中一种典型的共享模式，其特点在于社交和省钱，顾客可以成为个人服务提供商（房主）的新朋友，而不是传统经济中的“God”。顾客会更享受这种P2P互惠交换因为大家可以网上交流。此外，通常这种P2P住宿的价格低于酒店，对顾客来说也是一种经济刺激，她们会表示感恩，且参与到可持续性消费行为中作为互惠反馈。因此，本文以社会交换理论为基础，探讨了社会影响 (social influence) 和价格 (price) 是如何影响顾客可持续性消费行为的。 本文的贡献主要如下。(1) 本研究是第一个去阐明可持续性消费行为特点的研究，并提出了相关策略去提高这些行为，以及这些行为在共享经济环境下的结果和影响。(2) 本研究检验了可持续消费行为对销售表现的直接影响。(3) 本研究从社会交换理论这个新视角去探究共享经济环境下人与人之间交往的本质。 Research framework &amp; hypotheses研究模型图： Antecedents of customer sustainable consumption behaviors Social factor: social influence，即社会影响，某种程度反应了社会支持 (social support) Economic factor: money-saving, high-quality service 根据前面两个前提，本文首先提出两个假设： H1a：社会影响正向影响顾客可持续消费行为； H1b：价格负向影响顾客可持续消费行为。 Moderating effects of service provider’s reputation &amp; response rate社会交换理论的一个重要原则就是信任。在P2P住宿平台中，顾客消费行为取决于服务提供商的声誉和服务质量。服务提供商的声誉保证了网上交易的安全性，同时提高了顾客和提供商之间的相互信任。此外，声誉也减少信息不对称，增加了顾客支付额外小费的意愿，由此减少了价格对可持续消费行为的负向影响。因此，本文继续提出如下假设： H2a：相较于声誉差的服务提供商，声誉好的服务提供商的社会影响对顾客可持续消费行为的正向影响更大； H2b：相较于声誉差的服务提供商，声誉好的服务提供商的价格对顾客可持续消费行为的负向影响更小。 在P2P住宿平台中，拥有及时回复速率的房主更能获得一个好印象，并由此促进信任的建立。由此提出如下假设： H3a：相较于回复效率低下的服务提供商，回复高效的服务提供商的社会影响对顾客可持续消费行为的正向影响更大； H3b：相较于回复效率低下的服务提供商，回复高效的服务提供商的价格对顾客可持续消费行为的负向影响更小。 The outcome of customer sustainable consumption behaviorsH4: 顾客可持续消费行为正向影响销售表现。 Methodology本研究从 小猪短租 P2P平台上获取数据，数据样本地点为北京，包含3027套房子，29054条顾客评论和24265条房主回复。对变量异常值进行筛选之后，文中最终确定2967条样本。平均每个房子的订单数量为161，均价为538。约有1869家房主应用了声誉系统，另1159家则没有。房子平均面积大小为83平方米，平均能够接待3位顾客。其中，有410套 (13.54%) 房子和描述的一致，而有745套 (24.61%) 房子小猪平台被鉴定为高质量房子。 本文采用三个数据来源的measures： 网站爬取：sales performance, social influence, price, service provider’s reputation, response rate, room quality, check as described, room size, and the number of guests. 变量：房子图片的数量 (the number of photos). 可持续消费行为代理指标：房主回复中包含顾客自愿清洁的数量 (the number of words associated with voluntary cleaning work from hosts’ reply) （说实话这个变量挺怪的，它是通过文本内容分析得到这个变量，如果房主针对一个顾客的一句回复说到房子被顾客清洁过了，那么编码为1，如果在n次回复中都出现了清洁，那么编码为n）。 以下一表给出了measure的定义，另一表给出了描述性统计和变量相关系数。 Results本文主要检验了两个因变量，一个是顾客可持续消费行为，另一个是销售表现。结果如图： 模型1展示了控制变量，模型2添加了自变量。显然，社会影响对顾客可持续消费行为是正向影响，而价格对顾客可持续消费行为是负向影响。其次，在模型5中顾客可持续消费行为可提高销售表现，也是正向影响。由此，H1a，H1b和H4均得到支持。 为了检验调节效应，在模型3中添加了交互项。结果显示服务提供商的声誉正向调节社会影响力和顾客可持续消费行为之间的关系 (贝塔系数=0.003)，然而服务提供商的声誉却是负向调节价格对顾客可持续消费行为的影响。因此，H2a得到支持，而H2b则没有。同理，H3a得到支持，而H3b没有（H3b甚至不显著）。 如下数图展示了声誉和回应速率两个调节变量的效应： H3b由于不显著，因此没有画图进一步检验了。 DiscussionTheoretical implication 补充了共享经济视角下顾客可持续消费行为研究的空缺； 发现社会因素和经济因素对顾客可持续消费行为的显著影响，这些影响可提高销售表现； 拓展了对共享经济文献的认知和理解 (understanding); 丰富了社会交换理论的文献，本文将顾客可持续消费行为视为共享经济下的一个互惠行为。 Practical implications 平台管理者应意识到顾客可持续消费行为能对环境、社会和经济方面都产生贡献。为了促进可持续消费行为，平台管理者应该鼓励房主使用声誉评价系统，且对声誉好的房主进行经济奖励；其次，可以设定具体条例让顾客在住宿期间保持清洁整齐，如在顾客入住前发送环保信息。 对于房主来说，顾客可持续消费行为也是吸引更多顾客的一个重要因素。因此，房主可以从保持房子整洁提高社会影响力，采取促销价格作为经济刺激，或提高声誉和回复效率等多种方式来促进顾客可持续消费行为。 Reference Wang Y, Xiang D, Yang Z Y, et al. Unraveling customer sustainable consumption behaviors in sharing economy: A socio-economic approach based on social exchange theory[J]. Journal of Cleaner Production, 2019, 208: 869-879.]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>实证</tag>
        <tag>可持续</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[政治表现与投资决策——以公众养老基金为例]]></title>
    <url>%2F2018%2F11%2F08%2F60-%E6%94%BF%E6%B2%BB%E8%A1%A8%E7%8E%B0%E4%B8%8E%E6%8A%95%E8%B5%84%E5%86%B3%E7%AD%96%E2%80%94%E2%80%94%E4%BB%A5%E5%85%AC%E4%BC%97%E5%85%BB%E8%80%81%E5%9F%BA%E9%87%91%E4%B8%BA%E4%BE%8B%2F</url>
    <content type="text"><![CDATA[今天要讲的是一篇论文，最近在研究政策与投资的关系，刚好在 Journal of Finance 最新一期上看到一篇关于政策表现和投资决策的文章: Political Representation and Governance: Evidence from the Investment Decisions of Public Pension Funds，于是赶紧下载来读一读，同时也和大家分享分享。 Abstract Representation on pension fund boards by state officials—-often determined by statute decades past—-is negatively related to the performance of private equity investments made by the pension fund, despite state officials’ relatively strong financial education and experience. Their underperformance appears to be partly driven by poor investment decisions consisitent with political expediency, and is also positively related to political contributions from the finance industry. Boards dominated by elected rank-and-file plan participants also underperform, but to a smaller extent and due to these trustees’ lesser financial experience. 摘要主要讲的是养老基金组委会由政府官员 (state official) 组成做主导的话（在数十年前常由法令决定），那么政府官员的表现与养老基金私募股权投资的表现呈负相关，哪怕政府官员拥有较好的财务教育和经历。为什么呢？这种低迷的表现部分可能是政府官员为了政治私利而做出差的投资决策所导致的，它与来自金融业的政治捐款呈正相关。而如果组委会是由普通参与者 (participant) 选举产生并组成的，那么同样可能出现低迷表现，但是程度上会更小，因为这些人的财务经历更少。在这里，board members有三类：state, public, participant；这三类members产生的途径也有三种：政府任命 (appointed)、凭借自身职务 (ex officio)、由其他成员选举 (elected)。 看了摘要感觉有点奇怪，基金的投资表现怎么与基金经理是不是政府官员扯上了关系？反而基金经理的能力和经历倒是影响的其次了？让我们接下去看看。 Introduction目前有许多文献已经表明政治联系对企业有很大的价值，什么样的政治联系呢？比如说企业的资本成本、采购合同等是政治影响的一些渠道，公众资产组委会的管理同样是一种渠道。在这篇文章中，作者就展示了在资产管理组委会上的政治影响，同时展示了与前人研究产生不同影响的机制。 本文主要检验的投资决策是养老基金投资分配，以及私有股权资产的表现 (performance)，其中私有股权资产 (private equity (PE) asset) 具体来说包括 buyout, venture capital (VC), real estate (RE), natural resources, funds of funds 和其他一些私有投资的杂项。 基金表现主要由净内部收益率 (IRR) 来衡量，基金表现与组委会政客的表现 (representation)相关性很大。相对于基金参与者任命成为组委会成员，当政客由其他官员任命进入组委会时，每增加组委会中 10% 的政客比例，将减少 IRR 0.9%；当政客凭借他自己的官职进入组委会时，每增加组委会中 10% 的政客比例，将减少 IRR 0.5%。 为什么政客在组委会中会导致养老基金表现不佳？文章从三个渠道进行了检验，the Control channel, the Corruption channel and the Confusion channel. 作者还介绍了很多发现，在这里不提，放到结果中一并展示。那么文章的主要贡献在于：(1) 揭示了政客在组委会、投资决策和基金表现的影响和作用；多数文献认为政治联系能提高基金价值，然而政客的作用只在于通过公众的财富为自己获利，这就意味着政治联系带来的是潜在的亏损，而不是收益。其次，检验了政客的存在是否有利于纳税人和养老金受益者。政客将公众养老金资产投资到 PE 中会带来更低的收益，且需要支付的成本很大程度上由计划参与者和纳税人承担。(2) 促进了在当前会计和监管制度下公众养老金和投资刺激的相关文献的进展，先前研究认为养老金不总是追求净值最大化，而这篇研究表明由政客主导的公众养老基金更容易出现以牺牲投资表现去追求政治或个人利益。(3) 促进了投资表现和决策者（基金经理或个人投资者）特征关系的相关资产管理文献的进展。 Data and Sample数据有4个来源： 公众养老金基金委员会组成（Comprehensive Annual Financial Reports） 基金受托人的人物信息（Generalized web search） 基金受托人收到的政治捐款（Follow the Money database） PE 投资数据（Preqin） 根据以上数据来源，作者收集了1990-2011年间212只养老基金投向13559个私有股权投资的数据，相关描述性统计见如下数图表： Political Representatives on Boards of Trustees and Performance首先作者对投资表现和组委会组成进行了回归，检验了它们之间的相关性。 其次，作者分析了组委会组成是否真的能够影响投资表现。它采用了养老基金的三个样本子集：Old Board, Change, Change. Polotical Representation and Investment Selection是什么导致了在政客表现中组委会的投资不佳？作者认为投资表现的区别是由于PE投资的不同分配导致的。因此，作者再次分析了不同类型基金的IRR与组委会组成等各大变量的关系： 政客表现和投资表现的因果关系可以表明在一个组委会中，将政府官员替换为更加独立的组委会成员（如公众或计划参与者等）会使基金投资表现更好： Political Contributions and Performance在这一节，作者检验了投资表现和政治捐款的关系： Experience, Skills and Performance这一节作者检验了组委会成员不同财务能力和经验对投资表现的影响程度： 结果显示较低的财务技能几乎可以解释所有选举参与者的低迷表现，然而却不能解释政府官员的低迷表现。这个结果很令人惊讶。 Conclusion这篇文章主要发现了由政客管理的养老基金投资于PE基金会导致更差的IRR或其他投资表现。为什么会表现不佳？文章从三个渠道得出了结论。 Control channel. 政客在养老基金投资越多RE，获得收益越低。管理差的养老基金更可能投资小型私有基金，这些私有基金通常很少投资者去投资，且由经验较差的基金经理管理。 Corruption Channel. 政客导致的投资不佳部分可以由政客接受的政治捐款进行解释。 Confusion Channel. 缺少金融知识、技能和经验会导致政客管理的投资表现不佳。 Reference Andonov A, Hochberg Y V, Rauh J D. Political representation and governance: Evidence from the investment decisions of public pension funds[J]. The Journal of Finance, 2018, 73(5): 2041-2086.]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>决策理论与方法</tag>
        <tag>实证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将本地博客从Windows迁移到Mac上]]></title>
    <url>%2F2018%2F10%2F29%2F59-%E5%B0%86%E6%9C%AC%E5%9C%B0%E5%8D%9A%E5%AE%A2%E4%BB%8EWindows%E8%BF%81%E7%A7%BB%E5%88%B0Mac%E4%B8%8A%2F</url>
    <content type="text"><![CDATA[嘻嘻，最近新买了一部macbookpro，真是可喜可贺，一直在探索着全新的世界，全然忘记了更新博客的事。结果等到月底想在新电脑上更新博客的时候，才发现原来博客迁移是那么繁琐的一件事，在无数的坑中跳进跳出，花了一两天才彻底搞定。 为了避免大家重蹈覆辙，先把相关教程记录下来，并将一些实用帖子分享给大家。 从网上大部分的教程来看，关于迁移Hexo博客的基本上都是在Windows环境下，而关于Mac环境的基本上都是建立Hexo博客的专题，基本没有迁移博客的专题（至少我没找到。。。）。但是我发现，其实不管是Mac还是Windows，建站的流程是很相似的，或许迁移的过程也没有太大的区别吧。 那么我们来看一下，将本地博客从Windows环境迁移到Mac下有什么需要注意的地方。由于大部分网上教程都有十分详细的过程，在这里我也不再重复浪费字数了，把涉及到关键细节的帖子post上来，大家一步步对照着处理就好了。 先在Mac上建站安装node.js, npm和Git首先到 nodejs官网 上下载node.js，安装时一路点下一步，基本上没有任何问题。 安装好之后就可以在终端查一下当前安装node.js和npm的版本号（npm是附属在node.js安装包上，与node.js同时安装）： 12$ node -v$ npm -v 另外，一般在Mac上都已经自带Git了。如果不清楚的话，可以通过这个帖子的教程查询一下是否存在Git，有的话可以忽略，没有的话继续按照教程进行安装： MAC上Git安装与GitHub基本使用 备份旧博客文件安装Hexo之前，我们要把旧博客的文章以及相关内容给备份一遍，然后在安装完Hexo之后将备份内容与对应新博客的内容进行替换，具体需要备份的文件有：source和themes文件夹，站点配置文件_config.yml。 安装 Hexo安装Hexo其实非常简单，直接按照下面这个教程进行安装就好了： Hexo的安装和使用（mac篇） 如果在安装过程中常会出现perimission denied相关错误，就在命令前加上sudo，然后执行命令的时候输入你的锁屏密码就可以了。sudo是指用管理员权限运行。 备份文件替换由于我们刚刚已经将旧博客的各种主题配置文件都备份好了，那么现在就不再需要专门去下载主题了，直接将备份文件拖到新博客对应目录下进行替换。 设定Github公匙SSH上述步骤已经重新将整个博客框架及内容迁移到新电脑了，然而在重新进行deploy的时候，却发现出错，同样是permission denied的问题，这次问题的原因和上面不同，而是因为缺少SSH，因此我们要重新设置一个，详见这个帖子： 关于Hexo部署文章时出现的问题-SSH 设置完之后我猜基本上部署到Github上应该是没什么问题了。大家打开自己的博客网页，如果和原来一模一样，那么说明迁移成功！ 公式问题但事实上，很多时候并没有那么简单。我还是想得太简单，结果成功掉坑了。尽管部署成功了，但是我打开网页，结果基本上所有的公式都乱码了。所以我又耗了许多精力在这上面，但多亏了这个帖子，让我成功解决了这个问题： 使用LaTex添加公式到Hexo博客里 其实很多时候部署不成功，其实不是我们的错误，而是因为在新的环境下，没有将需要的包给安装起来，比如说公式的Kramed包，还有其他一些自定义功能的包，反正缺少什么就安装什么好了。 Next主题更新我采用的是next主题，但是在我旧博客上的next主题其实也是旧版的，所以每次在generate的时候，总会出现这样的提示： 1234567WARN ======================================================WARN ================== ATTENTION! ========================WARN ======================================================WARN NexT repository is moving here: https://github.com/theme-nextWARN ======================================================WARN It&apos;s rebase to v6.0.0 and future maintenance will resume thereWARN ====================================================== 强迫症的人可能受不了这样的警告。所以我毫不犹豫地对Next主题进行了升级。当然第一步就是搜教程，然后就让我发现了这个帖子： Hexo博客NexT主题从v5.x.x更新到v6.x.x的记录及总结 话说上面这个帖子的博主真的很牛逼，他的博客界面真心好看，而且内容质量也挺好的。我得继续努力才行，向高人看齐！ 以上就是我在将本地博客从Windows迁移到Mac上的一些过程，在每个步骤过程中都有许多细节需要注意，因此将这些细节的解决方法和教程搜集起来分享给大家。 Reference https://www.jianshu.com/p/7edb6b838a2e https://blog.csdn.net/superchao_5/article/details/51963942?utm_source=blogxgwz2 https://www.jianshu.com/p/9b67641b5ec7 https://blog.csdn.net/Aoman_Hao/article/details/81381507?utm_source=blogxgwz8 https://sevencho.github.io/archives/14534beb.html#more]]></content>
      <categories>
        <category>Work</category>
      </categories>
      <tags>
        <tag>经验</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[循环神经网络大比拼——基于金融时序数据预测的检验]]></title>
    <url>%2F2018%2F09%2F22%2F58-%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%A4%A7%E6%AF%94%E6%8B%BC%E2%80%94%E2%80%94%E5%9F%BA%E4%BA%8E%E9%87%91%E8%9E%8D%E6%97%B6%E5%BA%8F%E6%95%B0%E6%8D%AE%E9%A2%84%E6%B5%8B%E7%9A%84%E6%A3%80%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[在之前的深度学习课程中，我们已经详细介绍过循环神经网络 (Recurrent neural network)。 RNN的应用相当之多，主要是用于时序数据的处理，如语音识别、机器翻译等。因为它具备长时记忆性，能够记住上一个时段的输入特征对下一时段的影响。RNN层 主要有三种形式，SimpleRNN，GRU 以及 LSTM 层。在这里我们以预测时序金融价格数据为例，分别比较哪种一下哪种类型的RNN层效果更优！ Data沪深300股票指数一直以来都是我进行金融研究的主要对象，因为它基本上代表了整个大盘的波动情况，也是A股市场盈亏的晴雨表。在这里也不例外，我挺喜欢直接从 聚宽 上获取数据，因为方便快捷，做个小研究的话也不大需要数据的严谨性。当然，如果需要更加可靠的数据，可以去Wind数据库获取。 首先，聚宽提供了很方便的数据接口，我们简单提取沪深300指数5分钟级数据，并将其导出到本地进行研究。事实上，也可以在聚宽平台上直接进行实验，但我更习惯在本地上操作。获取数据代码如下： 12345678910import pandas as pd# 沪深300股票指数代码：000300index = &apos;000300.XSHG&apos;# 获取5分钟级数据df = get_price(index,start_date=&apos;2013-01-1&apos;,end_date=&apos;2017-12-31&apos;,frequency=&apos;5m&apos;,fields=&apos;close&apos;,skip_paused=True)# 将行名另设为一列df.index.name=&apos;time&apos;df.reset_index(inplace=True)# 导出到本地df.to_csv(&apos;000300.csv&apos;) Data preprocessing首先，我们对数据进行标准化处理，标准化在神经网络训练中是十分重要的，它通常能大大加快梯度下降的速度。Z-score 是最常用的标准化方法之一： x_{standardize} = \frac{x-\mu}{\sigma}其中，$\mu$ 和 $\sigma$ 分别为沪深300价格序列的均值和标准差。 其次，由于我们输入的是时序数据，并预测下一步的价格。因此，我们需要定义一个窗宽，根据窗宽将数据集切割成一段段具有时序性的输入，简单来说代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940# 首先导入各个步骤会使用到的模块import numpy as npimport pandas as pdfrom keras.models import Sequentialfrom keras.layers import Densefrom keras.layers import SimpleRNN, GRU, LSTMfrom matplotlib import pyplot as plt# 加载第一步中下载得到的数据集index = np.loadtxt(&apos;D:/.../000300.csv&apos;, delimiter=&apos;,&apos;, skiprows=1, usecols=2)x = []# 数据标准化x_mean = np.mean(index)x_std = np.std(index)index_standard = (index-x_mean)/x_std# 设定窗宽w = 48# 根据窗宽划分每个时间步输入for t in range(len(index_standard)-w): a = index_standard[t:t+w] x.append(a)# 输入x和输出yx = np.array(x)y = index_standard[w:(len(index_standard)+1)]# 划分训练集和测试集train_num = int(len(x)*0.85)test_num = int(len(x)*0.15)x_train = x[0:train_num]x_test = x[len(x_train):(len(x_train)+test_num+1)]y_train = y[0:train_num]x_test = y[len(y_train):(len(y_train)+test_num+1)]# 将二维数据重置为能够输入模型的三维尺度x_train = np.reshape(x_train,(len(x_train),1,w))x_test = np.reshape(x_test,(len(x_test),1,w)) 窗宽由自己按实际情况而定，在这里我把窗宽定为48，主要是我们的数据为5分钟级高频数据，1天能采集到48个时间价格。大家也可以多去尝试，从而做出更好的选择。 SimpleRNN, GRU &amp; LSTM这三种类型的RNN层，其各自特点在之前的深度学习课程都已经讲解过了，在这就不再重复啰嗦了，我们直接进行实验并对照结果。在这里为保证结果一致性，因此每种类型RNN层的层数，节点数，batch-size 等超参数都作相同的设定。 1234567891011121314151617181920212223# SimpleRNN 模型架构model = Sequential()model.add(SimpleRNN(32, return_sequences=True, input_shape=(x_train.shape[1], 1)))model.add(SimpleRNN(32, return_sequences=True))model.add(SimpleRNN(32))model.add(Dense(1))model.compile(loss=&apos;mean_squared_error&apos;,optimizer=&apos;adam&apos;)# GRUmodel_gru = Sequential()model_gru.add(GRU(32, return_sequences=True, input_shape=(x_train.shape[1], 1)))model_gru.add(GRU(32, return_sequences=True))model_gru.add(GRU(32))model_gru.add(Dense(1))model_gru.compile(loss=&apos;mean_squared_error&apos;,optimizer=&apos;adam)#LSTMmodel_lstm = Sequential()model_lstm.add(LSTM(32, return_sequences=True, input_shape=(x_train.shape[1], 1)))model_lstm.add(LSTM(32, return_sequences=True))model_lstm.add(LSTM(32))model_lstm.add(Dense(1))model_lstm.compile(loss=&apos;mean_squared_error&apos;,optimizer=&apos;ada) 上面为各个类型RNN层的模型架构，大家可参考Keras文档。建立好模型之后，我们开始对训练集进行训练拟合，并对测试集做出相应预测。 12345678910# 拟合,以20%样本作为验证集fit = model.fit(x_train, y_train, batch_size=32, epochs=100, validation_split=0.2, shuffle=False)# 预测pred_rnn = model.predict(x_test,batch_size=32)# 将迭代的损失函数保留fithistory = pd.DataFrame(fit.history)# GRU和LSTM的拟合与上面类似，在这里不再重复 训练结果我们可以看损失值，损失值越大，说明训练效果越差，拟合优度越低。 1234567891011121314151617181920212223plt.figure(figsize=(15,5))plt.subplot(131)plt.plot(range(1,101), fithistory[&apos;val_loss&apos;],c=&apos;red&apos;, label=&apos;Loss(development)&apos;)plt.plot(range(1,101), fithistory[&apos;loss&apos;],c=&apos;blue&apos;,label=&apos;Loss(train)&apos;)plt.legend()plt.ylabel(&apos;Loss of SimeRNN&apos;)plt.xlabel(&apos;Number of epochs&apos;)plt.subplot(132)plt.plot(range(1,101), fithistory_gru[&apos;val_loss&apos;],c=&apos;red&apos;, label=&apos;Loss(development)&apos;)plt.plot(range(1,101), fithistory_gru[&apos;loss&apos;],c=&apos;blue&apos;, label=&apos;Loss(train)&apos;)plt.legend()plt.ylabel(&apos;Loss of GRU&apos;)plt.xlabel(&apos;Number of epochs&apos;)plt.subplot(133)plt.plot(range(1,101), fithistory_lstm[&apos;val_loss&apos;],c=&apos;red&apos;, label=&apos;Loss(development)&apos;)plt.plot(range(1,101), fithistory_lstm[&apos;loss&apos;],c=&apos;blue&apos;, label=&apos;Loss(train)&apos;)plt.legend()plt.ylabel(&apos;Loss of LSTM&apos;)plt.xlabel(&apos;Number of epochs&apos;)plt.show() 训练效果主要看蓝线，因为它是训练集的损失值，红线代表的是验证集的损失值。由于验证集和测试集是同分布的，验证集的损失值基本也就相当于测试集的损失值。从图中可见，蓝线中 SimpleRNN 的损失值最低，说明 SimpleRNN 在训练集上的拟合效果最好。而红线中 GRU 的损失值相对较低，说明 GRU 在测试集上的拟合效果会更好。 Result Analysis经过上面的训练，我们可以看看预测结果如何，并比较哪种模型的预测效果最好。由于在开始时我们对数据进行了标准化，现在我们要对数据进行逆标准化，使数据恢复原来的量纲。 12345# 其中，pred_gru 和 pred_lstm 分别为GRU和LSTM模型拟合的结果y_pred_rnn = pred_rnn * x_std + x_meany_pred_gru = pred_gru * x_std + x_meany_pred_lstm = pred_lstm * x_std + x_meany_test_recover = y_test * x_std + x_mean 顺便将时间点提取出来，其实在第一步就应该提取出来的，省得麻烦。。。 123time = pd.read_csv(&apos;D:/.../000300.csv&apos;, header=0, usecols=[&apos;time&apos;])time = time.iloc[-8741:]time = pd.to_datetime(time[&apos;time&apos;]) 接下来我们画个图看看实际值和预测值的差别： 123456789101112131415161718192021222324plt.figure(figsize=(15,5))plt.subplot(131)plt.plot(time, y_test_recover, c=&apos;red&apos;,label=&apos;CSI_300&apos;)plt.plot(time, y_pred_rnn, c=&apos;blue&apos;, label=&apos;Prediction based on SimpleRNN&apos;)plt.legend()plt.ylabel(&apos;Price&apos;)plt.xlabel(&apos;Time&apos;)plt.subplot(132)plt.plot(time, y_test_recover, c=&apos;red&apos;,label=&apos;CSI_300&apos;)plt.plot(time, y_pred_gru, c=&apos;blue&apos;, label=&apos;Prediction based on GRU&apos;)plt.legend()plt.ylabel(&apos;Price&apos;)plt.xlabel(&apos;Time&apos;)plt.subplot(133)plt.plot(time, y_test_recover, c=&apos;red&apos;,label=&apos;CSI_300&apos;)plt.plot(time, y_pred_lstm, c=&apos;blue&apos;, label=&apos;Prediction based on LSTM&apos;)plt.legend()plt.ylabel(&apos;Price&apos;)plt.xlabel(&apos;Time&apos;)plt.show() 从图中可见，在前期应该是 GRU 的预测效果与实际价格最为靠近，但到了后期几乎三种模型似乎都偏离得越来越远，因此我们不能简单断定哪个模型最好，还需要一定的评价指标来加以辅助判断。 而对于序列数据是说，评价指标通常会采用余弦相似度。如果两序列的余弦相似度越高，说明两序列越相似，走势也越相同。 \cos \theta=\frac{\bf{a} \cdot \bf{b}}{\lvert \bf{a} \rvert \cdot \lvert \bf{b} \rvert}=\frac{x_1y_1+x_2y_2+\cdots+x_ny_n}{\sqrt{x_1^2+x_2^2+\cdots+x_n^2}\sqrt{y_1^2+y_2^2+\cdots+y_n^2}}我不太了解哪个包有具体余弦相似度的评价指标，所以自己简单定义了一个： 123456def cosine_sim(x,y): sim = np.dot(x,y) norm_x = np.linalg.norm(x) norm_y = np.linalg.norm(y) cosine_sim = sim/(norm_x * norm_y) return cosine_sim 1234567# 上面编写的函数太简陋了。。以至于自己不得不另外统一一下输入的维度，非程序猿的本质暴露无遗。。。y_test_recover1 = np.reshape(y_test_recover,(1,8741))# 逐个计算余弦相似度cosine_rnn = cosine_sim(y_test_recover1, y_pred_rnn) cosine_gru = cosine_sim(y_test_recover1, y_pred_gru)cosine_lstm = cosine_sim(y_test_recover1, y_pred_lstm) SimpleRNN GRU LSTM Cosine_similarity 0.999678 0.999868 0.999961 。。。。。。好吧，这个评价指标其实感觉并不太好，三个值都异常高且差别超乎想象地小，似乎没有达到我想要区别三个模型的效果。看来我还是得老老实实回头再认认真真复习一下深度学习的课程。不过我们从序列相似度来看，LSTM还是最高的，说明LSMT预测价格的走势和实际价格的走势相似度是高度相似的，尽管从预测图来看似乎两价格的距离很大。然而假设我们只预测涨跌，而不是预测具体价格的话，那么LSTM还是很有优势的。 Summary简单做了一个实验，就当是锻炼一下自己打代码的能力了。尽管实验结果并没有我们预期的那么好，其实就是我没能进一步调参所造成的结果。。。有空再试一下好好进行调参看看。]]></content>
      <categories>
        <category>Work</category>
      </categories>
      <tags>
        <tag>RNN</tag>
        <tag>Recurrent Neural Networks</tag>
        <tag>GRU</tag>
        <tag>LSTM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[演唱会之夜]]></title>
    <url>%2F2018%2F08%2F18%2F57-%E6%BC%94%E5%94%B1%E4%BC%9A%E4%B9%8B%E5%A4%9C%2F</url>
    <content type="text"><![CDATA[记下 2018年8月17日和9月21日 的夜晚。 8月17日上急急忙忙穿梭于国子监大大小小的胡同之中，汗水隐隐约约在额上闪现，抬腕看了一下手环，“哎呀，已经6点多了，怎么还找不到共享单车？！要是耽误了演唱会可就不得了了。”心慌着，也顾不得吃晚饭的事了，只想早点赶到体育馆现场。 十几分钟前微信收到一条信息：“到了吗~”，顿时把还沉浸在国子监大街拍照的我惊醒了，我看了看时间，急着搜了一下地图便快步走了起来，抱歉！人家还在等着我的票呢！赶忙中便回复了信息。我买了两张演唱会的票，本想着能找个朋友陪伴一起去，却怎么也找不着，无奈跑到豆瓣上转让了一张出去。 睡米要了那张票，那是她在微信上的昵称。我没问她的名字，也没改备注，就叫睡米好了，挺好听的！ 中途找到了一辆摩拜，花了20分钟终于到了现场——北京工人体育馆。“我在北门门口了，北京建工城管车旁边。”看到信息后，我摸索着，突然眼前就出现了一个不时低头看着手机又抬头望向四周的女生。 她的模样在我感觉就像是一个川妹子，高高瘦瘦，小麦色皮肤带点黝黑，一头长发黑又直，涂了口红的嘴唇就像是平淡中的一点惊艳，身上的职业衬衫干净整洁。 “你好！”这时，她也注意到我了。 她走了过来，我翻着书包拿出了票撕了一张给她。 “400块钱对吧？”她很快地就给我转了账。 “好的！你现在要进去吗？我们是连坐的，要不一起进去？”我问了问她。 “行。”她犹豫了一下，便答应了。 从北门进入北京工人体育馆中，睡米看了看票，说我们的座位在东门。我满脸惊诧地跟着她，“这是我第一次来北京工人体育馆呢！”。 睡米瞥了我一眼，“噢，那你应该是从外地来的吧？” 观察力很强的一个女孩子，我尴尬地笑了笑。出于好奇心使然，我又想着到处转转。看了看表，还不到六点半，距演唱会开始还有一个多小时。眼下已经走到东门了，我跟睡米说，我还不想进去呢，有点早。睡米也在犹豫着，她也不想太早进馆的吧。 我不是个擅长沟通的人，没有和她聊天的意思。况且睡米对这个体育馆貌似很熟悉了，她应该不会想逛这个体育馆。于是我自己溜着溜着就走开了，再次沉浸在我的看人看景的世界中。 ~~ 中转眼就已经七点整了，我想是时候进场了，于是赶忙去检票。在寻找座位的途中，很巧又碰见睡米也在找位子，哈哈。很快，我和她便找到了座位。这时，我注意到睡米手上的一本册子，我四周望了下，原来每个座位边上都插了一本演唱会的介绍册。 我看着专辑《回声》里的11首歌，是我大学期间最难忘的回忆之一。曾经我就在想着，如果有一天有这么一场演唱会，那么我一定会来。命运有时候总是安排地这么巧妙，于是乎我来了，恰恰是在北京，恰恰是在这个暑假。我多希望自己能和三毛也有一点缘分，能见其真人，而非读其书。我想她的人或许比她的书有趣得多。我有个荒谬的念头，如果人死后真有灵魂，那么我的灵魂在出窍后会不会去找三毛？ 哈哈，我扫开这些奇奇怪怪而又纷纷扰扰的念头，看向睡米， “你也喜欢三毛吗？” 她低着头，“三毛是我高中看的，其实我更喜欢是听齐豫的歌。” 哇，我惊呼了一声，原来来这演唱会的竟然还有齐豫的歌迷，而不是三毛的粉丝！ “我问过一些同事，他们都说根本没听过齐豫，但是她的歌真的很好听啊。” “齐豫的歌我也觉得蛮好听的，但是我大部分都没听说，基本就是三毛专辑这十几首了。” “我特别喜欢李宗盛写的曲，然后由齐豫演唱，像《七点钟》这首。” “对，对，李宗盛的歌会更加流行……” 我本以为我们会聊到三毛，结果却聊起了歌。很快，演唱会便开始了。 下在这节中，我们都各自沉浸在演唱会中，一首接着一首，时而沉静，时而欢呼，连拍照也是顾不上。 睡米拍了几张，上面那张就是从她朋友圈中“盗”来的，哈哈。 在这接近两个半小时的演唱会中，我有着深深的感动。我已经没办法描述和形容当时的场景了，它是神圣的，它永远留在了我的心中，留在我脑海中的某个角落。 演唱会结束后，人潮涌动，我和睡米走散了却浑然不觉。因为我还沉醉着仿佛不能醒来，就像是一艘小船，随着河水不断漂流，漂流，却不知道自己走了多远。 走到门外，我茫然望着星空，拿出手机给睡米发了一句，“一个美好的夜晚，谢谢有你的陪伴。” 后记回去后我就把睡米的微信删了，相逢何必曾相识。 9月21日仅仅过了一个多月，我在此来到了演唱会的现场，而这次的主角是我最爱的乐队—— The royal concept ！！！ 哈哈，这场演唱会完全没有什么美丽的邂逅，因为是我一个人去 High 的。在去往现场的路上，实在想不到中秋假期的周五晚地铁原来是如此恐怖，在6号线等了8趟才挤上了地铁。心想千万不要赶不上，一路飞走。还没到现场，已经开始把自己给激动起来了。 主唱 David 真的是帅爆了，我以为自己不会追星，结果遇到真正心爱的星星后追起来也是势不可挡啊！ 话不多说，看看这个乐队到底有多酷！ 激昂的心跳，震耳欲聋的摇滚声，无数人的狂欢，是在这个 live house 最真实的写照。真想不到喜欢三毛的我，原来也有喜欢电子摇滚的一面，这场演唱会的风格和上一场简直风牛马不相及。哈哈哈。（以上的图也是盗自演唱会交流群中，像我这种基本上是不可能拍照的啦！感谢这位网友的贡献！如侵权请联系删图。） 看演唱会的花费对还是学生的我自然是一笔沉重的负担，但是我却有我的法子！因为我买的票都是从别人的手中低价转让过来的！！每次想去演唱会，首先肯定不是正儿八经到官网去买票，而是转战各路豆瓣、贴吧论坛，搜有没有转让的，没有的话再自己写个帖求转让。一般临时去不了的歌迷，当然会低价转让出去的啦！]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>三毛</tag>
        <tag>The Royal Concept</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让Keras更酷一些！Keras模型杂谈]]></title>
    <url>%2F2018%2F08%2F12%2F56-%E8%AE%A9Keras%E6%9B%B4%E9%85%B7%E4%B8%80%E4%BA%9B%EF%BC%81Keras%E6%A8%A1%E5%9E%8B%E6%9D%82%E8%B0%88%2F</url>
    <content type="text"><![CDATA[今天刚好读到一篇关于深度学习框架 Keras 的教程，我挺喜欢 Keras 的，毕竟它是我唯一会使用的框架。。。。之前也是一直跟着 Keras Documentation 边看边学，但总觉得里面的例子太简单，想要自己实际编程时困难重重。今天看到的这篇博文，倒是解决了我之前不少的疑惑，在这里转载分享给大家。 让Keras更酷一些！Keras模型杂谈 转载自：https://www.spaces.ac.cn/archives/5765 Keras 伴我走来回想起进入机器学习领域的这两三年来，Keras是一直陪伴在笔者的身边。要不是当初刚掉进这个坑时碰到了Keras这个这么易用的框架，能快速实现我的想法，我也不确定我是否能有毅力坚持下来，毕竟当初是theano、pylearn、caffe、torch等的天下，哪怕在今天它们对我来说仍然像天书一般。 后来为了拓展视野，我也去学习了一段时间的tensorflow，用纯tensorflow写过若干程序，但不管怎样，仍然无法割舍Keras。随着对Keras的了解的深入，尤其是花了一点时间研究过Keras的源码后，我发现Keras并没有大家诟病的那样“欠缺灵活性”。事实上，Keras那精巧的封装，可以让我们轻松实现很多复杂的功能。我越来越感觉，Keras像是一件非常精美的艺术品，充分体现了Keras的开发者们深厚的创作功力。 本文介绍Keras中自定义模型的一些内容，相对而言，这属于Keras进阶的内容，刚入门的朋友请暂时忽略。 层的自定义这里介绍Keras中自定义层及其一些运用技巧。 基本定义方法在Keras中，自定义层的最简单方法是通过Lambda层的方式： 12345from keras.layers import *from keras import backend as Kx_in = Input(shape=(10,))x = Lambda(lambda x: x+2)(x_in) # 对输入加上2 有时候，我们希望区分训练阶段和测试阶段，比如训练阶段给输入加入一些噪声，而测试阶段则去掉噪声，这需要用K.in_train_phase实现，比如 12345678def add_noise_in_train(x): x_ = x + K.random_normal(shape=K.shape(x)) # 加上标准高斯噪声 return K.in_train_phase(x_, x)x_in = Input(shape=(10,))x = Lambda(add_noise_in_train)(x_in) # 训练阶段加入高斯噪声，测试阶段去掉 当然，Lambda层仅仅适用于不需要增加训练参数的情形，如果想要实现的功能需要往模型新增参数，那么就必须要用到自定义Layer了。其实这也不复杂，相比于Lambda层只不过代码多了几行，官方文章已经写得很清楚了： https://keras.io/layers/writing-your-own-keras-layers/ 这里把它页面上的例子搬过来： 123456789101112131415161718192021class MyLayer(Layer): def __init__(self, output_dim, **kwargs): self.output_dim = output_dim # 可以自定义一些属性，方便调用 super(MyLayer, self).__init__(**kwargs) # 必须 def build(self, input_shape): # 添加可训练参数 self.kernel = self.add_weight(name=&apos;kernel&apos;, shape=(input_shape[1], self.output_dim), initializer=&apos;uniform&apos;, trainable=True) def call(self, x): # 定义功能，相当于Lambda层的功能函数 return K.dot(x, self.kernel) def compute_output_shape(self, input_shape): # 计算输出形状，如果输入和输出形状一致，那么可以省略，否则最好加上 return (input_shape[0], self.output_dim) 双输出的层平时我们碰到的所有层，几乎都是单输出的，包括Keras中自带的所有层，都是一个或者多个输入，然后返回一个结果输出的。那么Keras可不可以定义双输出的层呢？答案是可以，但要明确定义好output_shape，比如下面这个层，简单地将输入切开分两半，并且同时返回。 1234567891011121314151617class SplitVector(Layer): def __init__(self, **kwargs): super(SplitVector, self).__init__(**kwargs) def call(self, inputs): # 按第二个维度对tensor进行切片，返回一个list in_dim = K.int_shape(inputs)[-1] return [inputs[:, :in_dim//2], inputs[:, in_dim//2:]] def compute_output_shape(self, input_shape): # output_shape也要是对应的list in_dim = input_shape[-1] return [(None, in_dim//2), (None, in_dim-in_dim//2)]x1, x2 = SplitVector()(x_in) # 使用方法 层与 loss 的结合有了《Keras中自定义复杂的loss函数》一文经验的读者可以知道，Keras中对loss的基本定义是一个输入为y_true和y_pred函数。但在比较复杂的情况下，它不仅仅是预测值和目标值的函数，还可以结合权重进行复杂的运算。 这里再次以center loss为例，介绍一种基于自定义层的写法。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Dense_with_Center_loss(Layer): def __init__(self, output_dim, **kwargs): self.output_dim = output_dim super(Dense_with_Center_loss,self ).__init__(**kwargs) def build(self, input_shape): # 添加可训练参数 self.kernel = self.add_weight(name=&apos;kernel&apos;, shape=(input_shape[1], self.output_dim), initializer=&apos;glorot_normal&apos;, trainable=True) self.bias = self.add_weight(name=&apos;bias&apos;, shape=(self.output_dim,), initializer=&apos;zeros&apos;, trainable=True) self.centers = self.add_weight(name=&apos;centers&apos;, shape=(self.output_dim, input_shape[1]), initializer=&apos;glorot_normal&apos;, trainable=True) def call(self, inputs): # 对于center loss来说，返回结果还是跟Dense的返回结果一致 # 所以还是普通的矩阵乘法加上偏置 self.inputs = inputs return K.dot(inputs, self.kernel) + self.bias def compute_output_shape(self, input_shape): return (input_shape[0], self.output_dim) def loss(self, y_true, y_pred, lamb=0.5): # 定义完整的loss y_true = K.cast(y_true, &apos;int32&apos;) # 保证y_true的dtype为int32 crossentropy = K.sparse_categorical_crossentropy(y_true, y_pred, from_logits=True) centers = K.gather(self.centers, y_true[:, 0]) # 取出样本中心 center_loss = K.sum(K.square(centers - self.inputs), axis=1) # 计算center loss return crossentropy + lamb * center_lossf_size = 2x_in = Input(shape=(784,))f = Dense(f_size)(x_in)dense_center = Dense_with_Center_loss(10)output = dense_center(f)model = Model(x_in, output)model.compile(loss=dense_center.loss, optimizer=&apos;adam&apos;, metrics=[&apos;sparse_categorical_accuracy&apos;])# 这里是y_train是类别的整数id，不用转为one hotmodel.fit(x_train, y_train, epochs=10) 花式回调器除了修改模型，我们还可能在训练过程中做很多事情，比如每个epoch结束后，算一下验证集的指标，保存最优模型，还有可能在多少个epoch后就降低学习率，或者修改正则项参数，等等，这些都可以通过回调器来实现。 回调器官方页：https://keras.io/callbacks/ 保存最优模型在Keras中，根据验证集的指标来保留最优模型，最简便的方法是通过自带的ModelCheckpoint，比如 12345678910checkpoint = ModelCheckpoint(filepath=&apos;./best_model.weights&apos;, monitor=&apos;val_acc&apos;, verbose=1, save_best_only=True)model.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), callbacks=[checkpoint]) 然而，这种方法虽然简单，但是有一个明显的缺点，就是里边的指标是由compile的metrics来确定的，而Keres中自定义一个metric，需要写成张量运算才行，也就是说如果你期望的指标并不能写成张量运算（比如bleu等指标），那么就没法写成一个metric函数了，也就不能用这个方案了。 于是，一个万能的方案就出来了：自己写回调器，爱算什么就算什么。比如： 123456789101112131415161718192021222324252627282930from keras.callbacks import Callbackdef evaluate(): # 评测函数 pred = model.predict(x_test) return np.mean(pred.argmax(axis=1) == y_test) # 爱算啥就算啥# 定义Callback器，计算验证集的acc，并保存最优模型class Evaluate(Callback): def __init__(self): self.accs = [] self.highest = 0. def on_epoch_end(self, epoch, logs=None): acc = evaluate() self.accs.append(acc) if acc &gt;= self.highest: # 保存最优模型权重 self.highest = acc model.save_weights(&apos;best_model.weights&apos;) # 爱运行什么就运行什么 print &apos;acc: %s, highest: %s&apos; % (acc, self.highest)evaluator = Evaluate()model.fit(x_train, y_train, epochs=10, callbacks=[evaluator]) 修改超参数训练过程中还有可能对超参数进行微调，比如最常见的一个需求是根据epoch来调整学习率，这可以简单地通过LearningRateScheduler来实现，它也属于回调器之一。 1234567891011121314151617181920from keras.callbacks import LearningRateSchedulerdef lr_schedule(epoch): # 根据epoch返回不同的学习率 if epoch &lt; 50: lr = 1e-2 elif epoch &lt; 80: lr = 1e-3 else: lr = 1e-4 return lrlr_scheduler = LearningRateScheduler(lr_schedule)model.fit(x_train, y_train, epochs=10, callbacks=[evaluator, lr_scheduler]) 如果是其他超参数呢？比如前面center loss的lamb，或者是类似的正则项。这种情况下，我们需要将lamb设为一个Variable，然后自定义一个回调器来动态赋值。比如当初我定义的一个loss： 1234def mycrossentropy(y_true, y_pred, e=0.1): loss1 = K.categorical_crossentropy(y_true, y_pred) loss2 = K.categorical_crossentropy(K.ones_like(y_pred)/nb_classes, y_pred) return (1-e)*loss1 + e*loss2 如果要动态改变参数e，那么可以改为 1234567891011121314151617181920212223e = K.variable(0.1)def mycrossentropy(y_true, y_pred): loss1 = K.categorical_crossentropy(y_true, y_pred) loss2 = K.categorical_crossentropy(K.ones_like(y_pred)/nb_classes, y_pred) return (1-e)*loss1 + e*loss2model.compile(loss=mycrossentropy, optimizer=&apos;adam&apos;)class callback4e(Callback): def __init__(self, e): self.e = e def on_epoch_end(self, epoch, logs=&#123;&#125;): if epoch &gt; 100: # 100个epoch之后设为0.01 K.set_value(self.e, 0.01)model.fit(x_train, y_train, epochs=10, callbacks=[callback4e(e)]) Keras 无限可能Keras还有很多可圈可点的技巧，比如可以直接利用model.add_loss来灵活地增加loss，还有模型嵌套调用、纯粹作为tensorflow的简单上层api，等等，就不一一整理了，欢迎有疑问、有兴趣的读者留言讨论。 通常我们认为Keras这样的高度封装的库，灵活性是比较欠缺的，但事实上不然。要知道，Keras并不是简单地调用tensorflow或者theano中现成的上层函数，而仅仅是通过backend来封装了一些基本的函数，然后把所有的东西（各种层、优化器等）用自己的backend重写了一遍！也正是如此，它才能支持切换不同的后段。 能做到这个程度，Keras的灵活性是不容置喙的，但是这种灵活性在帮助文档和普通的案例中比较难体现，很多时候要阅读源码，才能感觉到Keras那样的写法已经无可挑剔了。我感觉，用Keras实现复杂的模型，既是一种挑战，又像是一种艺术创作，当你成功时，你就会陶醉于你创造出来的艺术品了。 转载到请包括本文地址： https://www.spaces.ac.cn/archives/5765 Reference Keras Documentation 让Keras更酷一些！Keras模型杂谈]]></content>
      <categories>
        <category>Work</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Keras</tag>
        <tag>深度学习框架</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequence Models - Week 3 - (3)]]></title>
    <url>%2F2018%2F07%2F27%2F55-Sequence-Models-Week-3-3%2F</url>
    <content type="text"><![CDATA[本文是深度学习课程最后一周的最后一部分了，主要介绍的是基于音频数据的语音识别，欢迎大家关注！ Speech recognition - Audio dataSpeech recognitionSequence-to-sequence model 最大的一个发展可以说是语音识别了，在这节中，我们主要讲解如何将 sequence-to-sequence 模型运用到音频数据中做语音识别。 什么是语音识别问题？假设给定一个音频片段 $x$，语音识别问题就是自动识别片段并给出相应的文本 (transcript) $y$。我们看一张黑白音频图，横坐标是时间，纵坐标反映的是空气波动的微小变化，这张音频图的语音是 “the quick brown fox”。那么语音识别系统要做的就是将这段语音输入后，可以输出得到文本。 上图左下角的是同一段音频的光谱图，不同颜色的深度反映了能量的大小。在将音频输入到运行算法中，我们需要进行预处理的步骤。 在过去，语音识别被建立用于通过识别音节来识别单词，比如说一个词由好几个音节组成，然而随着 end-to-end 学习的出现，这种音节表示法就不再需要了，大量的数据集促进了 end-to-end 学习的发展。 那么我们如何建立语音识别系统呢？在这里粗要介绍两种方法，一种是 Attention Model，另一种是 CTC cost。 Attention model for speech recognition Attention model 就像之前讲的一般，根据不同长度的关注词进行关注，从而得到文本输出。 CTC cost for speech recognitionCTC 全称为 Connectionist Temporal Classification，详见参考文献 2。假设还是输入一段音频，“the quick brown fox”，我们使用一种新的网络结构见下图，在这里我们用的是一个单向标准的RNN，实际中双向的 LSTM 和 GRU 单元会更常见。 对于音频数据，其输入的量是很大的，通常输入的时间步远大于输出的时间步。例如，我们刚刚的音频片段是 10 秒钟，而每秒钟都包含100个赫兹信号输入，也就是说10秒钟的音频片段即是1000个输入。然而我们的输出却未必有1000个字母。 CTC 损失函数可让 RNN 生成如下输出： “ttheee_ __ qqq ___“ 简单来说，就是让字母不断重复，从而达到特定的长度。之前再对没被空格分开的重复字母去重。这就是 CTC cost。 Trigger Word Detection对于现在的语音识别系统，越来越多的装置可以根据你的声音进行自动唤醒，这叫触发词检测系统 (Trigger word detection system)。例如，Amazon，Baidu，Apple和Google都有类似的系统，当你叫一声 “Alexa”，Amazon语音识别系统就会自动回应，当你叫一声 “百度你好”，百度语音识别系统也会自动回应。 当前关于 Trigger word detection 的相关研究还在不断发展，因此还没有一致公认的算法。在这里我们仅给出一个算法的例子： 在上图模型中，输入一个个音频片段的音节（光谱特征） $x^{\langle 1 \rangle},x^{\langle 2 \rangle},x^{\langle 3 \rangle}$，而RNN要做的就是根据输入确定目标标签 $y$。当出现 Trigger word 时，标签 $y=1$，否则为 0 。但是这样的效果未必会好，它的一个缺点就是通常 Trigger word 总是很短，而且出现得并不频繁，那么训练集就是十分不平衡，因为标签 0 的数量远远大于 1 。 一个解决办法就是在 Trigger word 出现后的几个词中都标记为 1，固定一定的长度在返回 0。那么就可以增大标签为 1 的比例，使得训练效果更好。 Conclusion哈哈，深度学习最后一门课程结束啦！我们来回顾一下，深度学习每门课程分别学了什么？ Neural Networks and Deep Learning Improving Deep Neural Networks: Hyperparameter tuning, Regularization and Optimization Structuring Machine Learning Projects Convolutional Neural Networks Sequence Model 真心感谢吴恩达老师的真诚付出！制作出这么好的课程分享给大家！深度学习的路上，你并不孤独。希望每一个学习吴恩达老师课程的同学，都能坚持到最后！ Reference Sequence Models - Week 3 Graves et al., 2006. Connectionist Temporal Classification: Labeling unsegmented sequence data with recurrent neural networks]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>Speech Recognition</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequence Models - Week 3 - (2)]]></title>
    <url>%2F2018%2F07%2F23%2F54-Sequence-Models-Week-3-2%2F</url>
    <content type="text"><![CDATA[本节主要讲解 Beam Search 的误差分析和注意力模型，欢迎大家关注！ Various sequence to sequence architecturesError analysis in beam search正如我们上文所说，Beam Search 是启发式搜索算法，它未必一定能输出概率最大的翻译结果。因为它仅仅跟踪于 $B$ 种可能性。那么当 Beam Search 出错了该怎么办？我们可以进行错误分析 (error analysis)，搞清楚到底是 Beam Search的问题，还是RNN模型的问题，并是否值得花时间去改进。 “Jane visite l’Afrique en septembre.” 还是这个例子，假设在我们机器翻译模型的验证集 (development set) 中，给出了人类的翻译结果，记为 $y^\ast $，而算法给出的翻译结果记为 $\hat{y}$ ： Human: “Jane visits Africa in September.” Algorithm: “Jane visited Africa last September.” 显然，人类的翻译结果更好一些，而算法给出的结果尽管没大的错误，但意思已经发生了改变。我们的模型主要包含两个部分，一部分是RNN网络，集合了 encoder network 和 decoder network，另一部分是 beam search 算法。那么到底是哪部分不够好，才导致了这样的结果呢？ Error analysis on beam search在误差分析中，我们分别计算人类和算法两种翻译结果的概率：$P(y^\ast|x)$ 和 $P(\hat{y}|x)$。这是可能存在两种情况： Case 1 : $P(y^\ast|x)&gt;P(\hat{y}|x)$ Beam Search chose $\hat{y}$. But $y^\ast$ attains higher $P(y|x)$. Conclusion: Beam search is at fault. Case 2 : $P(y^\ast|x) \leq P(\hat{y}|x)$ $y^\ast$ is a better translation than $\hat{y}$. But RNN predicted $P(y^\ast|x)&lt;P(\hat{y}|x)$. Conclusion: RNN model is at fault. 我们知道 Beam Search 的目标函数是寻找概率最大的翻译结果，即 $\arg\max_y P(y|x)$。在第一种情况中，当 $P(y^\ast|x)&gt;P(\hat{y}|x)$ 时，Beam Search 却选择了 $\hat{y}$ 的翻译结果，说明 Beam Search没有成功搜索到最优结果，这是来自 Beam Search的误差。 而在第二种情况中，当 $P(y^\ast|x) \leq P(\hat{y}|x)$ 时，由于我们已经知道 $y^\ast$ 的结果优于 $\hat{y}$，更优的结果应该有更大的概率。然而RNN模型却计算得到 $P(y^\ast|x)&lt;P(\hat{y}|x)$，因此这是来自RNN的误差，它没有预测准确。 在这里我们忽略了 Length normalization后的结果，实际上在评估这些概率时，应该考虑 length normalization。对于整个验证集，我们可以进行如下误差分析过程： Human Algorithm $P(y^\ast x)$ $P(\hat{y} x)$ At fault Jane visits Africa in September. Jane visited Africa last September. $2 \times 10^{-10}$ $1 \times 10^{-10}$ B …… …… …… …… R …… …… …… …… B …… …… …… …… R …… …… …… …… R 在表中 At faule 一列，B 表示由 Beam Search 引发的误差，R 表示由 RNN 模型引发的误差。最后，我们分别计算由 B 和由 R 带来误差的比例。如果由 B 带来的误差比例更大，那么我们可以尝试增大 beam width；如果由 R 带来的误差比例更大，那么我们可以对RNN模型进行修改，比如说添加正则项，增大训练集，或换一种网络架构等等。 针对不同问题，使用不同的解决办法，可以更好地提高我们的模型结果。 Bleu Score (optional)对于机器翻译，当前尚存在一些难题。其中之一就是比如说在翻译法语时，可能出现多个同样好的翻译结果。通常我们会采用精确度来评价一个模型的好坏，但当出现多个同样好的结果时如何计算精确度？可以通过 BLEU score来衡量。 Evaluating machine translation假设给定一个法语句子：“Le chat est sur le tapis.”，那么可以给出以下两种人类的翻译结果： Reference 1: The cat is on the mat. Reference 2: There is a cat on the mat. 这两种翻译都十分恰当。BLEU score算法要做的是给定一个机器生成的翻译，它自动计算分值去评价这个机器翻译的好坏。如果机器生成的翻译越接近人类的翻译水平，那么 BLEU score 越高。 BLEU，全称 bilingual evaluation understudy，由 Papineni等人提出，详见参考文献 2。Understudy，在电影界中指的是替角的意思。BLEU的意思就是你可以让人类评估者对机器翻译系统进行评估，也可以使用 BLEU score，它就像是替代的评估方式。 BLEU score计算的是机器生成翻译的词是否出现在人类翻译中，即两种翻译的匹配度，那么人类翻译分为两部分，一为验证集，一为测试集。假设机器翻译的结果为： MT output : the the the the the the the 机器翻译包含了7个 “the”，显然是个很糟糕的翻译。但是其每个词 “the” 都在 Reference 1和 Reference 2 出现过，那么准确率为 $\frac{7}{7}$ ，很高。这样的准确率计算方式并不好。因此我们使用修正的准确率，因为每个词 “the” 在Reference 1 和 Reference 2中出现的次数分别为2和1，最高出现的次数为2，修正准确率取的是出现最多的次数，而不是所有的次数，即为 $\frac{2}{7}$。在这里，分母为词 “the” 出现在机器翻译句中出现的总次数，分子为词 “the” 出现在人类参考句中出现最多的总次数。 我们刚刚计算的是单个词的准确率，但显然我们想要知道的是所有词组句子总的准确率，那么就要计算 Bleu score 了。 Bleu score on bigramsbigrams 指的是临近的词组，那么接下来bigrams 的Bleu score定义如下。还是选择之前的例子： Reference 1: The cat is on the mat. Reference 2: There is a cat on the mat. MT output: The cat the cat on the mat. 假设机器翻译输出了一个稍微比较好的翻译 (MT output)，那么依次的 bigrams 分别为： Count Countclip “the cat” 2 1 “cat the” 1 0 “cat on” 1 1 “on the” 1 1 “the mat” 1 1 其中，表中“Count”列指的是各个 bigrams 在MT中出现的次数，而“Countclip”列指的是各个 bigrams 在 Reference 1和 Reference 2 中出现的次数。那么 bigrams 的精确率 (Bleu score) 就是 $\frac{4}{6}$，即两列的和之比，分子为“Countclip”列之和，分母为“Count”列之和。 Bleu score on unigrams“unigrams”指的是单个词，我们把关于 unigrams 的精确率记为 $P_1$，$P$ 表示精确率，下标 $1$ 表示单个词 unigrams。 P_1=\frac{\sum_{unigram \in \hat{y}}CountClip(unigram)}{\sum_{unigram \in \hat{y}}Count(unigram)}进一步推广到 n-grams，也是同理，其精确率 $P_n$ 为： P_n=\frac{\sum_{n\_grams \in \hat{y}}CountClip(n\_grams)}{\sum_{n\_grams \in \hat{y}}Count(n\_grams)}Bleu details$p_n$ = Bleu score on n-grams only 当MT的输出和Reference 的翻译完全一样时，那么Bleu score就等于1。我们将多个精确率结合起来，计算最后的 Bleu score： Combined Bleu score: $BP \cdot \exp({\frac{1}{4} \sum^4_{n=1}p_n}) $ 其中 BP 是一个惩罚项，表示 brevity penalty。因为当我们的输出翻译越短时，更容易得到更高的精确率，然而我们未必需要那么短的输出，那么 BP 就是针对输出翻译太短的一个惩罚项。BP惩罚项具体如下： BP= \left\{ \begin{aligned} 1 \qquad, \ & if \ MT\_output\_length > reference\_output\_length \\ exp(\frac{1-MT\_output\_length}{reference\_output\_length}) ,\ & otherwise \end{aligned} \right.当机器输出的长度大于人类翻译长度时，$BP=1$，否则小于1。 Bleu score 通常用于评价许多系统，如文本生成、机器翻译和图片配标题等，在深度学习中是一个非常有用的指标。 Attention Model Intuition注意力模型，在深度学习中是一个影响力很大的思想，它对 RNN 中的 Encoder-Decoder 架构做了一定的改进，使得效果更为显著。我们这节主要讲它是如何works 的？ 给定一个很长的法语句子如下： Jane s’est rendue en Afrique en septembre dernier, a a pprecie la culture et a rencontre beaucoup de gens merveilleux; elle est revenue en parlant comment son voyage etait merveilleux, et elle me tente d’y aller aussi. 在RNN中，会将上面的法语完全输入到 encoder network 中，记忆储存整个句子并传输到激活值中，再到 decoder network 中生成英语翻译输出： Jane went to Africa last September, and enjoyed the culture and met many wonderful people; she came back raving about how wonderful her trip was, and is tempting me to go too. 然而，人类并不是这么翻译句子的，通常人们会先读一部分，翻译一部分，再接着读一部分翻译一部分，因为人们很难短时间记住一个很长的句子再对它进行翻译。因此对于 Encoder-Decoder结构来说，在短句中的翻译结果相对于长句中翻译结果，总是有更高的 Bleu score。注意力模型在翻译句子中会更像人们的表现，即一次关注句子的一部分进行翻译。 上图给出了 Attention Model 的架构，但是有点乱，我会一步一步慢慢解释，它是由 Dimitri 等人提出来的，详见参考文献 3 。 我们用一个较简短的法语句子来解释，“jane visite l’Afrique en septembre”，我们将其输入到一个双向RNN (bidirectional RNN)，先经过前向传递，而后经过反向传递，最后在传递到激活值 $S$ 中生成输出。 那么关键来了，在生成第一个输出中，应该关注于法语句子的哪一部份？显然主要应该关注于第一个输入单词，其次再关注临近的几个词，没必要完全关注整个句子。那么对于临近关注的几个词，我们分别计算一个关注权重 (attention weight)，即 $\alpha^{\langle t,t’ \rangle}$。其中，$t$ 为第 $t$ 个生成的输出，$t’$ 为第 $t’$ 个输入词。例如说 $\alpha^{\langle 1,2 \rangle}$，它指的是生成第 1 个输出 Jane 时需要对第 2 个输入词 “visite” 关注的程度。依次在生成每个输出时，都存在对临近输入词的关注权重 $\alpha$，与输入词形成 $C$，再传递到激活值 $S$ 中得到输出。以此类推，直到最后输出 EOS，结束整个句子的翻译。 大概的步骤就是这样，在下节中我们会给出更为详细的公式解释。 Attention ModelAttention model上节中我们看到注意力模型其在生成翻译时，的确更像人类一样，不断关注输入的一小部分来翻译。那么这节我们对给出更多关注注意力模型的具体细节。 正如我们之前的架构，首先是双向RNN，当然可以使用 GRU或LSTM单元，LSTM会更常用一些。在双向 RNN中，每一个时间步总会有一个前向一个后向的传播，我们用 $a^{\langle t’ \rangle}$ 表示时间步 $t’$ 下第 $t’$ 个输入词的特征向量，那么 $a^{\langle t’ \rangle}=(\overrightarrow{a}^{\langle t’ \rangle},\overleftarrow{a}^{\langle t’ \rangle})$。将 $a^{\langle t’ \rangle}$ 与关注权重 $\alpha^{\langle t,t’ \rangle}$ 结合，得到 $c^{\langle t \rangle}$，输入到激活层得 $s^{\langle t \rangle}$，最后输出预测词 $y^{\langle t \rangle}$。我们以第1个输出 $y^{\langle 1 \rangle}$ 为例： a^{\langle t' \rangle}=(\overrightarrow{a}^{\langle t' \rangle},\overleftarrow{a}^{\langle t' \rangle}) \\ \sum_{t'} \alpha^{\langle 1, t' \rangle}=1 \\ c^{\langle 1 \rangle}=\sum_{t'} \alpha^{\langle 1, t' \rangle}a^{\langle t' \rangle}在这里，对于每个输出的关注权重之和为1，如 $\sum_{t’} \alpha^{\langle 1,t’ \rangle}=1$ . 我们从整个神经网络架构看，不看下面的双向 RNN 部分，而看上面部分从 $c​$ 输入到 $y​$ 输出，就是一个标准的RNN。 Computing attention $\alpha^{\langle t,t’ \rangle}$ $\alpha^{\langle t,t’ \rangle}$ = amount of attention $y^{\langle t \rangle}$ should pay to $a^{\langle t’ \rangle}$ 我们已经知道了 $\alpha^{\langle t,t’ \rangle}$ 的含义，那么其计算如下： \alpha^{\langle t,t' \rangle}=\frac{\exp(e^{\langle t,t' \rangle})}{\sum^{T_x}_{t'=1}\exp(e^{\langle t,t' \rangle})}$e^{\langle t,t’ \rangle}$ 为参数，我们可以通过上一时间步的输出激活值 $s^{\langle t-1 \rangle}$ 和当前时间步的输入激活值 $a^{\langle t’ \rangle}$ 来得到，即将它们同时输入到一个小型隐含层，通过 gradient descent 得到 $e^{\langle t,t’ \rangle}$，见上图左下角。 整个网络架构图见上图右下角，这个架构图更清晰。Attention Model 的一个缺点就是想要运行这个网络需要花上成倍的时间和成本。如果你的输入长度为 $T_x$，而输出长度为 $T_y$，那么所有参数的量即为 $T_x \times T_y$，计算成本相当大。 我们介绍了注意力模型在机器翻译的应用，它同样可以用在 image captioning 上。 Attention examples在本周课程的编程练习中，机器翻译问题相对较难，我们可以尝试用 Attention 来解决 Date normalization 问题。 July 20th 1969 $\rightarrow$ 1969 - 07 - 20 23 April, 2564 $\rightarrow$ 1564 - 04 -23 我们将不同格式的日期输入进行转换，然后输出统一格式的日期。这个问题将在这周的练习中解决。 那么以上就是关于 Attention Model 的相关内容，需要更详细内容可阅读参考文献。 Reference Sequence Models - Week 3 Papineni et al., 2002. Bleu: A method for a automatic evaluation of machine translation Bahdanau et al., 2014. Neural machine translation by jointly learning to align and translate Xu et al., 2015. Show attention and tell: neural image caption generation with visual attention]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>Attention Model</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequence Models - Week 3 - (1)]]></title>
    <url>%2F2018%2F07%2F21%2F53-Sequence-Models-week-3-1%2F</url>
    <content type="text"><![CDATA[这周是深度学习序列模型的最后一周课程，本文主要讲述多种序列进序列出的模型架构，欢迎大家关注！ Various sequence to sequence architecturesBasic Modelssequence-to-sequence 模型对机器翻译、语音识别等应用方面是十分重要的，我们首先从sequence-to-sequence 的基本模型开始。 假设你想要输入一句法语：“Jane visite l’Afrique en septembre”，并将其翻译成英语：“Jane is visiting Africa in September.” 那么法语作为输入，每个输入单词分别记为：$x^{\langle 1 \rangle}$ 至 $x^{\langle 5 \rangle}$ ，而英语作为输出，每个输出单词分别记为：$y^{\langle 1 \rangle}$ 至 $y^{\langle 6 \rangle}$。 我们构建的网络如上图，是RNN，在RNN的每个单元中，可以是GRU，也可以是LSTM，每次输入一个法语单词。将整句话输完之后，依次输出每个预测的词，并将前一个预测出的词作为下一次预测的输入。整个网络中，前面依次输入部分是编码网络 (encoder network)，而后面依次预测部分是解码网络 (decoder network)，通过对法语句子进行编码，再解码生成对应的英语翻译。这个模型十分有效，在参考文献 2、3 有更详细的介绍。 另外还有一个 sequence-to-sequence 模型的应用十分常见，就是 Image captioning，即给定一幅图，对这幅图起标题。对于这个问题，解决方式和前面很相似，但这里是将 CNN 与 RNN 结合了起来。 模型如上图，我们输入一张图片，构建 AlexNet 结构，去掉 Softmax 层，直接与RNN 连接，进行序列预测。这个网络在多篇文献中都有出现，详见参考文献 4~6。 这就是关于 sequence-to-sequence 模型简单的例子介绍，我们在下节中会更详细地讲解关于模型的细节和推导。 Picking the most likely sentenceMachine translation as building a conditional language model和本课程第一周讲的语言模型相比，sequence-to-sequence机器翻译模型有很多相似的地方，但也有一些不同，我们可以将其认为是条件语言模型 (conditional language model)。 由上图可见，在语言模型中，输入 $x^{\langle 1 \rangle}$ 为零向量，接下来依次的输入$x^{\langle 2 \rangle}, x^{\langle 3 \rangle},\dots$ 等都是前一个生成的预测输出，我们最终计算的是预测句子的概率 $P(y^{\langle 1 \rangle},\cdots,y^{\langle T_y \rangle})$。 而在机器翻译模型中，主要包括两部分，绿色部分为编码网络 (encoder network)，紫色部分为解码网络 (decoder network)，解码网络与语言模型相同，而编码网络不再是简单的输入零向量，而是输入文本序列。 这就是其称为条件语言模型的原因，因为它是根据前面输入的 $x^{\langle 1 \rangle} $ 至 $x^{\langle T_x \rangle} $ 作为前提条件去计算输出 $y^{\langle 1 \rangle} $ 至 $y^{\langle T_y \rangle} $ 的概率，即 $P(y^{\langle 1 \rangle},\cdots,y^{\langle T_y \rangle}|x^{\langle 1 \rangle},\dots,x^{\langle T_x \rangle})$ 。这就是语言模型和机器翻译模型的区别。 Finding the most likely translation通过机器翻译模型，输入法语句子，模型就会输出不同的英语翻译的概率。这时，随机抽取输出的结果不是一个好的选择。当你从 $P(y^{\langle 1 \rangle},\cdots,y^{\langle T_y \rangle}|x)$ 的分布中随机抽取单词，很可能你会得到以下不同的结果： Jane is visiting Africa in September. Jane is going to be visiting Africa in September. In september, Jane will visit Africa. Her Africa friend welcomed Jane in September. 最好的结果是第一个翻译，尽管其余翻译也不算太差，但显然并不是平常人们说话的习惯。因此我们最好不要以概率分布进行随机抽样的方式得到翻译结果，而是选择最大概率的翻译结果： \arg\max _{ y^{\langle 1 \rangle} ,\dots, y^{\langle T_y \rangle} }P(y^{\langle 1 \rangle},\cdots,y^{\langle T_y \rangle}|x)因此我们要干的就是通过算法找出使得 $P(y^{\langle 1 \rangle},\cdots,y^{\langle T_y \rangle}|x)$ 最大的 $y$，关于这个问题最常用的算法就是 Beam Search。在课程中还提到一种方法，贪婪搜索 (greedy search)，它又有什么优缺点呢？ Why not a greedy search?根据条件语言模型，在生成第一个单词中，贪婪搜索会选择可能性最大的一个，随后在生成第二个单词中，贪婪搜索继续选择可能性最大的一个，以此类推，直到最后一个单词。 然而我们想要的是从所有完整的句子中选择可能性最大的，而非依次从每个单词中选择可能性最大的，因为这未必凑效，举个例子： Jane is visiting Africa in September. Jane is going to be visiting Africa in September. 相对于第1个翻译，使用贪婪搜索会更可能得到第2个翻译结果。不看前两个单词，从第3个单词开始，在英语中，“going” 是十分常见的，它出现的概率比 “visiting” 要大，因此可能得到第2个不太恰当的翻译结果。 英文单词的总量是很大的，如果你的字典中有10,000个单词，而模型翻译的句子有10个词那么长，那么就有10,000的十次方种可能性，因此也不可能将它们的概率全部计算出来取最大的。尽管贪婪搜索在概率计算上比较方便，只要选择每个单词中最大概率的一个即可，但结果不一定好。因此，我们需要一种更好的搜索方式。 Beam SearchBeam Search与贪婪搜索相似，但它需要一个超参数 $B$，也称为 Beam width，首先我们指定 $B=3$。 贪婪搜索在生成的第一个单词中，挑选出可能性最大的一个。而 Beam Search 在生成的第一个单词中，可以挑选出多个可能性最大的单词，具体个数由超参数 $B$ 指定。 在 Beam Search的第1步中，将法语句子输入到 encoder network 中，到 decoder network 时经过 softmax 层输出 $y^{\langle 1 \rangle}$，即10,000个词各自的概率。假设出现概率最大的三个词分别为：“in”, “jane”, “september” 。Beam Search 的第1步就是将这三个出现概率最大的词记住。 其次在第2步中，分别构建3个网络，针对上一步得到的三个词去计算第二个输出 $y^{\langle 2 \rangle}$ 出现单词的概率： P(y^{\langle 1 \rangle},y^{\langle 2 \rangle}|x)=P(y^{\langle 1 \rangle}|x)\cdot P(y^{\langle 2 \rangle}|x,y^{\langle 1 \rangle})那么，第1步的三个词分别对应着第2步中各自的10,000个单词，因此总共存在30,000种可能，我们继续从这30,000种可能中选择最大概率的3种单词组合。假设在第2步中得到的最大概率的3种单词组合分别为：“in september”, “jane in”, “jane visits” 。注意，这三个组合都是从第1步中的前两个单词 “in” 和 “jane” 处得到的，那么第1步中的 “september” 之后出现的单词组合就不再考虑了。那么 Beam Search 将这三个组合记住，继续输入到第3步中。 第3步与第2步相似，根据前一步的3个单词组合，计算第3个输出 $y^{\langle 3 \rangle}$ 的所有单词组合的概率，同样存在 30,000 种可能，继续挑选最大概率的3种可能。假设在这一步中我们得到：“in september jane”, “jane is visiting”, “jane visits africa” 。 依次类推，直到最后输出最大概率的完整翻译为止： “jane visits africa in september. &lt;EOS&gt;“ Beam Search 能够得到的翻译结果，相对来说会比贪婪搜索更为精确，贪婪搜索实际上就是 Beam Search的一种特殊情况，即超参数 $B=1$。另外还有一些细节可以使 Beam Search 效果更好，在下节讲述。 Refinements to Beam SearchLength normalizationLength normalizaiton 可以是 Beam Search 算法得到更好的结果，我们来看看。首先，Beam Search 的目标是要使如下概率最大化： \arg \max_y \prod^{T_y}_{t=1} P(y^{\langle t \rangle}|x,y^{\langle 1 \rangle},\dots,y^{\langle t-1 \rangle})事实上就是众多条件概率的累乘，根据全概率公式： P(y^{\langle 1 \rangle}\dots,y^{\langle T_y \rangle}|x)=P(y^{\langle 1 \rangle}|x)P(y^{\langle 2 \rangle}|x,y^{\langle 1 \rangle}) \cdots P(y^{\langle t \rangle}|x,y^{\langle 1 \rangle},\dots,y^{\langle t-1 \rangle})由于这些概率都是小于1的，那么多个概率的累乘会变得更小，其小数部分不利于计算机的精确储存。因此我们对目标函数取对数（对数函数为单调递增函数，对取最大化目标函数无影响）： \arg \max_y \sum^{T_y}_{t=1} \log P(y^{\langle t \rangle}|x,y^{\langle 1 \rangle},\dots,y^{\langle t-1 \rangle})然而有一个问题就是对于累乘的目标函数，假设你的句子很长，那么得到的概率会很小，因为连乘了很多项小于1的概率。显然这对结果会造成一定的影响，因为目标函数是取最大化的概率，那么目标往往会更倾向于较短的翻译（更短的输出），因为不需要连乘太多项，从而增大一定的概率，但是这样的翻译结果却未必是好的。 而对于累积的目标函数也同样，由于概率都是小于1的，那么取对数之后都将变为负数，且概率越小，负得越大。有一个办法可以尝试，那就是对目标函数进行标准化： \frac{1}{T_y^\alpha} \sum^{T_y}_{t=1} \log P(y^{\langle t \rangle}|x,y^{\langle 1 \rangle},\dots,y^{\langle t-1 \rangle})通过标准化，可以在一定程度上减少输出长翻译所带来的惩罚。在上式标准化中，存在一个超参数 $\alpha$，通常会取0.7。若 $\alpha=1$，那就是根据输出长度 $T_y$ 进行的标准化；若 $\alpha=0$，那么就是完全没标准化了。因此可以对 $\alpha$ 进行调参取得更好的结果。 在这里，输出翻译的长度 $T_y$ 相当于进行 Beam Search的步数。也就是说，Beam Search 在每一步搜索出的三种可能中都多加一个词的长度，直到搜索出一个完整的翻译句子。最终最大概率的结果称为 normalized log likelihood objective。 Beam search discussion最后还有一个细节，那就是如何选择超参数 $B$ ？$B$ 越大，说明考虑的可能性越多，你搜索到的结果也会更好，然而计算成本也很大，计算速度会变慢。$B$ 越小，得到的结果可能差一点，但是考虑的可能性小了，计算速度会更快。 我们之前采用了 $B=3$，事实上这是比较小的，通常会采取 $B=10$ 的情况。在某些文章，甚至会采用 $B$ 从 1000 至 3000 的情况。 Unlike exact search algorithms like BFS (Breadth First Search) or DFS (Depth First Search), Beam Search runs faster but is not guaranteed to find exact maximum for $\arg \max_yP(y|x)$. Reference Sequence Models - Week 3 Sutskever et al., 2014. Sequence to sequence learning with neural networks Cho et al., 2014. Learning phrase representations using RNN encoder-decoder for statistic machine translation Mao et al., 2014. Deep captioning with multimodal recurrent neural networks Vinyals et al., 2014. Show and tell: Neural image caption generator Karpathy and Fei Fei, 2015. Deep visual- semantic alignments for image descriptions]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>学习笔记</tag>
        <tag>Neural Network</tag>
        <tag>Sequence Models</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequence Models - Week 2 - (3)]]></title>
    <url>%2F2018%2F07%2F20%2F52-Sequence-Models-Week-2-3%2F</url>
    <content type="text"><![CDATA[本文主要讲解一下关于词嵌入的应用，如语义分类 (Sentiment Classification)、词嵌入的误差修正 (Debiasing word embeddings)，欢迎大家关注！ Applications using Word EmbeddingsSentiment Classification情感分类是指根据某段文本，分析人们对文本中所提及内容是否喜欢并做出分类的学习任务，这是NLP中十分基础而重要的一部分。当前这项任务的一个挑战就是难以获取大量做好标签的训练集。然而通过词嵌入算法，即使标记好的训练集样本量不大，同样可以建立一个好的情感分类器。 输入 $x$ 标签 $y$ The dessert is excellent. $\bigstar\bigstar\bigstar\bigstar$ Service was quite slow. $\bigstar\bigstar$ Good for a quick meal, but nothing special. $\bigstar\bigstar\bigstar$ Completely lacking in good taste, good service, and good ambience $\bigstar$ 举个例子，见上表关于餐厅的评价，收集顾客的评语并做好文本标签进行训练，那么就可以跟踪顾客对餐厅的满意度了。然而，当评语太多时，很难人工对这些评语做情感标签。而对于一个情感分类任务，训练集通常应包含10,000至100,000的评语集。这就造成了情感分类任务的困难，缺乏大量标签好的样本数据。 我们刚刚说了词嵌入能够解决这个问题，那么词嵌入是如何做的呢？ 见上图，词嵌入的模型架构我们已经很熟悉了。首先嵌入矩阵是提前根据算法学习好的，那么通过嵌入矩阵将每个词的one-hot向量转化为嵌入向量后，将这些向量进行求和 (Sum)或均值化 (Average)，最后输入 softmax 层进行分类，分类的结果有五种，分别从一星至五星。 然而，这个模型还是存在一些缺陷，那就是它忽略了词的顺序。例如说上表中的最后一句评语，“Completely lacking in good taste, good service, and good ambience”。其中，“good” 出现了多次，如果我们仅仅对这些词的嵌入向量进行求和或求平均，那么如此多的 “good” 对最终结果造成的影响是很大的，很可能情感分类器会将这句话认为是一句好的评价，而事实上并不好。 解决办法是采用RNN模型进行训练，如图： RNN会更好地考虑到词的顺序，从而捕捉到 “lacking” 的特征，并判断这是负面的评价。 假设句子修改了一下，变为：“Completely absent of good taste, good service, and good ambience”. 如果你的训练集中不存在 “absent” 这个词，但是只要出现在词嵌入矩阵的语料库中进行学习过，就能够对该词训练出一个很好的嵌入向量。因此，训练集样本少对于词嵌入来说并不是一个太大的问题。 Debiasing word embeddings词嵌入算法在NLP中起到了很大的作用，然而我们必须保证它尽可能精确，而不受性别、种族等特征上的一些各种形式的偏差。 什么是特征上的偏差？这不是我们在机器学习中经常讲到的 bias and variance。打个比方，我们说男对女，类似于国王对皇后。那么男对程序员，意味着女对什么呢？ Bolukbasi 的文章中（见参考文献 2）发现一个训练好的词嵌入算法可能会输出 “Man is to computer programmer as woman is to homemaker” 的结果，这结果令人惊异，给人一种对性别特征不好的刻板印象。另外还存在 “Father is to doctor as mother is to nurse” 的例子，这些就称为在性别、种族、年龄、甚至性取向等特征上的训练偏差。 然而随着机器学习算法在生活中越来越普及，如网上求职、贷款等都可能需要算法做出决策，因此我们必须要让算法尽可能减少在这些特征上的偏差，因为每个人都是平等的，不管收入还是地位的高低，每个人都应该有同等的机会，不能受刻板印象的影响。 Addressing bias in word embeddings假设我们已经训练好了词嵌入矩阵，那么消除偏差主要有三个步骤： Identify bias direction. Neutralize: For every word that is not definitional, project to get rid of bias. Equalize pairs. 在第一步中，主要通过嵌入向量之间的差来确定偏差的方向，例如计算 $e_{he}-e_{she}$，$e_{male}-e_{female}$ 等嵌入向量之间的差值，然后求均值，从而确定 gender 特征的方向。确定了 bias direction 之后，其余的与该方向不相关的方向称为 non-bias direction，在non-bias direction中包含其余299个特征维度的子空间。bias direction 可能高于一维，且不一定采用求均值的方式，这里都是简化进行描述，实际上在参考文献 2 使用了更为复杂的算法：SVU (a singular value decomposition)，主要是采用了主成分方法的思想。 第二步是中立化 (Neutraliza)，通常大部分词语是包含了性别的定义的，如 “grandfather”, “grandmother”, “girl”, “boy”, “she”, “he” 等，然而对于某些存在刻板印象而又不隐含性别定义的词，如 “doctor”, “babysitter” 等，我们必须中性化，避免产生特征偏差。进行中性化，即将词嵌入向量沿着 bias direction 正交的方向进行投影即可。投影公式： e^{bias\_component}=\frac{e \cdot g}{\lVert g \rVert ^2_2} *g \\ e^{debiased}=e-e^{bias\_component}在第二步中存在一个细节，那就是如何决定哪些词需要中性化？显然，像 “doctor” 就很有必要中性化。而像 “beard” 这类词就不需要，因为男性相对于女性更有可能出现 “beard”。在参考文献中，作者训练了一个分类器用于辨别哪些词是隐含 bias direction 的，从而做出相应的判断。事实上在英语中，大部分的词都是没有隐含 bias direction 的。 最后一个步骤为 equalizaiton。举个例子，从空间距离来讲，“grandmother” 与 “babysitter” 的距离（或相似度）可能小于 （高于）“grandfather” 与 “babysitter” ，可能这就存在了刻板印象，因为 “grandfather” 同样可以是一个 “babysitter”，因此我们必须让“grandmother” 和 “babysitter” 的距离与“grandfather” 和 “babysitter” 的距离相等，将它们在空间上的点距离同等化。同理，还有许多对类似的词需要进行距离均等化处理，如 “actor-actress”, “boy-girl”, “sorority-fraternity”, “girlhood-boyhood”, “sister-brother”, “niece-nephew”, “daughter-son” 等等。 在这里给出equalization的计算步骤，在参考文献中，有更为详细的推导。 \mu = \frac{e_{w1}+e_{w2}}{2} \\ \mu_B = \frac{\mu \cdot bias\_axis}{\lVert bias\_axis \rVert^2_2}* bias\_axis \\ \mu_{\perp}=\mu-\mu_B \\ e_{w1B} = \frac{e_{w1} \cdot bias\_axis}{\lVert bias\_axis \rVert^2_2}* bias\_axis \\ e_{w2B} = \frac{e_{w2} \cdot bias\_axis}{\lVert bias\_axis \rVert^2_2}* bias\_axis \\ e^{corrected}_{w1B}=\sqrt{\lvert 1- \lVert \mu_{\perp} \rVert^2_2 \rvert} * \frac{e_{w1B-\mu_B}}{\lVert (e_{w1}-\mu_{\perp})-\mu_B\rVert_2} \\ e^{corrected}_{w2B}=\sqrt{\lvert 1- \lVert \mu_{\perp} \rVert^2_2 \rvert} * \frac{e_{w2B-\mu_B}}{\lVert (e_{w2}-\mu_{\perp})-\mu_B\rVert_2} \\ e_1=e^{corrected}_{w1B}+\mu_{\perp} \\ e_2=e^{corrected}_{w2B}+\mu_{\perp}在上面的式子中， $\lvert \cdot \rvert$ 为绝对值，而$\lVert \cdot \rVert_2$ 为范数。 以上就是消除特征偏差的方法步骤。 Reference Sequence Models - Week 2 Bolukbasi et al., 2016. Man is to computer programmer as woman is to homemaker? Debiasing word embeddigns]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>Word Embeddings</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequence Models - Week 2 - (2)]]></title>
    <url>%2F2018%2F07%2F15%2F51-Sequence-Models-Week-2-2%2F</url>
    <content type="text"><![CDATA[本文是深度学习第5门课程第二周的第2部分，主要讲解关于词嵌入学习的两种方法，分别为 Word2vec 和 Glove，欢迎大家关注！ Learning Word Embeddings: Word2vec &amp; GloveLearning word embeddingsNeural language model这节主要介绍词嵌入学习中得到具体算法，在深度学习应用到词嵌入学习的理论发展中，人们是从较复杂的算法开始的。然而，慢慢地，研究者们发展出更多更简单的算法，尤其在大型数据集中也可以取得同样好的效果。 这些算法到现在仍是主流，但由于太简单，反而让人觉得十分奇妙，因此我们从比较复杂的算法开始介绍起，然后再过渡到简单的算法，这样可以更好地解释为什么简单的算法也能实现很好的结果。 我们还是从例子开始，假设输入一个句子：“I want a glass of orange __.”，需要预测出句子空格中的词。在这里，根据我们之前提到的10,000 长度的词汇表，我们分别记下每个词的序号。 I want a glass of orange 4343 9665 1 3852 6163 6257 接下来我们要讲的思想来源于 Bengio，详见参考文献 2。首先，对每个词构建 one-hot 向量 $O$ ，维度为10,000。其次，对参数矩阵（嵌入矩阵）$E$ 与每个词的 one-hot 向量求点积，得到每个词的嵌入向量 $e$ ，维度为300。最后将所有词的嵌入向量 $e$ 都输入到神经网络中，并进行 softmax 预测。 在神经网络的隐含层和 softmax 层中，都包含其各自的参数 $w$ 和 $b$ 。在输入到隐含层之前，输入有6个词，每个词的维度为300，将它们堆起来，形成一个维度为 1800 的向量，再输入到隐含层。 然而，通常会选择一个固定的历史窗宽。什么意思呢？也就是说，当我们想要预测下一个词时，总是以其前面连续的几个词作为输入。前面词的数量是一个超参数，由人为决定。这样子不管句子长短，输入到隐含层的向量维度都是相等的了，因此我们只固定根据前面某几个词进行预测。假设总是根据前面4个词进行预测，那么其输入到神经网络隐含层的向量维度就是1200。 在这个模型中，除了后面隐含层和softmax层的参数外，嵌入矩阵 $E$ 中的每个元素都是参数，都需要进行训练，从而使训练效果最优，即训练集与预测的拟合程度越高。 Other context/target pairs下面我们对算法进行简化，比较其他方式的算法。我们举一个更为复杂的句子： “I want a glass of orange juice to go along with my cereal.” 其中，要预测的目标单词是 “juice”。我们可以根据以下几种背景词进行预测： Context: Last 4 words 4 words on left &amp; right Last 1 word Nearby 1 word 第1种背景词是根据目标单词的前4个单词进行预测，第2种背景词是根据目标单词的左右各4个单词进行预测，后面两种背景更为简单，第3种直接根据目标单词的前1个单词进行预测，即 “orange”，第4种背景根据目标单词的附近1个单词进行预测，比如说 “glass”。第4种背景的结果出奇得好。 在下节中，我们会对这些算法进行更加严谨地说明。 Word2vec本节主要参考 Tomas Mikolov 等人的研究，详见参考文献 3。 Skip-grams首先我们从 skip-grams 模型开始介绍，还是以上面的句子为例： “I want a glass of orange juice to go along with my cereal.” 在这个模型中，我们要对背景词和目标词进行训练，背景词的选择有多种方法，上节中我们就讲了这个。在这里，我随机从句子中选择一个词作为背景词。假设我抽到了 “orange” 作为背景词，接下来要选择的是目标词，根据背景词周围的宽度进行选择，比如说背景词前后5个词或10个词的宽度均可。可能你恰恰选择了 “orange” ，或者 “glass” 或 “my” 等都可以。 那么我们的问题就是给定背景词，需要预测下一个词到底是其前后窗宽为10的哪个词。这不是一个简单的学习问题，因为背景词前后窗宽为10，有太多的可能。但是我们这个问题的目的不是为了准确预测出下一个词，而是为了训练出一个更好的词嵌入矩阵。 我们把背景词标记为 $c$，把目标词标记为 $t$，那么模型如下： O_c \rightarrow E \rightarrow e_c \rightarrow softmax \ unit \rightarrow \hat{y}在 softmax 层中，给定背景词，每个目标词出现的概率为： Softmax:p(t|c)=\frac{e^{\theta^T_t e_c}}{\sum^{10000}_{j=1}e^{\theta^T_j e_c}}其中，$\theta_t$ 是与输出 $t$ 相关联的参数。损失函数为： L(\hat{y},y)=-\sum^{10000}_{i=1}y_i \log \hat{y}_i在这里，$\hat{y}$ 和 $y$ 都是 one-hot 向量，$y$ 为目标值，$\hat{y}$ 为预测值。 这就是 skip-gram模型，通过输入一个背景词，可以跳过中间多个词去预测其他词。 Problems with softmax classification在skip-gram模型中，最大的不足就是计算速度慢。因为softmax层的时候，需要对10000个词进行求和，可能10000还比较少，但如果你的词汇表存在一百万或一千万个单词时，计算就更加慢了。 当然，这也是有办法解决的，在文献中有一种方法：hierarchical softmax classifier。这种方法不需要一次性计算所有词的和，可能目标词在词汇表中的前5000个？也可能在后5000个？当确定了在前面时，继续往下分，可能在前2500个？也可能在后2500个？依次类推，直到最后你就能直到目标词到底在哪一类中。这样的层次分类可以形成一个树状图。 实际上，较普遍的词通常会出现在树的顶端，因为有更多的分枝可以连接更多的词，而一些比较罕见的词会出现在分枝底部。 这个算法就不讲太多，详情可见参考文献 3。还有一个很重要的问题就是： How to sample the context $c$ ? 选择一个背景词也是很重要的，因为背景词确定后，目标词就在其前后10个词中出现。一种方法是使用均匀分布，从训练文本中随机抽取。然而这样抽取，很显然会抽到一些词，如 “of”,”a”,”and” “to” 等意义不大的词，但它们出现的频率很高。因此在现实中，人们通常不会直接随机抽取背景词。 以上就是 Word2vec的skip-gram模型，在文献中还有另一种模型为 CBOW，它是用目标词周围的背景词去预测中间词，这个算法我们不详细讲。 Negative Sampling在skip-gram模型中，通过背景词和目标词的映射可以学习到一个有效的词嵌入矩阵，其不足在于计算量大，计算速度慢。在本节中，我们介绍另一个算法，Negative Sampling，它的作用于skip-gram相似，但学习的效率更快。这个算法的主要提出者还是 Mikolov，详见参考文献 4。 Defining a new learning problem针对上面的例子，我们重新构建一个监督学习问题。给定一对词组 $x$，“orange” 和 “juice”，这是一对背景——目标词组，而且是正的、相关的，输出 $y$ 为 1。若给定令一对词组，“orange” 和 “king”，那么这是负的、不相关的，则输出为 0。 简单来说，首先选择一个正样本 (positive example)，其次随机在字典中抽取词汇，与原背景词构成负样本 (negative example)，如下表： Context Word Target orange juice 1 orange king 0 orange book 0 orange the 0 orange of 0 注意负样本的目标词是从词汇表（字典）中随机抽取的，即使恰好抽取到位于背景词附近的词也是可以的。设负样本的数量为 $k$，对于小数据集，Mikolov et al. 推荐$k$ 在区间 [5, 20] 。而对于大型数据集，$k$ 选择在 [2, 5] 之间。 那么我们就得到了一个训练集，输入为背景——目标词组，而输出为标签 “0” 和 “1”，负样本数量为4。 Model我们根据背景词 $c$，目标词 $t$，还有每个背景——目标词组对的标签 $y$，定义一个逻辑回归模型： P(y=1|c,t)=\sigma(\theta^T_t e_c)对于每个正样本，我们都存在 $k$ 个负样本去训练该模型。那么在测试集中，我们输入的词组是one-hot向量，经过嵌入矩阵后得到嵌入向量 $e$，再通过逻辑回归模型进行预测。根究到底，就是一个包含 10,000 个分类器的二分类逻辑回归问题。 在这里，我们无需对10,000个词都进行训练。在每次迭代中，只需训练1个正样本和其余4个随机选择的负样本，共5个样本，这就大大减小了计算成本。严格来说，是1个正样本和 $k$ 个负样本，共 $k+1$ 个训练样本。 这就是 Negative Sampling 模型。 Selecting negative examples在这个算法中，还有一个比较重要的细节，那就是如何选择负样本。我们刚刚使用的是随机抽样的方法，但这种方法并不能代表英语单词的分布。其次就是根据字典库中词的出现频率进行抽取，而这种方法多数容易抽取出 “the”,”of”,”and” 等词。 原文作者 Mikolov 提出一种经验值： P(w_i)=\frac{f(w_i)^{3/4}}{\sum^{10000}_{j=1}f(w_j)^{3/4}}$w_i$ 为字典中的任一单词 $i$，$f(w_i)$ 表示词 $w_i$ 在字典中出现的频率，那么词频取 3/4 次幂，就可以避免均匀分布的完全随机了。 Glove word vectorsGlove 算法也用于嵌入矩阵的学习，这种算法不像 Word2vec 那么常用，但由于它的简便，同样受到人们的追捧。这种算法由 Jeffrey Pennington 等人提出，详见参考文献 5。 ModelGloVe 全称为 “global vectors for word representation”，首先我们从文本库中抽取一对背景——目标词组，这对词组距离相近。设 $x_{ij}$ 表示词 $i$ 出现在背景词 $j$ 下的次数，其中 $i$ 相当于目标词 $t$，而 $j$ 相当于背景词 $c$ 。根据背景词和目标词的定义，有 $x_{ij}=x_{ji}$。事实上，如果你定义背景词和目标词同时出现在前后10个词的窗宽之内，那么存在一个对称的关系。如果背景词总是在目标词的前1个，那么 $x_{ij}$ 和 $x_{ji}$ 则未必存在对称的关系。 为了方便 GloVe 算法，我们就将背景词和目标词定义在一个距离相近的地方出现，即两个词双方的前后10个词为窗宽。那么 $x_{ij}$ 简单来说就是词 $i$ 和 $j$ 出现很近（在窗宽之内）的次数。GloVe 的目标就是使如下函数最小化： \min \sum^{10000}_{i=1} \sum^{10000}_{j=1}f(x_{ij})(\theta^T_i e_j + b_i + b_j' -\log x_{ij})^2其中，$f(x_{ij})$ 是权重项。显然，当 $x_{ij}$ 越接近于0时，$\log x_{ij}$ 越趋向于负无穷，由于平方项，会导致趋向于正无穷。但添加权重项之后，当 $f(x_{ij})=0$ 时，那么即使 $x_{ij}$ 为零，总的最小化函数也就等于零。这是权重项 $f(x_{ij})$ 的第一个作用。 另外，在句子中停用词 (this, of, a 等)总是频繁出现，而一些出现的并不频繁却又不能忽视的词。对于停用词，$f(x_{ij})$ 会给予较小的权重，对于不能忽视的词，$f(x_{ij})$ 会给予更大的权重。 在GloVe算法中还有一个细节，那就是参数 $\theta$ 和 嵌入向量 $e$ 是完全对称的。因此它们得到的优化结果是相同的。训练这个算法的方法就是使用均匀分布初始化 $\theta$ 和 $e$，并使用梯度下降算法使目标函数最小化。当每个词都输入并计算之后，取均值。 对于给定的一个词 $w$，有： e_w^{(final)}=\frac{e_w+\theta_w}{2}其中，$e_w^{(final)}$ 为最后得到的词 $w$ 的嵌入向量，$e_w$ 和 $\theta_w$ 分别为通过梯度下降训练后的词 $w$ 的嵌入向量和参数向量。因为 $\theta$ 和 $e$ 互相对称。这就是 GloVe算法。 A note on the featurization view of word embeddings在总结词嵌入的算法之前，它们都有一个性质我们应当提及。在我们的例子中，对于嵌入矩阵，我们打的比方是第一维度是 “Gender”，第二维度是 “Royal”，其次诸如 “Age”,“Food” 之类，共存在300个维度去表示词。我们使用这样的嵌入向量去对词的含义进行解释。然而，很多时候我们并不能保证嵌入矩阵中的每个独立维度都是可以用词义去解释的。 如上图，当一对正交特征向量 “Gender” 和 “Royal” 可以表示某些词时，而学习算法可能会选择其它一些无法解释的特征向量，同样达到表示这些词的效果，如 $e_{w,1}$ 和 $e_{w,2}$，甚至学习算法选择的特征向量并不正交。 为什么可以这样呢？我们可以从代数的角度进行解释。 \min \sum^{10000}_{i=1}\sum^{10000}_{j=1}f(X_{ij})(\theta_i^Te_j+b_i-b_j'-\log X_{ij})^2在目标最小化函数中，$\theta_i^Te_j$ 表示的是词，在不同的维度变换下，我们乘以可逆矩阵 $A$ ，得： (A\theta_i)^T(A^{-T}e_j)=\theta_i^TA^TA^{-T}e_j=\theta_i^Te_j因此，你不能保证学习算法所学习到的嵌入向量都是能够用词的特定意义去解释，但不管进行怎样的变换，都能够对词进行表示。 以上就是关于词嵌入的算法介绍。 Reference Sequence Models - Week 2 Bengio et.al., 2003, A neural probabilistic language model Mikolov et al., 2013. Efficient estimation of word representations in vector space Mikolov et al., 2013. Distributed representation of words and phrases and their compositionality Pennington et al., 2014. GloVe: Global vectors for word representation]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>Word2vec</tag>
        <tag>GloVe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequence Models - Week 2 - (1)]]></title>
    <url>%2F2018%2F07%2F13%2F50-Sequence-Models-Week-2-1%2F</url>
    <content type="text"><![CDATA[本文是序列模型的课程第二周，在这周主要介绍自然语言处理，包括词嵌入 (word embeddings) 的模型和应用，欢迎大家关注！ Introduction to word EmbeddingsWord Representation词嵌入是自然语言处理的一个重要思想，简单来说是表示单词的一种方式，它可以使你的算法自动识别一些短语的类比，比如说男人 (men) 对女人 (woman)，国王 (king)对皇后 (queen)，或其它例子。通过词嵌入，我们就可以减少识别性别等这些类比词语所带来的误差，这些类比词语在算法中会经常遇到。 Word representation我们首先从词的表示 (word representation)开始，在之前我们都是以一个包含10,000个词汇的词汇表，并用 one-hot 向量来表示词语。例如，“man” 出现在词汇表中的第5391位，用 $O_{5391}$ 表示； “Woman” 出现在第9853位，用 $O_{9853}$ 表示，类似的如 “king”,”queen”,”apple”,”orange” 等词以此类推，如图： 然而，这种表示方式有一定的缺陷，因为每个词都是独立的，即使是我们刚刚所说的类比词，在这种表示方式中是无法发觉到类比词之间的关联的。假设有一个以这种表示方式训练好的语言模型，那么当它遇到这样一句话时： I want a glass of orange __. 如果这个语言模型训练过了，那么它可能就很容易预测出空格中的单词是 “juice”，但是当它再次遇到类似的句型时，如下： I want a glass of apple __. 那么，one-hot 向量表达方式的缺点就暴露出来了，因为在 one-hot 向量中，“apple” 和“orange” 基本没任何关联，所以使用one-hot表示方法很难能让我们的学习算法继续做出 “juice” 的预测。 同理，“man” 和 “woman”， “king” 和 “queen” 等类比词都一样，尽管在意义上存在千丝万缕的关系，但在one-hot这种表达方式中都得不到体现。因为这种表达方式无法测算两个词向量之间的距离，我们想想就知道，在one-hot向量中，任意两个向量的点积均为0，这就是其缺陷。 Featurized representation: word embedding在这里，我们使用一种更好的方式对词进行表示，那就是特征表示法 (Featurized representation)，也就是词嵌入。 在上面的例子中，即 “man”,”woman”,”king”,”queen”,”apple”,”orange” 等6个单词，罗列出一些特征，看这些特征是否与这些词汇有所关联。 例如，对于 gender 特征，显然 “man” 和 “woman” 是完全对立的，因此其相关系数分别为 -1 和 1。同理 “king” 和 “queen” 在性别上也是高度对立的，相关系数分别为 -0.95 和 0.97。而水果 “apple” 和 “orange” 与性别特征上并没有专有的区分和关联，因此相关系数分别为 0 和 0.01。 而对于 royal 特征，与 “man” 和 “woman” 则没有太大的关系，与水果 “apple” 和 “orange” 也没什么关系，但与 “king” 和 “queen” 的相关性很高，相关系数分别写为 0.93 和 0.95。 如果说 Food 特征，那么和 “man”,”woman”,”king”,”queen” 都无关，而与 “apple” 和 “orange” 高度相关，相关系数分别为 0.95 和 0.97。 依次类推，我们可以从许多不同的维度特征，计算相关系数来反映不同的词语的相关性。那么每个词就可以用这样的特征向量进行表示。假设我们列举出了300个特征，那么用于表示这个词的词向量长度就为300。 我们将 “man” 记为 $e_{5391}$，将 “woman” 记为 $e_{9853}$，注意在这里下标表示该词在词汇表中的位置，与该词的词向量长度无关，该词的词向量长度为300，表示存在300个特征来对该词进行表示。 通常，对于相似的词来说，例如水果 “apple” 和 “orange” ，在许多维度特征中是相同或高度相似的，那么当算法识别出 “orange juice” 是一样东西时，也有很大可能识别出 “apple juice” 也是类似的一样东西。 当然，300个特征并不好表示，我们可以将这个200维的数据投影到二维空间中进行可视化。一个普遍的算法就是 t-SNE 算法，详见参考文献 2，类似于多元统计的多维标度法。尽管能将高维向量投影到二维图形中，但事实上由于 t-SNE 的非线性映射，有很多信息和关系是遭到了损失和破坏的。 结果如上图所示，“man” 和 “woman” 在一块， “king” 和 “queen”在一块，“cat”，“dot” 和 “fish” 也在一块；从大的角度讲，凡是表示动物的单词都靠得比较近。另外水果类、数字类的单词分别都靠得很近。 之所以将这种表达方式称为词嵌入，是因为每个特征都相当于一个维度。在我们的例子中，300个特征是不能用任何图像画出来，因此这300个维度相当于嵌入在词义里面。这就是词嵌入 (word embeddings)。 Using word embeddings词嵌入表达方式如何应用到自然语言处理中呢？举个例子，姓名识别： “Sally Johnson is an orange farmer.” 当我们将这句话通过词嵌入表达并输入到模型进行训练之后，得到输出，输出为1时表示为姓名，输出为0表示不是姓名，那么经过该模型，可得 “Sally Johnson” 这两个单词为姓名。 当我们再次输入一句话时： “Robert Lin is an apple framer.” 由于 “orange” 和 “apple” 是在特征上是非常相似的，那么算法就很容易识别出 “Robert Lin” 也是一个人名。有意思的是，假设再输入这样一句话时： “Robert Lin is a durian cultivator.” 这句话和前面不太相似，如果你的训练集很小，之前也没训练过 “durian” （榴莲）或 “cultivator” （种植者）的词，但是只要通过词嵌入表达方式的特征构建，就能很容易知道 “durian” 也是一种水果， “cultivator” 和 “farmer” 也很相关，从而使得算法很容易推测到 “Robert Lin” 可能是人名。 但词嵌入也需要大量的样本才能得出检验和学习，这些样本可以来自网上免费的无标签的文本。当你的姓名识别模型训练集很小时，而词嵌入已经检验学习过大量的词，那么我们可以用迁移学习去进行训练。 Transfer learning and word embeddings Learn word embeddings from large text corpus. (1-100B words) (Or download pre-trained embedding online) Transfer embedding to new task with smaller training set. (say, 100k words) Optional: Continue to finetune the world embeddings with new data. 在迁移学习中，首先需要让词嵌入训练大量的文本。当文本量大时，词嵌入的另一个优点也凸显出来了，那就是维度较小。假设你有10,000 个单词，那么用 one-hot 表示的话，每个词的维度是10,000。然而你用词嵌入表示，维度可以只需300，即词的特征量。 当训练好的词嵌入迁移到另一个模型中，即使训练集相对较小，也不影响训练效果。这对 NLP 的很多问题都非常有帮助，比如说姓名识别，text summarization，co-reference resolution 和 parsing 等，另外还有语言模型、机器翻译等。 Relation to face encoding我们在之前学习卷积神经网络中有一个脸部识别的例子，是采用了 Siamese network 架构，输入两张人脸图片，然后经过卷积神经网络层，输出两条向量进行对比，计算两条向量的距离，判别是否为同一张脸。这两天预测的向量称为 encoding . 这个向量 encoding 和词的 embedding 的意思差不多，区别之一就在于人脸识别模型输入的是人脸图片，即使是没从见过的脸也可以输入，而词嵌入输入的是大量的文本，且其学习的大量文本实固定的。 Properties of word embeddings词嵌入有一个很重要的特性，那就是它可以进行类比推理 (analogy reasoning)。举个例子，提个问题：男对女，那国王对什么？大家都猜得到，国王对皇后。然而，词嵌入也能做出这样的推断，它是怎么实现的呢？ Man (5391) Woman (9853) King (4914) Queen (7157) Gender -1 1 -0.95 0.97 Royal 0.01 0.02 0.93 0.95 Age 0.03 0.02 0.70 0.69 Food 0.09 0.01 0.01 0.01 上表分别是四个单词在4个特征维度上的系数，简单来说就是四个单词的嵌入向量 (embedding vector)，分别记作 $e_{man},e_{woman},e_{king},e_{queen}$ 。其中，我们可以发现： e_{man}-e_{woman} \approx \begin{bmatrix} -2 \\ 0 \\ 0 \\ 0 \end{bmatrix}, e_{king}-e_{queen} \approx \begin{bmatrix} -2 \\ 0 \\ 0 \\ 0 \end{bmatrix}显然，两个嵌入向量之差几乎相同。这就是词嵌入可以进行类比推断的原因。当给定“男对女”时，问“国王对什么？”，即 $e_{man}-e_{woman} \approx e_{king}-e_{?}$，通过计算词的嵌入向量差，再计算相似度，即可知道与“国王”对应的词是什么。 这个想法是由 Tomas Mikolov 等人提出的，详情可见参考文献 3。我们将这个算法写得正式一点，即： Find \; word \; w: arg\max \limits_w \ sim(e_w,e_{king}-e_{man}+e_{woman})上式讲述的是找到一个词 $w$，使得该词的嵌入向量 $e_w$ 与 $e_{king}-e_{man}+e_{woman}$ 的相似度 (similarity) 最大。在大部分文献中，通过这种方式进行类比推断的准确率均在30%~75%之间。 对于相似度函数，通常采用的是余弦相似度 (Cosine similarity)。 sim(\overrightarrow{u},\overrightarrow{v})=\frac{\overrightarrow{u}^T\overrightarrow{v}}{\lVert \overrightarrow{u} \rVert_2 \lVert \overrightarrow{v} \rVert_2 }其中，$\lVert \bullet \rVert_2$ 表示欧几里得距离。 Man:Woman as Boy:Girl Ottawa:Canada as Nairobi:Kenya Big:Bigger as Tall:Taller Yen:Japan as Ruble:Russia 以上是一些类比推断的例子，这就是词嵌入的类比推断功能。 Embedding matrix当我们执行算法对词嵌入进行学习时，会得到一个嵌入矩阵 (embedding matrix)。假设我们有一个10,000长度的词汇表，对于每个词都有300个特征，那么可以形成一个维度为 $300 \times 10,000$ 的矩阵，这个矩阵就是嵌入矩阵 $E$。 单词 “Orange” 在词汇表中的第6257位，它的 one-hot 向量记为 $O_{6257}$，维度为 $10,000 \times 1$ 。那么其 one-hot 向量与嵌入矩阵进行点积运算，就可以得到 “Orange” 的嵌入向量，维度为 $300 \times 1$。 E \cdot O_{6257} =e_{6257}同理，对于词汇表中的任意一个词 $j$，其one-hot向量为 $O_j$ ，与嵌入矩阵 $E$ 进行点积运算，即可得到该词 $j$ 的嵌入向量。 E \cdot O_{j} =e_{j}Reference Sequence Models - Week 2 van der Maaten and Hinton., 2008. Visualizing data using t_SNE Mikolov et al., 2013. Linguistic regularities in continuous space word representations]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>NLP</tag>
        <tag>Word Embeddings</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequence Models - Week 1 - (3)]]></title>
    <url>%2F2018%2F06%2F25%2F49-Sequence-Models-Week-1-3%2F</url>
    <content type="text"><![CDATA[接下来的这几节主要讲解的是RNN梯度消失的解决办法，同时还会介绍LSTM，以及双向RNN等，欢迎大家关注！ Recurrent Neural NetworksGated Recurrent Unit (GRU)RNN unitGated Recurrent Unit (GRU) 在深层的RNN中，有助于捕捉长距离之间的关系和解决梯度消失的问题。我们首先来看一下简单的RNN unit. 我们知道，RNN在每一个时间步的正向传播是这样的：$a^{\langle t \rangle}=g(W_a[a^{\langle t-1 \rangle},x^{\langle t \rangle}]+b_a)$ 。根据此式画出下图： 这就是一个RNN unit，$a^{\langle t-1 \rangle}$ 和 $x^{\langle t \rangle}$ 同时输入，与$W_a$ 和 $b_a$ 进行线性组合运算，经过一个 tanh 激活函数，输出 $a^{\langle t \rangle}$ 分为两个方向同时进行，一是传递到 Softmax 进行预测得到 $\hat{y}^{\langle t \rangle} $，二是传递到下一个时间步作为输入。 GRU的形式和这个简单的RNN unit 很相似。GRU主要是在 Cho et al. (2014) 和 Chung et al. (2014) 这两篇文章中提出来的，详见参考文献。 GRU (simplified)我们继续以上节课的一个例子来讲解： “The cat, which already ate …, was full.” 我们需要记住前面的 “cat” 是单数，才能确定后面的谓语用 “was” 还是 “were”。当我们将这句话的词从左到右依次输入时，GRU会产生一个新的变量 $c$ ，表示 memery cell。menery cell 的作用就是对部门过去的信息进行记忆。$c^{\langle t \rangle}$ 表示第 $t$ 个时间步下的激活值，在GRU中， $c^{\langle t \rangle}=a^{\langle t \rangle}$ 。而在LSTM中，$c^{\langle t \rangle}$ 和 $a^{\langle t \rangle}$ 是不相同的两个值。为了统一，在GRU中也添加 $c^{\langle t \rangle}$ ，但实际上它就等于 $a^{\langle t \rangle}$。 另外考虑变量 $\tilde{c}^{\langle t \rangle}=\tanh (w_c[c^{\langle t-1 \rangle},x^{\langle t \rangle}]+b_c)$ ，同时GRU还有一个重要的思想，那就是门 $\Gamma_u$，$u$ 表示更新门 (uodate gate)： \Gamma_u=\sigma (w_u[c^{\langle t-1 \rangle},x^{\langle t \rangle}]+b_u) \tag{1}由于门$\Gamma_u​$ 计算的激活函数为sigmoid，因此其值域在0到1之间，而在大部门时间中，$\Gamma_u​$ 总是接近于0，或接近于1。 当我们把 $c^{\langle t \rangle}​$ 更新为 $\tilde{c}^{\langle t \rangle}​$ 时，那么门的思想就会确定这个信息是否值得记忆并进行对 $c^{\langle t \rangle}​$ 的进一步更新。 也就是说过去的信息“cat” 会储存在 $\tilde{c}^{\langle t \rangle}$ ，而门会判断过去的信息，是否值得记忆，是否有效，并作出是否更新的决定。如果是重要信息，比如说 “cat”，那么 $\Gamma_u$ 会接近于1；如果是句中其他无关的词，那么 $\Gamma_u$ 接近于0。然后根据 $\Gamma_u$ 继续更新 $c^{\langle t \rangle}$，如下： c^{\langle t \rangle}=\Gamma_u * \tilde{c}^{\langle t \rangle}+(1-\Gamma_u)*c^{\langle t-1 \rangle} \tag{2} 显然，“cat” 的信息被保留住了，当 $\Gamma_u=1​$ ，则 $c^{\langle t \rangle}=\tilde{c}^{\langle t \rangle}​$ ，$c^{\langle t \rangle}​$ 得到了更新，即捕捉住了 “cat” 的特征；而句子中间的其他无关词语， $\Gamma_u=0​$ ，则 $c^{\langle t \rangle}=c^{\langle t-1 \rangle}​$，句中其他无关词语的信息都没有被记忆，$c^{\langle t \rangle}​$ 也没有得到更新，还是保留着原来 “cat” 的特征，因此句子后面的谓语就可以根据前面得到的特征选择合理形式进行输出。 我们同样可以作图来表示GRU，见下图： 通过门的判断，将句子单词从左往右依次输入时，当遇到一个比较关键的词则会将其记住，而遇到不那么关键的词就选择性过滤，继续保持原关键词的信息，直至遇到下一个关键词。 那么 $c^{\langle t \rangle}=\Gamma_u \ast \tilde{c}^{\langle t \rangle}+(1-\Gamma_u) \ast c^{\langle t-1 \rangle}​$ 有了这样的一道门，即使 $\Gamma_u​$ 接近于0，也不需要担心梯度消失的问题，因为当 $\Gamma_u=0​$ 时，$c^{\langle t \rangle}=c^{\langle t-1 \rangle}​$ ，维持原信息不变；而 $\Gamma_u=1​$ 时，$c^{\langle t \rangle}=\tilde{c}^{\langle t \rangle}​$，进一步更新迭代。 在以上各式中，$c^{\langle t \rangle}$ 可以是一个向量，同理如 $\tilde{c}^{\langle t \rangle},\Gamma_u$ 等都可以是向量，与 $c^{\langle t \rangle}$ 的维度相同。“*” 表示矩阵的內积运算。以上就是一个简化版的 GRU，接下来我们看看一个完整的GRU。 \tilde{c}^{\langle t \rangle}=\tanh (w_c \big [ \Gamma_t \ast c^{\langle t-1 \rangle},x^{\langle t \rangle}\big]+b_c) \\ \Gamma_u=\sigma (w_u[c^{\langle t-1 \rangle},x^{\langle t \rangle}]+b_u) \\ \Gamma_r=\sigma (w_r[c^{\langle t-1 \rangle},x^{\langle t \rangle}]+b_r) \\ c^{\langle t \rangle}=\Gamma_u \ast \tilde{c}^{\langle t \rangle}+(1-\Gamma_u) \ast c^{\langle t-1 \rangle} \\ a^{\langle t \rangle}= c^{\langle t \rangle}完整的GRU中，在第1个式子中添加了一个门 $\Gamma_r$ ，$r$ 可看作为相关性，那么 $\Gamma_r$ 表示输入 $c^{\langle t-1 \rangle}$ 与输出 $\tilde{c}^{\langle t \rangle}$ 的关系。 为什么需要 $\Gamma_r$ ？为什么不用上面的简化版？在经过多年研究者的实验中，结果发现完整的GRU能使上下文存在更长范围的联系，同时能够解决梯度消失问题，效果更佳。 GRU是一种比较普遍的RNN单元架构，还有另一种较为普遍的版本就是LSTM (Long Short Term Memory)，这种单元我们在下节讲解。 Long Short Term Memory (LSTM)GRU and LSTMGRU (the gated recurrnt unit)， 即使在很长的序列中也能学习到句中的前后联系。LSTM 同样可以达到类似的效果，甚至相较于GRU更为强大。LSTM 最初由 Sepp Hochreiter 和 Jurgen Schmidhuber 于1997年提出，它对序列建模影响很大[4]。 接下来不妨看看LSTM的结构。 \tilde{c}^{\langle t \rangle}=\tanh (w_c [ a^{\langle t-1 \rangle},x^{\langle t \rangle} ]+b_c) \\ \Gamma_u=\sigma (w_u[a^{\langle t-1 \rangle},x^{\langle t \rangle}]+b_u) \\ \Gamma_f=\sigma (w_f[a^{\langle t-1 \rangle},x^{\langle t \rangle}]+b_f) \\ \Gamma_o=\sigma (w_o[a^{\langle t-1 \rangle},x^{\langle t \rangle}]+b_o) \\ c^{\langle t \rangle}=\Gamma_u \ast \tilde{c}^{\langle t \rangle}+ \Gamma_f \ast c^{\langle t-1 \rangle} \\ a^{\langle t \rangle}=\Gamma_o \ast c^{\langle t \rangle}回顾一下GRU结构，我们可以很容易发现 GRU 只有两个门: $\Gamma_u$ (update gate) 和 $\Gamma_r$ (relevant gate)。 LSTM存在三个门： $\Gamma_u$ (update gate) ， $\Gamma_f$ (forget gate) 和 $\Gamma_o$ (output gate)。在更新迭代 $c^{\langle t \rangle}$ 时，我们用遗忘门 $\Gamma_f$ 替代了 $(1-\Gamma_u)$ ，这个遗忘门可以选择性对过去的信息 $c^{\langle t-1 \rangle}$ 进行记忆或遗忘。另外添加了 $\Gamma_o$ 计算 $a^{\langle t \rangle}$，$a^{\langle t \rangle}$ 不再是单纯等于 $c^{\langle t \rangle}$。显然，LSTM 就像是 GRU 的进化版。我们看看如何用图对LSTM 进行表示。 LSTM in pictures 从上图中，我们注意到所有门的值，都是通过 $a^{\langle t-1 \rangle}$ 和 $x^{\langle t \rangle}$ 计算得来，包括 $\tilde{c}^{\langle t \rangle}$。图中上方表示 $c^{\langle t-1 \rangle}$ 的直线，都是从左到右直接传递，这是 LSTM 和 GRU 为什么在经过多个时间步后，仍能很好地记住特定关键词信息的原因。 这就是 LSTM，它还有其他变体，例如门的输入并不只依赖于 $a^{\langle t-1 \rangle}$ 和 $x^{\langle t \rangle}$ ，还可能包括 $c^{\langle t-1 \rangle}$ 的影响，因此 $c^{\langle t-1 \rangle}$ 也参与到门的输入当中，这种变体称为 peephole connection。 有一个计算上的细节，那就是假设输入和中间隐含单元的维度都是100，那么 $c^{\langle t-1 \rangle}$ 的第5个元素仅影响对应门中的第5个元素，这是一对一的关系， $c^{\langle t-1 \rangle}$ 的每个元素不会影响对应门中的所有因素。 当文献中出现 peephole connection 时，那就代表着 $c^{\langle t-1 \rangle}$ 同样影响着门的值。以上就是关于 LSTM 的内容。 最后在模型上，你会选择GRU还是LSTM？当前对此并没有比较深入的探讨，尽管GRU会更简单，但事实上LSTM出现的时间比GRU更早。在不同的问题中，不同的算法的效果也不同。GRU的优点就在于简单，更容易建立更大的网络，由于只有两扇门，因此在计算上也会更快一些。而LSTM更复杂更强大，此外它出现的时间更早，经过了时间的考验，人们可能会更常用LSTM。 Bidirectional RNN我们已经见过 RNN 中的各种单元了，如GRU、LSTM等。接下来我们将介绍另一种RNN类型，双向RNN (Bidirectional RNN)，它可以让你从一个序列中的前后同时提取信息。 Getting information from the future在BRNN开始前，我们回顾一下之前的例子：实名识别。 在这个例子中，假设我们使用普通的RNN，即序列的单词从左往右依次传递，那么就会有一个问题，当我们想要识别 “Teddy” 是否为人名的一部分时，只看该词前面的部分是不足以做出判断的。因为你不知道它到底在说泰迪熊 “Teddy bear” 还是美国前总统 “Teddy Roosevelt”。 而在RNN中的单元，可以是标准的RNN blocks，也可以是 GRU 或 LSTM。他们都是前向型 (forward directional) RNN，只利用句子前面的信息。BRNN (bidirectional RNN)，可以解决这个问题。BRNN结构如下： 我们仅用简化的4个单词进行输入，$x^{\langle 1 \rangle}$ 至 $x^{\langle 4 \rangle}$。在进入循环单元 (memory cell)之后，得到 $\overrightarrow{a}^{\langle 1 \rangle}$ 至 $\overrightarrow{a}^{\langle 4 \rangle}$。字母头上的右向箭头表示前向循环单元，它们是一直从左向右进行传递连接的。最后通过这四个前向循环单元输入 $x$，从而预测出 $\hat{y}^{\langle 1 \rangle}$ 至 $\hat{y}^{\langle 4 \rangle}$。这是前向传播部分。 在反向传播中，我们添加反向循环层，即一个个反向循环单元。在这些反向循环单元中，用 $\overleftarrow{a}^{\langle 4 \rangle}$ 至 $\overleftarrow{a}^{\langle 1 \rangle}$ 表示反向连接。反向传播时会从右往左开始进行计算，当 $\overleftarrow{a}^{\langle 4 \rangle}$ 至 $\overleftarrow{a}^{\langle 1 \rangle}$ 依次计算出来后，即可进行预测。 那么通过前向和反向的结合，那么即可捕捉到句子当前输入和未来输入前后的信息，从而做出更准确的预测。这就是BRNN，同理在BRNN中，其单元既可以是标准 RNN block，也可以是GRU和LSTM。 现实中对于许多NLP问题，人们普遍采用BRNN结合LSTM的方式进行训练。然而，BRNN的一个不足就是你需要将一个序列的所有数据都输入之后方能进行预测。例如，当你建立一个语音识别系统时，BRNN 必须让一个人讲完，获取所有语音之后才能进行处理并作出语音识别的预测。 因此对于现实中真正的语音识别应用，会采用比BRNN更为复杂高级的模块。那么在下一节，我们将考虑将RNN、LSTM、GRU、BRNN等结合起来构建更为强大的模型网络。 Deep RNNs我们已经看过了RNN的多个版本，但如果想要学习更为复杂的功能，可以建立多层单元并将其堆叠起来，形成更深的RNN模型。 例如建立一个包含3个隐含层的RNN。如图，3个隐含层分别为 $a^{[1]}$，$a^{[2]}$ 和 $a^{[3]}$。我们将隐含层展开，每一层都包含4个时间步。 我们举个例子，看 $a^{[2]\langle 3 \rangle}$ 是如何计算的？ $a^{[2]\langle 3 \rangle}$ 有两个输入，第一个输入来自第一层，而另一个输入来自同一层的上一个时间步，那么将这两个输入合并，得： a^{[2]\langle 3 \rangle}=g(w_a^{[2]}[ a^{[2]\langle 2 \rangle}, a^{[1]\langle 3 \rangle}]+b_a^{[2]})在同一层中的所有时间步，使用的参数都是相同的，比如说第2层中所有时间步，其参数都是 $w_a^{[2]}$ 和 $b_a^{[2]}$。对于RNN来说，3个隐含层已经是足够了。因为考虑到每一层的时间步，即使是层数很少，其整个网络也可能很大。 那么在经过隐含层之后，即分别输出预测值 $y^{\langle 1 \rangle},y^{\langle 2 \rangle},y^{\langle 3 \rangle}$ 和 $y^{\langle 4 \rangle}$ 了。在每个单元中，无需是标准RNN，也可以是GRU或者LSTM，当然也可以建立双向RNN结构。由于深度RNN训练时十分消耗计算资源，哪怕层数不多，但时间范围可能很长，因此RNN一般不会构建太深，不像卷积神经网络。 以上就是这周关于RNN的所有内容，下周的课程会接触到自然语言处理。 Reference Sequence Models - Week 1 Cho et al., 2014. On the properties of neural machine translation: Encoder-decoder approaches Chung et al., 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling Hochreiter &amp; Schmidhuber 1997. Long short-term memory]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequence Models - Week 1 - (2)]]></title>
    <url>%2F2018%2F06%2F25%2F48-Sequence-Models-Week-1-2%2F</url>
    <content type="text"><![CDATA[这一部分继续对RNN的相关知识进行深化讲解，比如RNN的类型介绍、语言模型、序列生成和梯度消失等，由于课程中许多内容是关于自然语言处理领域的，本人并不是这个方向，但也想大概了解学习一下这方面的知识，在这里所做的笔记可能并不专业，仅作为自己的总结和理解。欢迎大家关注！ Recurrent Neural NetworksDifferent types of RNNs本节内容主要参考了博文 The Unreasonable Effectiveness of Recurrent Neural Networks 的内容，作者是Andrej Karpathy，也是深度学习中计算机视觉领域的大神了。 在之前我们介绍RNN时，就说到训练样本中输入的长度 $T_x$ 和输出的长度 $T_y$ 可以是不相同的。我们之前举的姓名识别的例子，其输入长度和输出长度是相同的，这样的RNN我们称为是多对多的结构 (many-to-many architecture)，即多个输入多个输出。 其次还有多对一的结构 (many-to-one architexture)，例如语义分类，对于一句电影评论，“There is nothing to like in this movie.” ，8个单词依次输入后输出一个从1至5的等级分数。 另外还有一对一 (one-to-one) 和一对多 (one-to-many) 的结构，一对一结构相对简单，一般比较少运用到。而一对多结构通常用在音乐生成方面，用一个输入指定生成音乐的类型，或者音乐的第1个音符，即使你不知道输入什么，你也可以不输入，或者输入零向量。 通常，多对多是RNN中最常使用的一种结构。而多对多也分两种情形，一种是输入和输出长度相等，另一种是输入和输出长度不一致。例如机器翻译，输入一种语言，经过翻译后输出另一种语言，其长度就可能不一致。总的来说，RNN 的类型主要分为5种，见下图： Language model and sequence generationWhat is language modelling?语言建模是当前自然语言处理领域十分基本而又重要的一个任务，这也是RNN处理效果比较好的一个应用方面。 当你在建立一个语音识别系统时，假设你听到一句话：“The apple and pear salad was delicious.” ，将这句话转化成文本时，到底是下面哪种情况呢？ The apple and pair salad. The apple and pear salad. 尽管两句话听起来完全一模一样，但一个好的语音识别系统会自动辨别选择更合理的一句，这就是语言模型的功能了，它可以计算两句话各自出现的可能性。例如，第一句出现的概率为 $3.2 \times 10^{-13}$，而第二句出现的概率为 $5.7 \times 10^{-10}$，显然相较于第一句，第二句出现的可能性更大，那么语音识别系统就选择第二句转化为文本。 Language modelling with an RNN通过RNN建立语言模型，首先我们需要一个包含大量英文文本语料 (word corpus) 的训练集。假设在训练集中有一句话：“Cats average 15 hours of sleep a day.”。那么开始我们会进行分词，建立一个长度为 10,000 的词汇表，然后将句中的8个词转化为对应的词向量。其次我们要识别一个句子在什么时候截止，那么就要添加一个 &lt;EOS&gt;标记，表示 end of sentence. 这样，这句话就存在9个片段，8个词语和一个标记，分别记为 $y^{\langle t \rangle},t=1,2,\dots,9$。 若是出现了在词汇表中不存在的单词，那么我们将该单词用 &lt;UNK&gt;进行替换，表示 unknown words。 做好以上步骤后，我们开始建立RNN，如上图。在这个RNN中，上一时间步的实际值（即句中的每个单词，非预测值）作为下一时间步的输入，即 $x^{\langle t \rangle}=y^{\langle t-1 \rangle}$。那么在第1个时间步中，初始输入为零向量，即 $x^{\langle 1 \rangle}=\overrightarrow{0}$，并进行 softmax 预测，输出为词汇表中（长度为10,002，除了10,000个词汇表中原有的词汇，还包括&lt;EOS&gt;和&lt;UNK&gt;两个标记）每个单词在句首出现的概率，即输出的维度为10,002 。 接下来第2个时间步，输入为 $y^{}$ ，即第1个单词 Cats。输出同样为 softmax 预测，计算的是词汇表中所有单词在 “Cats” 为前提条件下出现的概率，即 $P(\cdots|”Cats”)$。同时，在第3个时间步，输入$y^{\langle 2 \rangle}$，计算所有单词在 “Cats average” 为前提条件下出现的概率，即 $P(\cdots|”Cats \ average”)$。 依次类推。根据全概率公式，显然可以计算整句话出现的概率，我们以前3个单词共同出现的概率计算为例： P(y^{\langle 1 \rangle},y^{\langle 2 \rangle},y^{\langle 3 \rangle})=P(y^{\langle 1 \rangle}) \cdot P(y^{\langle 2 \rangle}|y^{\langle 1 \rangle}) \cdot P(y^{\langle 3 \rangle}|y^{\langle 1 \rangle},y^{\langle 2 \rangle})最后计算损失函数，softmax预测时，我们一般选择的损失函数为： L(\hat{y}^{\langle t \rangle},y^{\langle t \rangle})=-\sum_t y_i^{\langle t \rangle} \log \hat{y}_i^{\langle t \rangle} \\ L=\sum_t L^{\langle t \rangle}(\hat{y}^{\langle t \rangle},y^{\langle t \rangle})Sampling novel sequencesSampling a sequence from a trained RNN当我们训练了一个序列模型后，我们想知道这个模型到底学习到了什么，那么就要进行序列随机抽样（这样翻译好像不太合适，大家可根据建模的过程进行理解），简单来说其作用就是看看已经训练好的模型效果好不好，是否能自动生成有意义的文本。模型见下图： 已知训练好了一个语言模型，首先我们输出初始零向量，$x^{\langle 1 \rangle}=\overrightarrow{0}​$，让其预测出 $\hat{y}^{\langle 1 \rangle}​$ ，显然 $\hat{y}^{\langle 1 \rangle}​$ 是所有词汇出现概率的向量，然后对 $\hat{y}^{\langle 1 \rangle}​$ 向量进行随机取样，python命令为 np.random.choice() ，随机抽取一个概率值所对应的某个单词的词向量作为下一个时间步的输入。 接下来输出 $\hat{y}^{\langle 2 \rangle}$ ，再次进行随机抽样，抽取一个概率值所对应的某个单词的词向量作为 $x^{\langle 3 \rangle}$ 的输入，以此类推，直到随机抽样产生一个 &lt;EOS&gt; 标记停止。如果你的词汇表中不包含 &lt;EOS&gt; 标记，那么你可以决定抽样的次数，当到达该次数的时间步时，就停止继续抽样。 在随机抽样时，不可避免地会抽到 UNK 标记，即词汇表中不存在的单词。如果你不希望模型生成这样的文本，那么可以拒绝此次抽样结果，重新进行随机抽样。当然你也可以保留这种未知单词的结果。 Character-level language model当前我们所建立的 RNN 都是基于英语单词的水平上的，同样你也可以建立一个基于字母水平的 RNN。那么你的词汇表就全是字母，或是和标点符号以及数字了。如上例中，“Cats average 15 hours of sleep a day.” ，则 $y^{\langle 1 \rangle}=”C”,y^{\langle 2 \rangle}=”a”,y^{\langle 3 \rangle}=”t”,\dots$ . 以此类推。 使用字母水平的语言模型有好有坏，优点在于你不会遇到&lt;UNK&gt;的单词，因为所有单词都由字母拼写而成。缺点在于每句话都可能是一个很长的序列，不利于捕捉上下文之间的特征，且需要消耗大量的计算资源和训练成本。 一般字母水平的语言模型并不常用，除非存在某些大量的未知单词时才会选择使用字母水平的语言模型。 Vanishing gradient with RNNs梯度消失是 RNN 最大的一个问题之一，它是如何产生的呢？我们举个例子，假设有下面两句话： “The cat which already ate and maybe already ate a bunch of food that was delicious …… , was full.” “The cats which already ate and maybe already ate a bunch of food that was delicious …… , were full.” 两句话的区别在于主语和谓语的单复数不同，由上看来，谓语的形式取决于主语是单数还是复数，尽管中间部分很长，这就存在了下文对上文有一个很强的依赖性，然而基本的RNN未必能捕捉到这种强依赖性的特征。 为什么呢？我们之前曾讨论过对于一个深度的神经网络，它会存在一个梯度消失的问题。因为在深度神经网络中，在前向传播之后进行反向传播时，由于层数太多，梯度很容易减小为0，很难影响到前面层的权重的更新迭代，也很难影响到前面层的计算。 对于RNN来说也是一样的，如果一个句子很长，由于梯度消失，反向传播时很难可以更新前面时间步的权重，从未无法记忆前面的特征，对后文做出有效的预测。RNN仅仅能根据距离较近的特征做出预测。 除了梯度消失，还可能存在梯度爆炸问题。但在RNN中，梯度消失问题比梯度爆炸更为难以解决，因为梯度爆炸问题更容易被发现。当存在梯度爆炸问题时，解决办法是梯度裁剪 (gradient clipping)：通过设定阈值，当梯度向量大于阈值时，对梯度向量进行重新调整到在阈值之内，从而避免梯度爆炸。 对于梯度消失的解决办法，在接下来的博文中会进行详细的介绍。 Reference Sequence Models - Week 1 The Unreasonable Effectiveness of Recurrent Neural Networks]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Sequence Models - Week 1 - (1)]]></title>
    <url>%2F2018%2F06%2F06%2F47-Sequence-Models-Week-1-1%2F</url>
    <content type="text"><![CDATA[这是深度学习系列的最后一门课程——序列模型 (Squence Models)，在这开始的第一周，主要关注递归神经网络 (Recurrent Neural Networks) ，简称为RNN。RNN也有多种类型的架构，其中我比较熟悉的有LSTM，接下来将为大家一一讲述，欢迎大家关注！ Recurrent Neural NetworksWhy sequence models序列模型，在深度学习中也是比较有趣的一块。例如RNN，在语音识别、自然语言处理和其他等领域都十分常见。那么序列模型具体有哪些应用实例呢？见下图： 如语音识别、音乐生成、语义分类、DNA基因序列检测、机器翻译、视频活动识别和实名识别等都可以采用序列模型来解决。在序列模型中，输出 $X$ 和输出 $Y$ 可以都是序列数据，也可以任一为序列数据，序列的长度可以不相等。下节中我们开始对序列模型的相关概念进行讲解。 Notation在序列模型中，我们对各个变量进行如下定义，例如输入 $x$ 为一句话： $x$ : Harry Potter and Hermione Granger invented a new spell. 在这个模型中，输入 $x$ 为一序列文本，我们想要模型自动识别出句中出现的人名，如 Harry Potter 和 Hermione Granger。这个问题称为 Name-entity recognition，这个问题通常用于搜索引擎中对一些新闻中出现的人物名字的检索。当然除了人名检索，还可以用于查找其他时间、地点等字段。 在上面的输入中，共有9个单词，分别定义为 $x^{\langle t \rangle},t=1,2,\dots,T_x $ 。在这里，$T_x=9$。同理，输出 $y$ 定义为序列 $ y^{\langle t \rangle},t=1,2,\dots,T_y $ 。$ T_x $ 和 $ T_y $ 可以相等，也可以不相等。 这是第一个训练样本，如果有多个训练样本，我们用 $x^{(i) \langle t \rangle},t=1,2,\dots,T_x^{(i)}$ 表示第 $i$ 个训练样本中的第 $t$ 个单词。$T_x^{(i)}$ 为输入集第 $i$ 个训练样本中的长度。输出 $y$ 同理表示。 接下来，我们如何将输入 $x$ 中的每个单词表示成计算机能看懂的东西呢？首先我们需要构建一个词汇表 (Vocabulary)，也可称为字典，实际上就是一个单词组成的列表。在这个词汇表中，例如第一个单词为a，第二个为Aaron，一直延续下去，and出现在367位，Harry排在4075， Potter排在6830，最后一个词 Zulu为10,000。显然，在这里构建的字典长度为10,000。这在现在的自然语言处理领域是十分小的，通常在大部分商业用途中，采用的是30,000至50,000的字典长度。 那么，我们根据每个单词在字典中出现的位置，将每个单词转化为向量形式，如： x^{\langle 1\rangle }= \begin{bmatrix} 0 \\ 0 \\ \vdots \\ 0 \\ 1 (4075) \\ 0 \\ \vdots \\ 0 \end{bmatrix}, x^{\langle 2 \rangle}= \begin{bmatrix} 0 \\ 0 \\ \vdots \\ 0 \\ 1 (6830) \\ 0 \\ \vdots \\ 0 \end{bmatrix}, \dots每个单词的向量维度均为10,000，当你的字典长度为10,000时。 而对于输出 $y$ 的标签，若单词 $ x^{\langle t \rangle} $ 为人名时，则 $ y^{\langle t \rangle}=1 $ ，否则为0。当然，这不是最优的表示方式，因为有可能一个人名是由多个单词组成的，这种表示方式并不能让你知道人名在句中是何时开始，何时结束。在这里我们姑且这么表示。 Recurrent Neural Network ModelWhy not standard network?往常，我们可能会采用标准的神经网络架构进行训练，比如说上面的例子，一句话中包含9个单词，那么输入 $x$ 的维度为 $9 \times 10000$ ，通过中间的多个隐含层（全连接层），最终输出 $y$ 的维度为 $9\times 1$ 。这样的标准神经网络并不好，主要有两个问题： Inputs, outputs can be different lengths in different examples. Doesn’t share features learned across different positions of text. 第1个问题说的是，在每个样本中，输入和输出的长度都可以是不相等的，然而在标准神经网络中，只能限定输入和输出的长度相等，因为全连接。 另一个问题则是标准神经网络结构并不能将已经学习好的特征在文中的不同位置进行共享。例如上例中，第1个单词为人名，神经网络已经学习到了相应的特征，然而当另一个人名出现在句中的其它位置时，该神经网络仍不能自动将前面学习到的人名识别的特征利用起来，而需要重新学习新出现的人名的特征，因为前后人名中学习到的特征并没有实现共享。 我们之前讲的卷积神经网络也类似，在神经风格转移中可以将在一副图中的特征提取运用到另一幅图的生成中，在这里存在特征共享。而标准神经网络架构并没有这样的作用，如果没有权值共享，那么对于一个维度巨大的输入，其参数矩阵也是十分巨大的。因此，对于序列数据来说，标准神经网络不是一个好的选择，这是我们采用递归神经网络 (RNN) 的原因。 Recurrent Neural Networks过程有点复杂，先post上图再说。 我们将句中的第1个单词 $x^{\langle 1 \rangle}$ 开始输入，那么经过一个隐含层，得到第1个输出 $\hat{y}^{\langle 1 \rangle}$ ，判断这个单词是否为人名。接下来输入第2个单词 $x^{\langle 2 \rangle}$ 时，递归神经网络并不仅仅根据输入 $x^{\langle 2 \rangle}$ ，同时还结合上一步中所学到的特征对 $\hat{y}^{\langle 2 \rangle}$ 进行预测，也就是在上一步中得到的激活值会传递到下一步。同理，在接下来的每一步中，都不仅采用输入 $ x^{\langle t \rangle} $ 的信息，同时采用前面所有步中所学到的特征共同对 $ y^{\langle t \rangle} $ 进行预测，这就是递归神经网络的基本构架。 在初始（第0步）时，普遍定义激活值 $a^{\langle 0 \rangle}$ 为零向量。也有其他研究者会定义 $a^{\langle 0 \rangle}$ 为随机向量。同时，在一些文献中，会将RNN画为上图中右边的形式，表示时间步的循环，在每个循环中，都有一个输入和输出。另外，在循环标记中，会添加一个阴影正方形（也就是那个涂满颜色的小正方形），表示延迟一个时间步。在这里，我们还是采用上图左边的形式进行讲解，更为直观。 在RNN中，随着单词输入的增多，每一步中的参数都会传递到下一步，实现权值共享。对于参数，主要分为三种。第一种是输入$x$ 到隐含层之间的参数矩阵，记为 $w_{ax}$ 。其次，从上一时间步传递到下一时间步之间的参数矩阵，记为 $w_{aa}$ 。同理，从隐含层到预测输出 $y$ 之间的参数矩阵，记为 $w_{ya}$ 。 RNN主要是通过结合当前输入和过去学习的知识对当前输出进行预测的，这是优点也是缺点。事实上，在很多语义环境中，很可能需要用到句子后面的输入才能对当前做出更好的预测。比如下面的例子： He said, “Teddy Roosevelt was a great President.” He said, “Teddy bears are on sale!” 当神经网络想要预测 Teddy 是否为姓名的一部分时，显然上一句是姓名，而下一句却不是。前面两个单词并不能起到任何帮助，除非结合考虑了句子后面部分的信息。这是这种网络架构的缺陷之一。在接下来的课程中，我们会讲到 BRNN (Bidirectional Recurrent Neural Network)，它可以解决这个问题。 Forward Propagation我们看看前向传递是如何进行的。如下： a^{\langle 0\rangle}=\overrightarrow{0} \\ a^{\langle 1\rangle}=g_1(w_{aa}a^{\langle 0\rangle}+w_{ax}x^{\langle 1\rangle}+b_a) \\ \hat{y}^{\langle 1\rangle}=g_2(w_{ya}a^{\langle 1\rangle}+b_y) \\ \dots \\ a^{\langle t\rangle}=g_1(w_{aa}a^{\langle t-1\rangle}+w_{ax}x^{\langle t\rangle}+b_a) \\ \hat{y}^{\langle t\rangle}=g_2(w_{ya}a^{\langle t\rangle}+b_y) 其中，激活函数 $g_1​$ 通常采用 tanh 或 ReLU，而激活函数 $g_2​$ 取决于你的输出 $y​$ 的形式，若是一个二分类问题，通常采用 sigmoid 激活函数，若是其他分类问题，也可采用其他激活函数。 Simplified RNN notation我们可以将上式进行简化，写成如下形式： a^{\langle t\rangle}=g(w_a[a^{\langle t-1\rangle},x^{\langle t\rangle}]+b_a) \\ [w_{aa}|w_{ax}]=w_a \\ [w_{aa}|w_{ax}] \begin{bmatrix} a^{\langle t-1\rangle} \\ x^{\langle t\rangle} \end{bmatrix} =w_{aa}a^{\langle t-1\rangle}+w_{ax}x^{\langle t\rangle}假设初始向量 $a^{\langle 0 \rangle}​$ 维度为100，输入 $x​$ 的维度为10000，则 $w_{aa}​$ 矩阵维度应为 $100 \times 100​$ ，而 $w_{ax}​$ 矩阵维度应为 $100 \times 10000​$， 将这两个参数矩阵合为 $w_a​$ ，维度为 $100 \times 10100​$。 而将 $ a^{\langle t-1 \rangle} $ 和 $ x^{\langle t \rangle} $ 上下堆起来，则形成一个维度为10100的向量。 同理，对于输出 $ \hat{y} $ 也可简化为： \hat{y}^{\langle t\rangle }=g(w_ya^{\langle t\rangle }+b_y)以上就是一个基本的RNN，下面一节我们会讲到反向传播的推导。 Backpropagation through time一般在编程框架上，比如说tensorflow，都会自动进行反向传播的计算。在这里，我们大概讲一下反向传播的过程，并不涉及到反向传播的推导。 如上图是一个RNN正向传播的过程。首先，根据参数 $w_a$ 和 $b_a$ 计算每一步隐含层中的激活值，其次再根据参数 $w_y$ 和 $b_y$ 计算预测每一步的输出。 为了计算反向传播调整参数值，我们需要建立损失函数。损失函数通常定义为交叉熵损失，即： L^{}(\hat{y}^{\langle t \rangle},y^{\langle t \rangle})=-y^{\langle t \rangle}\log \hat{y}^{\langle t \rangle}-(1-y^{\langle t \rangle})\log (1-\hat{y}^{\langle t \rangle})上式为第 $t​$ 步的损失值，总的损失值即为所有时间步的损失值之和： L(\hat{y},y)=\sum^{T_y}_{t=1}L^{]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>Deep Lerning</tag>
        <tag>RNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Networks - Week 4 - (2)]]></title>
    <url>%2F2018%2F05%2F18%2F46-Convolutional-Neural-Networks-Week-4-2%2F</url>
    <content type="text"><![CDATA[这是课程4第4周的最后一部分，主要内容为神经风格转换 (Neural Style Transfer)，欢迎大家关注！ Neural Style TransferWhat is neural style tranfer?ConvNet 有趣的应用之一就是神经风格转换 (Neural Style Transfer)，这是什么呢？ 我们看上图，我们提供一幅真实场景的图片，称为 content image (简写为 C)；再提供一幅虚拟的图画，称为 style image (S)；我们将 style image 的风格运用到 content image 中，生成一幅新的图画，称为 generated image (G)。这就是神经风格转换。 What are deep ConvNets learning?深度 ConvNet 到底在学习什么？在这节中，我们会对 ConvNet 学习的东西进行可视化，这会帮助我们更进一步地了解神经风格转换。 Visualizing what a deep network is learning 假设我们在训练上面这个 ConvNet，是 AlexNet 类型的网络架构。首先我们看第1层的隐含节点，当你将所有训练集都输入到 ConvNet之后，该隐含节点会找出令该节点的 activation 最大化的9个小图块 (image patches)，每个图块表示其原有图像卷积后检测到的结果，见下图 (a)： 我们看下一个隐含节点，同样可以得到9个小图块，见上图 (b) ；依次类推，我们可以看到9个节点输出的81个小图块。每个节点检测的方向都不相同，有的是斜对角的，有的是竖直方向，有的是水平方向。因为是第1层隐含层，所以检测到的结果还比较粗糙，但已经捕捉到一些特征，比如说边缘、形状和颜色等，这个例子来自参考文献 2，大家可去详细阅读。接下来我们看更深层的网络学习的结果。 Visualizing deep layers 随着网络层数越深，检测到的图像区域越大，特征也越丰富，不再像是第1层只能捕捉到边缘等比较粗糙的特征。我们见上图，在这里共给出了5层的网络可视化，显然能检测到的细节越来越多。 每一层的检测过程都和上一节所说的类似，找出能令某一层中每个节点的activation 最大化的图块作为输出。这就是 ConvNet 真正学习的过程。 Cost Function 上面我们讲到 content image (C), style image (S) 和 generrated image (G)，那么如何判断 G 的效果好不好呢？我们需要计算关于 G 的 cost function。 我们将 cost function 定义为两个部分，分别为 content cost 和 style cost ，也就是 C 和 S 的损失： J(G)= \alpha J_{content}(C,G)+\beta J_{style}(S,G)$ J_{content}(C,G) $ 衡量了G 的图像内容与 C 的相似度，而 $J_{style}(S,G)$ 则衡量了 G 的风格与 S 的相似度，然后通过将两者加权求和计算总的 cost。具体细节可参考文献 3. 使用 $J(G)$ 来生成 G 的计算步骤如下： Initiate G randomly $\rightarrow \ G:100\times 100\times 3$ Use gradient descent to minimize $J(G)$ $\rightarrow \ G:=G-\frac{\partial}{\partial G}J(G)$ 那么我们看看其变化过程： Content Cost Function我们刚刚讲了 Cost Function 包含了两个部分，这节中主要讲第一部分，也就是 Content Cost Function ，首先给出内容损失函数的计算步骤： Say you use hidden layer $l$ to compute content cost. Use pre-trained ConvNet. (E.g., VGG network) Let $ a^{[l] (C)} $ and $ a^{[l] (G)} $ be the activation of layer $l$ on the images If $ a^{l} $ and $ a^{l} $ are similar, both images have similar content 我们假设使用第 $ l $ 层来计算内容损失，如果层数越浅，比如说第1层，那么生成的图片G 会与你的初始图片 C 十分相似；如果层数越深，那么你要在 G 中找到和 C 相似的地方，那么就得看得仔细一点了。所以在实际中，我们通常选定 $l$ 在浅层和深层之间。 其次，使用一个预先训练好的 Convnet，可以是 VGG 结构或者是其它，开始计算 C 和 G 在内容上的相似度。我们假设 $ a^{l} $ 和 $ a^{l} $ 分别为C 和 G 在第 $ l $ 层的激活值 (activation) ，计算它们之间的相似度，若相似度越接近，说明图片的内容也越相似。那么，$ J_{content}(C,G) $ 为： J_{content}(C,G)=\frac{1}{2} ||a^{[l](C)}-a^{[l](G)}||^2在图片输入前标准化可要可不要，因为在 $ J(G) $ 中含有 超参数 $\alpha$ 进行调整。另外， $ a^{l} $ 和 $ a^{l} $ 应将它们拉直成向量，才能计算 $ J_{content}(C,G) $ . Style Cost FunctionMeaning of the “style” of an image在讲 Style Cost 之前，我们要详细了解一下什么是图像的风格。假设在ConvNet第 $l$ 层的输出维度为 $n_h \times n_w \times n_c$ ，$n_c$ 为第三个维度，我们把该维度称为 channels. 那么我们把风格 (style)定义为不同channels 之间激活值的相关性。 Say you are using layer $ l $’s activation to measure “style.” Define style as correlation between activations across channels. 我们举个简单的例子，比如说上图为某一层的输出 activations，有5个channels，每个channels都有不同的色调，那么我们把风格定义为不同channels之间激活值的相关性，比如说在第1channel和第2channel的边缘，画了一些点，这些点表示激活值，我们要计算的风格就是计算这两组点的相关性。 Intuition about style of an image那么为什么不同channels之间的相关性能捕捉到风格呢？ 我们看上图，假设红色channel对应图中下面部分第二组的9个小图块，我们要检测出这中间存在的竖直特征，其次黄色channel对应第四组的9个小图块，它们看起来偏向橙色。那么如果这两个channel相关性很高，就表明图像中的某部分存在竖直结构，就会偏向橙色色调，这就是风格；但如果两个channel不太相关，那么即使存在竖直结构，也未必会是橙色的。 我们用不同channels之间的相关性去衡量风格，即衡量生成图片 (generated image) 中第1channel和第2channel的相关性，它反映了竖直结构特征和橙色色调特征是否会同时出现的频率，这也就衡量了生成图片的风格和 style image 的风格之间的相似度。 Style matrix我们把上面的Intuition写的正式点。首先我们要计算风格矩阵 (style matrix)，它实际上就是所有channels之间的相关性矩阵。我们令第 $l$ 层的激活值为 $a_{i,j,k}^{[l]}$ ，$i,j,k$ 分别代表在 $n_h,n_w,n_c$ 三个维度下的值，同时令第 $l$ 层的风格矩阵为 $G^{[l]}$，那么其维度为 $n^{[l]}_c \times n^{[l]}_c $ 。 设style image中第 $k$ 个channel 和第 $k’$ 个channel之间的风格矩阵为 $ G_{kk’}^{l} $ ，同理generated image中第 $k$ 个channel 和第 $k’$ 个channel之间的风格矩阵为 $ G_{kk’}^{l} $ ，则： G_{kk'}^{[l](S)}= \sum_{i=1}^{n_H^{[l]}} \sum_{j=1}^{n_W^{[l]}} a^{[l](S)}_{ijk} a^{[l](S)}_{ijk'} \\ G_{kk'}^{[l](G)}= \sum_{i=1}^{n_H^{[l]}} \sum_{j=1}^{n_W^{[l]}} a^{[l](G)}_{ijk} a^{[l](G)}_{ijk'}由于 $ k \in [1,n_c]$ ，我们将所有不同的channel一一计算出相关性，即可得 $n_c \times n_c$ 维的风格矩阵 $G^{[l]}$ . 根据上两式，我们可以发现，当激活值越大时，相关性会越高，当激活值越小时，相关性也就越小。风格矩阵，在这里我们称为 Style matrix，但同时它也称为 gram matrix . 最后，我们计算 style cost function，即 $J_{style}^{[l]}(S,G)$ ： \begin{aligned} J_{style}^{[l]}(S,G) &= \frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})^2}||G^{[l](S)}-G^{[l](G)}||_F^2 \\ &= \frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})^2} \sum_k \sum_{k'}(G_{kk'}^{[l](S)}-G_{kk'}^{[l](G)}) \end{aligned}这是第 $l$ 层的风格损失函数，对于总的风格损失函数，只要将所有层的风格损失函数求和即可。当然，也可以添加超参数 $\lambda$ 进行加权求和： J_{style}(S,G)= \sum_l \lambda^{[l]}J_{style}^{[l]}(S,G)1D and 3D Generalizations我们已经学了关于 ConvNet 的众多知识，包括 ConvNet 的多种架构，以及 ConvNet 的多种应用，如图像识别、目标检测、人脸识别和风格转换等。我们讲的大部分应用都是关于 2D 的图像，事实上图像还有1D和3D的，我们的算法也可以应用在1D和3D 的图像中，我们来具体看看。 Convolutions in 2D and 1D 见上图，对于2D的图像，假如说图像维度为 $14\times 14$，滤波器为 $5\times 5$，有16个滤波器，那么卷积之后可得输出为 $10\times 10 \times 16$。若图像是彩色的，则维度为 $14\times 14 \times 3$，在这里彩色图像维度尽管是3维的，但并不属于3D图像，我们只是将色调拆分为RGB三种分别来看而已。那么滤波器和图像维度必须保持一致，即$5\times 5\times 3$，同样有16个滤波器，卷积之后可得输出为 $10\times 10 \times 16$ 。 1D图像同样可以使用类似的卷积运算，常见的1D图像，比如说信号图。该信号图测量你的心脏，每跳动一下将产生多大电压。假设信号图的维度是14，因为只有1个维度，所以滤波器的维度保持一致，为5，采用16个滤波器，卷积后可得输出维度为 $10 \times 16$. 对于1D的数据，我们更常采用 RNN (recurrent neural network)，递归神经网络，我们下门课程序列模型 (sequence model) 会讲到这种网络结构。 3D convolution3D图像是怎样的呢？我们举个例子，比如说 CT 扫描图，这是X光照的一种，但可以对你进行一层一层地扫描，直到将你完整地堆叠成一个整体，见下图： 这才是真正的3D图像。假设一张3D图像，其维度为 $14\times 14\times14$ ，三个维度分别为 height, width, depth，第3个维度为 depth，而不是我们之前说的channels. 那么我们的滤波器维度应该为 $5 \times 5 \times 5$，滤波器个数为16，那么卷积之后可得输出维度为 $10 \times 10 \times 10 \times 16$. 假设下一层还有32个 $5 \times 5 \times 5 \times 16$ 的滤波器，那么将上一层的输出输入到下一层，可得下一层输出为 $6 \times 6 \times 6 \times 32$ . 这就是卷积运算在1D和3D图像中的应用。 Reference Convolutional Neural Networks - Week 4 Zeiler and Fergus., 2013, Visualizing and understanding convolutional networks Gatys et al., 2015. A neural algorithm of artistic style. Images on slide generated by Justin Johnson]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>Neural Style Transfer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Networks - Week 4 - (1)]]></title>
    <url>%2F2018%2F05%2F17%2F45-Convolutional-Neural-Networks-Week-4-1%2F</url>
    <content type="text"><![CDATA[这周是课程4的最后一周，本文内容主要为人脸识别，欢迎大家关注！ Face RecognitionWhat is face recognition?我们之前学了很多关于 ConvNet 的算法知识，在这周主要展示 ConvNet 在人脸识别中的应用。 首先，什么是人脸识别？这个很简单，就是基于人的脸部特征信息进行身份识别的一种技术。在应用人脸识别之前，我们先掌握人脸识别中的一些相关术语。 在人脸识别相关文献中，人人常常会提到人脸验证 (face verification) 和人脸识别 (face recognition). 这两个有什么区别呢？ 人脸验证问题实际上就是给定一张某个人的输入图像以及姓名、ID和工作等信息，由系统验证输入的图像是否是确切的某个人。这是一对一问题，因为它只能判断图像中的人是否就是真正的该人。 而人脸识别问题远难于人脸验证问题。因为人脸识别是一对多问题，它包含众多人的信息，当输入一张图像时，必须和所有人的信息同时匹配，才能验证出是哪个人。 假设我们有一个准确率高达99%的人脸验证系统，99%的准确率并不低，如果你只验证一个人的话，那基本上验证100次才有1次错误。但如果你将这个人脸验证系统应用到人脸识别任务中，在数据库中有100个人的信息，那么这个系统对每个人都存在1%的误判率，这个就未必能够接受了。我们可能需要准确率在99.9%或以上的验证系统才行。 接下来我们会介绍如何建立一个人脸验证系统，当准确率足够高时，也可以作为人脸识别系统的一个 building block 。 One Shot Learning人脸识别的一大挑战就是一次学习问题 (one-shot learning problem)，它指的是在人脸识别系统中，只给定一张图片或一个人脸样本去识别一个人。 通常来说，每个类别只有一个训练样本，深度学习算法是很难凑效的，比如说数据库中有4个人的图片（图中左侧）作为训练样本，那么人脸识别系统要识别出图中右侧第1张到底是图中左侧的哪一位。另外，若给出一张在数据库中不存在的图片（图中右侧第2张），那么人脸识别系统也要识别出这是不是数据库中的人。这就是 one-shot learning problem，它要求只通过一个样本的训练去再次识别这个样本。在企业中，大部分时候我们的数据库中可能只有同事的一张照片，因此这个问题是很关键的。 按照我们之前学的知识，一共有4人，我们把每个人的一张照片给定好标签，输入到 ConvNet 中，运用 Softmax 分类将类别划分为5类，分别对应为这4人以及“不是以上任何一人”。然而，这基本训练不出好的效果，因为训练集太小，如果不断有新的同事要加入数据库，那是否要不断地重新训练 ConvNet？这显然不太可能，因此想要进行人脸识别，必须进行 one-shot learning. one-shot learning 有一个比较重要的部分就是相似度函数 (similarity function)。 d(img1,img2)=degree \ of \ difference \ between \ images \\ If \ d(img1,img2) \left\{ \begin{aligned} \leq \tau \quad & ,\ "Same" \\ \geq \tau \quad &,\ "different" \end{aligned} \right.相似度函数即表示两张图片之间差别的程度，值越小说明越相似，值越大说明越不相似。在这里我们会给定阈值 $\tau$ ，若相似度小于 $\tau$ ，则两张图片是识别为同一个人，否则为不是同一人。 如果有新人加入数据库，同样可以直接计算相似度来判断是否为同一人，就不需要不断重新训练网络了。 Siamese Network上节我们所说的相似度函数，通常在 Siamese Network 中使用。那什么是 Siamese Network ？我们来看看。 一般我们的卷积网络结构是先从输入一张图像样本开始，经过一系列的卷积层、池化层和全连接层，得到一串特征向量，再将这串特征向量输入到 Softmax 分类器中做出分类和预测。但我们现在去掉 Softmax 这一步，那么结果就是一串维度为 128 的向量，我们把这串向量用 $f(x^{(1)})$ 表示，$x^{(1)}$ 为第一个样本，如图： 其次，我们输入第2张图像样本，同样得到一串向量，我们用 $f(x^{(2)})$ 表示，这样用函数表示的过程，我们称为编码 (encoding)。那么我们计算 $f(x^{(1)})$ 和 $f(x^{(2)})$ 之间的相似度： d(x^{(1)},x^{(2)})=||f(x^{(1)})-f(x^{(2)})||^2_2根据相似度，我们可以判断这两张图片是否为同一个人，这就是 Siamese Neural Network 的构架，具体还可参考文献 2。 Triplet LossLearning Objective我们如何对上面的 Siamses Neural Network 进行参数训练呢？一个方法就是定义 triplet loss function 进行梯度下降。 triplet loss function 必须同时在多张图像中使用，进行相互比较。举个例子：对于同一个人的两张图片，其之间的距离是很小的，表示这两张图片很相似；而对于不同人的两张图片，其之间的距离是很大的，triplet loss也会随之增大。 给定一张图片，我们称之为 Anchor image (简写为A)，和它相似的（同一个人）的图片，称之为 Positive image (P)，而和它不相似（不是同一人）的图片，称之为 Negative image (N). 那么我们的目标是，在神经网络训练参数时，能满足： d(A,P) \leq d(A,N) \\ that \ is : ||f(A)-f(P)||^2 \leq ||f(A)-f(N)||^2 \\ \Longrightarrow ||f(A)-f(P)||^2 - ||f(A)-f(N)||^2 \leq 0现在，我们要做一些修改。因为如果神经网络训练得出的编码 $f​$ 参数均为0，那么不管输入的是什么图片，输出都为0，显然上式是永远成立的。我们添加一个参数 $\alpha​$ ，得到： ||f(A)-f(P)||^2 - ||f(A)-f(N)||^2 + \alpha \leq 0这样就避免了刚刚所说的那种情况，我们把 $\alpha​$ 称为 margin，这在支持向量机中也常用到。 假设我们把 $\alpha$ 设为0.2，通常 $d(A,P)$ 是小于 $d(A,N)$ ，但我们也不希望它们之间过于接近，比如说 $d(A,P)=0.5$，$d(A,N)=0.51$ ，这是不能接受的，$d(A,N)$ 至少得大于等于0.7，这是我们把 $\alpha$ 设为0.2的原因，它能够把两类距离进一步拉大。 Loss function给定三张图片：A，P 和 N，P 和 A 图像中是同一人，而 N 和 A 图像中并非同一人，那么 Triplet loss function 为： L(A,P,N)=max(||f(A)-f(P)||^2 - ||f(A)-f(N)||^2 + \alpha, \ 0)因为损失函数总是大于等于0的，因此要在相似度之差和0之间，取一个最大值。只要满足 $d(A,P) \leq d(A,N) $，那么损失函数总是等于0的。但如果$d(A,P) &gt;d(A,N) $，那么就说明出现了误判，损失函数也随之增大。Cost function 如下： J=\sum^m_{i=1}L(A^{(i)},P^{(i)},N^{(i)})注意到我们如果想要训练这个网络，那么就必须要有图片 A 和 P，也就是说同一个人至少要有2张照片以上进行训练。最好每个人能提供10张照片进行训练才能得到好的效果，如果每个人只有1张照片，那么是不能在这个网络进行训练的。 Choosing the triplets A,P,N那么在神经网络中，是如何从训练集中选择这样的三图组合呢？如果你随机选择的话，那么这样的约束是很容易满足的 $||f(A)-f(P)||^2 + \alpha \leq ||f(A)-f(N)||^2$，因此我们必须尽量选择更难识别的组合去训练，即$d(A,P) \approx d(A,N) $，也就是 A,P,N 都很相似，尽管 A 和 N 不是同一人。 Choose triplets that are “hard” to train on. 关于组合选择的详细细节可以参考文献 3 . Face Verification and Binary Classification人脸识别可以转化为一个直接的二元分类问题，那就是使用 Siamese Network，我们具体来看看。 见上图，我们将两张图分别输入到神经网络中，得到两串特征向量，然后我们将这两串向量输入到 logistic regression 中做出预测。如果预测为1，则两张图像是同一人；如果预测为0，则两张图像并非同一人。 这种方式和计算 triplet loss 训练参数的方式不同，但同样十分有效。我们具体看 逻辑回归单元中是怎么计算的。 输出 $\hat{y}$ 采用了 sigmoid 函数，但逻辑回归的输入并非只是前面一层得到的两列编码向量，而是： \hat{y}=\sigma (\sum^{128}_{k=1}w_i \big| f(x^{(i)})_k- f(x^{(j)})_k \big|+b)在式中，$\big| f(x^{(i)})_k- f(x^{(j)})_k \big|$ 还有其它的形式，如卡方形式，称为卡方相似度： \frac{( f(x^{(i)})_k- f(x^{(j)})_k )^2}{ f(x^{(i)})_k+ f(x^{(j)})_k }最后提示一下计算技巧，假设上图中的第一个人是新人，我们不需要将他的图像添加到已训练的网络重新进行训练，只需要将他的图像输入到训练好的网络中计算出一串特征向量。以后当他每一次进入企业时，拍照后输入到网络中计算特征向量，然后与数据库中其之前图像计算的特征向量进行逻辑回归，即可预测出他是否为本人。这样就不用重新进行训练，节省了大量的计算成本。 Reference Convolutional Neural Networks - Week 4 Taigman et al., 2014. DeepFace closing the gap to human level performance Schroff et al., 2015. FaceNet: A unified embedding for face recognition and clustering]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>Face Recognition</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Networks - Week 3 - (2)]]></title>
    <url>%2F2018%2F05%2F16%2F44-Convolutional-Neural-Networks-Week-3-2%2F</url>
    <content type="text"><![CDATA[本文是课程4第3周的第2部分，继续讲解目标检测的相关算法，欢迎大家关注！ Detection algorithmsIntersection Over Union我们如何评价一个目标检测算法是否有效？这节要介绍一个评价指标：Intersection Over Union. 下面我们具体看看这个指标怎么计算。 在左图中，目标的边界框应为红色框，而我们的检测算法得到的边界框为紫色框。在中间的图中，我们把紫色框和红色框所有的部分都用绿色条纹涂满，表示总的目标检测面积；在右图中，我们把紫色框和红色框交叉的部分用橙色条纹涂满，表示交叉目标检测面积。 那么，Intersection Over Union 这个指标就是用交叉面积除以总的面积，即橙色面积除以绿色面积： Intersection \ Over \ Union=\frac{size \ of \ Intersection}{size \ of \ Union}IoU值越大越好，若等于1 说明检测算法的边界框和实际完全重叠。通常，我们以 0.5 作为判断的阈值，IoU大于0.5，说明检测算法的边界框预测结果和实际能够很好的重叠；IoU小于0.5，说明检测算法精确度较差。 当然，0.5 只是一个经验值。如果你对算法的要求更严格，那么可以选择更大的阈值，比如说0.6或0.7。但很少人会把阈值定于0.5以下。 Non-max Suppression我们知道通常目标检测有一个问题，那就是当我们按网格划分图像时，若目标太大占据多个网格，那么算法可能会对同一个目标检测到多次，而非一次。Non-max supression 就是解决这个问题的方法之一。 Non-max Suppression example例如，我们想要对下面这张图片的左图进行目标检测，识别出行人、车和摩托车，那么我们添加 $19 \times 19$ 的网格。显然，图中的两辆车会被多个网格检测出来。 那么我们看看 Non-max suppression 如何解决这个问题。实际上，non-max suppression 做的就是将对同一个目标的多个检测进行清除，只留下一个可能性最大的检测结果。 具体来说，我们知道预测结果的第一个输出为 $p_c$ ，也就是出现目标的可能性。那么我们看到上图中间的那张图，左边的车被检测出两次，概率分别为0.7和0.8，且得到两个蓝色边界框；而右边的车被检测出三次，概率分别为0.6，0.7和0.9，其中中间浅蓝色框的概率最大。 其次，我们看 IoU，可以发现 $p_c$ 最大的结果，其边界框与实际的重叠最大。那么我们即可把其它检测结果删去，得到上图的右边图。这就是 non-max suppression。它字面上的意思其实就是选取目标检测最大可能性的一个预测结果，然后对其它非最大的预测进行屏蔽和清除。 Non-max Suppression algorithm我们继续看 non-max suppression 算法的一些细节，假设我们只检测车，那么预测的标签为： Each \ output \ prediction \ is : \begin{bmatrix} p_c \\ b_x \\ b_y \\ b_h \\ b_w \end{bmatrix}首先，我们确定 $p_c$ 的阈值为0.6 ，将 $p_c&lt;0.6$ 的预测结果丢弃。选择 $p_c$ 最大的预测结果，并计算其他所有留下结果与最大 $p_c$ 结果的IoU。确定 IoU 的阈值为0.5，将 $IoU \geq 0.5$ 的结果丢弃。IoU越大，重叠的部分越大，说明检测到同一目标的可能性越大，因此对于越大IoU的结果，应当丢弃。 Discard all boxes with $p_c \leq 0.6$ While there are any remaining boxes: Pick the box with the largest $p_c$ output that as a prediction. Discard any remaining box with $IoU\geq 0.5$ with the box output in the previous step. 我们刚讲的例子只针对车的检测，如果想要检测行人、摩托车等其他目标，应当对每种目标分别独立地进行 non-max suppression，即进行多次 non-max suppression. Anchor boxesOverlapping objects目标检测还有一个问题就是一个网格中只能检测一个目标，如果多个目标出现在一个网格中，应该怎么办？Anchor boxes 就是解决这个问题的方法之一。 我们举个例子，比如说下面这张图，我们添加 $3\times 3$ 的网格，可以发现人的中心点和车的中心点都几乎在同一个网格中。那么对于这个网格，它的预测结果只能是行人、车和摩托车的任意一种，不可能输出两个目标。 我们可以采用 Anchor boxes 的思想，那就是预先定义两种候选框 (anchor boxes)，如图中的 anchor box 1 和 anchor box 2. 在这里我们为了方便例子的讲解，因此定义两个 anchor box，通常也可以使用更多的 anchor boxes. 其次确定输出标签，之前我们的标签存在8个输出，现在我们将8个输出添加一倍用于分别表示两个 anchor box： y= \begin{bmatrix} p_c \\ b_x \\ b_y \\ b_h \\ b_w \\ c_1 \\ c_2 \\ c_3 \\ p_c \\ b_x \\ b_y \\ b_h \\ b_w \\ c_1 \\ c_2 \\ c_3 \end{bmatrix}标签中上面的8个输出与 anchor box 1 绑定，下面的8个输出与 anchor box 2 绑定，我们看图中行人的形状与 anchor box 1 更相近，那么标签中上面的8个输出用于预测行人，图中车的形状与 anchor box 2 更相近，那么下面的8个输出用于预测车的检测。 Anchor box algorithm总结一下，在之前我们是对包含目标中心点的网格去预测目标结果，但有了两个 anchor boxes，我们对预测的网格，不仅要求包含目标中心点，还要求 anchor box 与目标形状有很高的IoU。 Previously: Each object in training image is assigned to grid cell that contains that object’s midpoint. With two anchor boxes: Each object in training image is assigned to grid cell that contains object’s midpoint and anchor box for the grid cell with highest IoU. 那么预测结果的维度为 $3\times 3 \times 16$，当然你也可以看成是 $3\times 3 \times 2 \times 8$。 Anchor box example我们再回到上面那个例子，对第8个网格，显然人和车的中心点都在该网格中，那么我们对它的预测应为： y= \begin{bmatrix} 1 \\ b_x \\ b_y \\ b_h \\ b_w \\ 1 \\ 0 \\ 0 \\ 1 \\ b_x \\ b_y \\ b_h \\ b_w \\ 0 \\ 1 \\ 0 \end{bmatrix}如果有一个网格，在这个网格上只有车没有行人，那么预测结果应为第1个输出为0，随后7个输出任意，我们不给予考虑，第9个输出为1，其余输出分别为边界框和目标类型。 Anchor box 算法也不是万能，还可能出现一个网格中存在3个目标，或者一个网格中两个目标的 anchor box 相同等意外情况，这些情况对于 Anchor box 算法来说，也是不能给出很好的方案。但这些情况并不经常发生，对于训练效果或许影响不大。 YOLO Algorithm我们之前讲了目标检测的大部分算法，在这里我们将之前学的所有部分结合起来，理清整个YOLO目标检测算法的思路。 Train首先我们要建立训练集，训练集要给样本进行数据标注，也就是贴标签，我们还是分为行人、车和摩托车3类。同时，使用两种 anchor box，那么标签的维度为 $3\times 3 \times 16$，也可写成 $3\times 3 \times 2 \times 8$。当然，在实际情况下，我们更可能将图片分割为 $19\times 19$，同时使用五种 anchor box，那么标签的维度就为 $19\times 19 \times 40$，或 $19\times 19 \times 5 \times 8$ 。 Making predictions预测，我们之前都说过了，在这里不再多讲。要注意的就是，当预测结果的第1个输出 $p_c=0$ 时，不必考虑 $p_c$ 后面的7个输出，不管那7个输出是边界框的形状还是车或人都不再给予考虑，因为 $p_c$ 已经告诉你网格中不存在目标。 Outputting the non-max suppressed outputs 我们看一个例子，假设我们使用两种 anchor box，那么对于每个网格，我们都预测出两个边界框，尽管有些网格的边界框的 $p_c$ 可能性很低，但都存在两个边界框，见上图第二幅。 其次，丢弃 $p_c$ 小的预测结果，得到上图第3幅。最后我们对还剩的预测结果进行 non-max suppression. 由于我们的类别有3个，因此需要分别独立地对3个类别进行 non-max suppression，从而得到最终的预测结果。 这就是完整的YOLO目标检测算法，也是当前最有效的目标检测算法之一。 Reference Convolutional Neural Networks - Week 3 Redmon et al,. 2015. You Only Look Once: Unified real-time object detection]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Networks - Week 3 - (1)]]></title>
    <url>%2F2018%2F05%2F14%2F43-Convolutional-Neural-Networks-Week-3-1%2F</url>
    <content type="text"><![CDATA[这是课程 4 的第 3 周，这周主要学习如何使用卷积神经网络去解决当前计算机视觉领域最难，但也最热门的方向：目标检测 (Object detection)。欢迎大家关注！ Detection algorithmsObject LocalizationWhat are localization &amp; detection?我们已经很熟悉前面讲的图像识别的例子了，比如说猫的分类。然而在目标检测中，不仅需要图像识别，更需要目标定位。如下图： 在上图中，我们识别出车之后，要对其进行定位，用框把车包围标注起来。如有多辆车，则要一一标注。 事实上在真正的自动驾驶中，我们要检测的不仅是车，还有行人、摩托车，甚至其它物体等。另外在分类问题中，通常只有一个大的目标在图像中央；而在检测问题中，可能是多个目标分散在图像各处。那么我们之前所学的图像识别技术只能用于分类，想要用于目标检测，还有更多的要学。 Classification with localization我们再进行图像分类时，总是把一张图片输入到多层卷积神经网络中，然后得到的特征再输入到 Softmax 分类，从而得到预测结果。根据我们设定的类别，预测的结果可能是行人，可能是车，或摩托车，也可能只是背景，即什么目标都没有。这是标准的图像识别过程，要想对目标进行定位，还需要设计其它输出单元。 首先我们在图像上建立一个坐标系，以图像左上角为原点 (0, 0)，右下角为点 (1, 1)。其次，定位检测目标的边界框，设边界框的中心为点 $(b_x,b_y)$ ，高度为 $b_h$ ，宽度为 $b_w$ 。那么通过这四个参数，我们即可对目标进行定位。 我们将这四个参数添加到输出标签 $y$ 中，并定义 $p_c$ ：若 $p_c=1$ ，存在目标 ；若 $p_c=0$ ，不存在目标。那么设定输出标签 $y$ 为： y= \begin{bmatrix} p_c \\ b_x \\ b_y \\ b_h \\ b_w \\ c_1 \\ c_2 \\ c_3 \end{bmatrix}$c_1,c_2,c_3$ 分别代表行人、车和摩托车。在这里我们假设图像中只有一个目标。 那么我们看两个例子，上图中左图是一辆车，而右图是一片雪景，没有目标，那么这两张图片标签 $y^{(1)},y^{(2)}$ 分别为： y^{(1)}= \begin{bmatrix} 1 \\ b_x \\ b_y \\ b_h \\ b_w \\ 0 \\ 1 \\ 0 \end{bmatrix}, y^{(2)}= \begin{bmatrix} 0 \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \\ ? \end{bmatrix}$y^{(1)}$ 结果很显然表示一辆车，而 $y^{(2)}$ 的结果中，除了第1个输出为0，表示不存在目标，其它输出我们可以不管，无论是输出什么我们也不考虑。 最后我们考虑神经网络的损失函数： L(\hat{y},y)= \left\{ \begin{aligned} (\hat{y}_1-y_1)^2+(\hat{y}_2-y_2)^2+\dots+(\hat{y}_8-y_8)^2 \ & ,if \ y_1=1 \\ (\hat{y}_1-y_1)^2 \ &,if \ y_1=0 \end{aligned} \right.当第1个输出结果为0时，因为其它输出不在考虑，所以也不需要计算损失偏差。 Landmark Detection在大部分时候，我们在目标检测时，还需要更进一步检测更细节的东西，比如说人脸识别，不仅要检测定位人脸，还要检测眼睛、鼻子、嘴巴等，那这就不是大范围的目标检测能做到的了，而是需要特征点检测 (Landmark Detection)。 特征点检测的思路和目标检测一样，就是不断添加重要特征点的坐标作为标签 $y$ 的输出。那么训练后神经网络就能预测出每个特征点的具体坐标，即告诉你眼睛、鼻子和嘴巴等分别在哪里。显然，特征点越多，标签的维度也就越大。假设你给定64个特征点，那么标签 $y$ 的维度为129. 第一个输出为是否存在目标，如果存在目标，那么接下来的128个输出则分别为64个特征点的 $x$ 和 $y$ 坐标；如果不存在目标，那么接下来的128个输出不管是什么，都不必考虑。 特征点检测在 AR 技术上应用得十分广泛。我们在一些美化照相机等app中，拍照时可以自动添加一些腮红、皇冠等动画效果，事实上首先要进行的就是特征点检测。还有其他的应用，比如说人体姿势检测等。 Object DetectionSliding Windows Detection在目标检测中，卷积神经网络是通过滑动窗口检测法 (Sliding Windows Detection) 来检测目标的。 首先我们选定一个小方块，作为 window size. 其次将输入图片按小方块大小和步长进行裁剪成多块，然后将这些图片块依次输入到卷积神经网络中做出预测，如图所示： 检测了一次后，可以重新选择 window size 进行多次检测。通过对图片的每个小部分进行检测，那么就可以确定目标在图片的具体位置。 当然滑动窗口检测有一个比较大的缺陷，那就是计算成本过高。因为我们对图片进行多次不同类型的裁剪，并将它们单独地输入到卷积神经网络中运行。如果选择一个很大的stride，或很大的窗口，去减小裁剪的图片数量，这又会可能损失训练效果。而如果选择一个比较小的stride，那么将裁剪出很多的图片块，这是很消耗计算内存的。 Convolutional Implementation of Sliding Windows我们说到滑动窗口检测由于计算成本特别高，计算速度将特别慢，那么如何解决呢？那就得通过将滑动窗口卷积式地输入神经网络来解决了。 Turning FC layer into convolutional layers首先我们来看如何将神经网络中的全连接层转化为卷积层。 假设目标检测的输入为 $14 \times 14 \times 3$ 的图像，我们使用一个 $5\times 5$ 的过滤器，将原始图像映射为 $10\times 10\times 16$ ，然后继续使用最大池化层降维成 $5 \times 5\times 16$ . 接下来通过全连接层，最后进行 Softmax 分类，预测结果有4个类别，分别为：行人、车、摩托车和背景环境。 这是标准的卷积神经网络，但是我们认为全连接层的计算还是太消耗时间，那么我们现在将全连接层转化为卷积层，同时不损害训练结果。在经过最大池化层时，其之前的网络结构不变，其之后我们使用400个 $5 \times 5 \times 16$ 的滤波器进行卷积，那么得到 $1\times 1 \times 400$ 的向量，这就相当于转置并添加一个维度的全连接层，接着继续使用400个 $1\times 1\times 400$ 的滤波器，这同样得到和前面一层相同维度的全连接层，最后使用 $1\times 1\times 4$ 的滤波器进行 Softmax 分类。 Convolution implementation of sliding windows那么在滑动窗口检测中，我们同样使用类似的变换，还是直接上图吧。 卷积滑动窗口的方法来源于参考文献 2 。图中最上层是我们上节的例子，中层的输入为 $16 \times 16 \times 3$ ，那么我们以步长为2，可裁剪出四个部分。我们可依次将这四张图输入卷积神经网络中分别进行预测，得到四个预测结果，但显然这样做会消耗很大的计算成本，因为这四张图都有很大的重叠的部分。 我们可以直接将原始的完整图片输入卷积神经网络，使用和上层例子同样的超参数去训练它，那么最终得到 $2 \times 2 \times 4 $ 的分类结果，这四个结果代表什么意思？它们代表的就分别是我们刚刚所说的四张裁剪的部分图的分类结果。 这样本来应该运行4次的，现在只要运行1次就能得到四个预测结果，显然节省了很大的计算成本。 在上图的下层例子中，是一个更大的图像 $28\times 28\times3$，我们可以使用同样的方法得到输出结果 $8\times 8\times 4$，这样就可以使用同样的超参数进行一次计算，避免了将图片裁剪成64个部分分别进行64次计算了，这在很大程度上提高了运算效率。 Bounding Box Predictions在目标检测中，滑动窗口检测并不是最好的方法，因为它得到目标的边界框并不够准确，很多时候我们裁剪得到的图片中只有目标的一小部分。在这节中我们会使用一个更好的算法去预测更准确的边界框，那就是YOLO算法。 YOLO (You Only Look Once)，这是 Joseph Redmon 在15年发表的文章，可见参考文献 3。我们还是用一个例子来对这个算法进行说明吧。 我们看上面一张输入图像 $100 \times 100$，我们用一个 $3\times 3$ 的网格将这张图片划分为9块，根据我们最开始一节所说的分类定位，那么我们可以得到这9块小图片的标签用于训练： Labels for training For each grid cell：（以第6块图像为例） y= \begin{bmatrix} 1 \\ 0.4 \\ 0.3 \\ 0.9 \\ 0.5 \\ 0 \\ 1 \\ 0 \end{bmatrix}如果将这张图片输入到卷积神经网络中，我们得到的输出维度则为 $3 \times 3 \times 8$ ，分别代表着9块小图片的预测结果，每张小图片的预测结果维度为 $1 \times 1 \times 8$ 。 YOLO算法的主要优点在于能够精确地输出目标在图片中的具体位置。当然，我们用 $3\times 3$ 的网格划分或许会太大，容易发生在其中一个网格中出现多个目标。我们可以进一步细化，如使用 $19 \times 19$ 的网格，那么就可以减少在一块网格中出现多个目标的情况。 我们主要关注两点，第一就是YOLO算法在目标分类和定位方面效果显着，而且得到的目标边界框比滑动窗口检测法更精确；第二就是我们将网格划分的所有小块图像同时进行卷积，这样可以避免分别对每块小图片进行预测所造成的计算成本过高。 我们再看看每张小图像的标签，标签中第 2~4 个输出分别为目标中心的坐标 $x$ 和 $y$，以及目标边界框的高度和宽度，分别用 $b_x,b_y,b_h,b_w$ 表示。我们以每张小图像的左上角为原点 (0, 0)，右下角的点为 (1, 1)。显然，$b_x$ 和 $b_y$ 的值应在区间 [0, 1] 之间，而 $b_h$ 和 $b_w$ 可以大于1，因为目标在原始图像中的比例较大，那么其高度和宽度可以跨越多个网格。 在原文中还有其他更为复杂的参数可以更精确地对目标进行定位检测，在这里就不提了。感兴趣可以搜文章来看。 Reference Convolutional Neural Networks - Week 3 Sermanet et al., 2014. OverFeat: Integrated recognition, localization and detection using convolutional networks Redmon et al,. 2015. You Only Look Once: Unified real-time object detection]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>Object Detection</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Keras Tutorial - the Happy House]]></title>
    <url>%2F2018%2F05%2F14%2F42-Keras-Tutorial-the-Happy-House%2F</url>
    <content type="text"><![CDATA[Keras was developed to enable deep learning engineers to build and experiment with different models very quickly. Just as TensorFlow is a higher-level framework than Python, Keras is an even higher-level framework and provides additional abstractions. Being able to go from idea to result with the least possible delay is key to finding good models. However, Keras is more restrictive than the lower-level frameworks, so there are some very complex models that you can implement in TensorFlow but not (without more difficulty) in Keras. That being said, Keras will work fine for many common models. Welcome to the first assignment of week 2. In this assignment, you will: Learn to use Keras, a high-level neural networks API (programming framework), written in Python and capable of running on top of several lower-level frameworks including TensorFlow and CNTK. See how you can in a couple of hours build a deep learning algorithm. In this exercise, you’ll work on the “Happy House” problem, which we’ll explain below. Let’s load the required packages and solve the problem of the Happy House! 123456789101112131415161718192021import numpy as npfrom keras import layersfrom keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2Dfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2Dfrom keras.models import Modelfrom keras.preprocessing import imagefrom keras.utils import layer_utilsfrom keras.utils.data_utils import get_filefrom keras.applications.imagenet_utils import preprocess_inputimport pydotfrom IPython.display import SVGfrom keras.utils.vis_utils import model_to_dotfrom keras.utils import plot_modelfrom kt_utils import *import keras.backend as KK.set_image_data_format(&apos;channels_last&apos;)import matplotlib.pyplot as pltfrom matplotlib.pyplot import imshow%matplotlib inline Note: As you can see, we’ve imported a lot of functions from Keras. You can use them easily just by calling them directly in the notebook. Ex: X = Input(...) or X = ZeroPadding2D(...). The Happy HouseFor your next vacation, you decided to spend a week with five of your friends from school. It is a very convenient house with many things to do nearby. But the most important benefit is that everybody has commited to be happy when they are in the house. So anyone wanting to enter the house must prove their current state of happiness. As a deep learning expert, to make sure the “Happy” rule is strictly applied, you are going to build an algorithm which that uses pictures from the front door camera to check if the person is happy or not. The door should open only if the person is happy. You have gathered pictures of your friends and yourself, taken by the front-door camera. The dataset is labbeled. Run the following code to normalize the dataset and learn about its shapes. 12345678910111213141516X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()# Normalize image vectorsX_train = X_train_orig/255.X_test = X_test_orig/255.# ReshapeY_train = Y_train_orig.TY_test = Y_test_orig.Tprint (&quot;number of training examples = &quot; + str(X_train.shape[0]))print (&quot;number of test examples = &quot; + str(X_test.shape[0]))print (&quot;X_train shape: &quot; + str(X_train.shape))print (&quot;Y_train shape: &quot; + str(Y_train.shape))print (&quot;X_test shape: &quot; + str(X_test.shape))print (&quot;Y_test shape: &quot; + str(Y_test.shape)) Output: number of training examples = 600number of test examples = 150X_train shape: (600, 64, 64, 3)Y_train shape: (600, 1)X_test shape: (150, 64, 64, 3)Y_test shape: (150, 1) Details of the “Happy” dataset: Images are of shape (64,64,3) Training: 600 pictures Test: 150 pictures It is now time to solve the “Happy” Challenge. Building a model in KerasKeras is very good for rapid prototyping. In just a short time you will be able to build a model that achieves outstanding results. Here is an example of a model in Keras: 1234567891011121314151617181920212223def model(input_shape): # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image! X_input = Input(input_shape) # Zero-Padding: pads the border of X_input with zeroes X = ZeroPadding2D((3, 3))(X_input) # CONV -&gt; BN -&gt; RELU Block applied to X X = Conv2D(32, (7, 7), strides = (1, 1), name = &apos;conv0&apos;)(X) X = BatchNormalization(axis = 3, name = &apos;bn0&apos;)(X) X = Activation(&apos;relu&apos;)(X) # MAXPOOL X = MaxPooling2D((2, 2), name=&apos;max_pool&apos;)(X) # FLATTEN X (means convert it to a vector) + FULLYCONNECTED X = Flatten()(X) X = Dense(1, activation=&apos;sigmoid&apos;, name=&apos;fc&apos;)(X) # Create model. This creates your Keras model instance, you&apos;ll use this instance to train/test the model. model = Model(inputs = X_input, outputs = X, name=&apos;HappyModel&apos;) return model Note that Keras uses a different convention with variable names than we’ve previously used with numpy and TensorFlow. In particular, rather than creating and assigning a new variable on each step of forward propagation such as X, Z1, A1, Z2, A2, etc. for the computations for the different layers, in Keras code each line above just reassigns X to a new value using X = .... In other words, during each step of forward propagation, we are just writing the latest value in the commputation into the same variable X. The only exception was X_input, which we kept separate and did not overwrite, since we needed it at the end to create the Keras model instance (model = Model(inputs = X_input, ...) above). Exercise: Implement a HappyModel(). This assignment is more open-ended than most. We suggest that you start by implementing a model using the architecture we suggest, and run through the rest of this assignment using that as your initial model. But after that, come back and take initiative to try out other model architectures. For example, you might take inspiration from the model above, but then vary the network architecture and hyperparameters however you wish. You can also use other functions such as AveragePooling2D(), GlobalMaxPooling2D(), Dropout(). Note: You have to be careful with your data’s shapes. Use what you’ve learned in the videos to make sure your convolutional, pooling and fully-connected layers are adapted to the volumes you’re applying it to. 12345678910111213141516171819202122232425262728293031323334353637383940414243def HappyModel(input_shape): &quot;&quot;&quot; Implementation of the HappyModel. Arguments: input_shape -- shape of the images of the dataset Returns: model -- a Model() instance in Keras &quot;&quot;&quot; ### START CODE HERE ### # Feel free to use the suggested outline in the text above to get started, and run through the whole # exercise (including the later portions of this notebook) once. The come back also try out other # network architectures as well. # Define the input placeholder as a tensor with shape input_shape. Think of this as your input image! X_input = Input(input_shape) # Zero-Padding: pads the border of X_input with zeroes #X = ZeroPadding2D((3, 3))(X_input) # CONV -&gt; BN -&gt; RELU Block applied to X #X = Conv2D(32, (7, 7), strides = (1, 1), name = &apos;conv0&apos;)(X_input) #X = BatchNormalization(axis = 3, name = &apos;bn0&apos;)(X) #X = Activation(&apos;relu&apos;)(X) X = Conv2D(32, (3, 3), strides = (1, 1), name = &apos;conv0&apos;)(X_input) X = BatchNormalization(axis = 3, name = &apos;bn0&apos;)(X) X = Activation(&apos;relu&apos;)(X) # MAXPOOL X = MaxPooling2D((2, 2), name=&apos;max_pool&apos;)(X) # FLATTEN X (means convert it to a vector) + FULLYCONNECTED X = Flatten()(X) X = Dense(1, activation=&apos;sigmoid&apos;, name=&apos;fc&apos;)(X) # Create model. This creates your Keras model instance, you&apos;ll use this instance to train/test the model. model = Model(inputs = X_input, outputs = X, name=&apos;HappyModel&apos;) ### END CODE HERE ### return model You have now built a function to describe your model. To train and test this model, there are four steps in Keras: Create the model by calling the function above Compile the model by calling model.compile(optimizer = &quot;...&quot;, loss = &quot;...&quot;, metrics = [&quot;accuracy&quot;]) Train the model on train data by calling model.fit(x = ..., y = ..., epochs = ..., batch_size = ...) Test the model on test data by calling model.evaluate(x = ..., y = ...) If you want to know more about model.compile(), model.fit(), model.evaluate() and their arguments, refer to the official Keras documentation. Exercise: Implement step 1, i.e. create the model. 123### START CODE HERE ### (1 line)happyModel = HappyModel((64,64,3))### END CODE HERE ### Exercise: Implement step 2, i.e. compile the model to configure the learning process. Choose the 3 arguments of compile() wisely. Hint: the Happy Challenge is a binary classification problem. 123### START CODE HERE ### (1 line)happyModel.compile(optimizer = &quot;Adam&quot;, loss = &quot;binary_crossentropy&quot;, metrics = [&quot;accuracy&quot;])### END CODE HERE ### Exercise: Implement step 3, i.e. train the model. Choose the number of epochs and the batch size. 123### START CODE HERE ### (1 line)happyModel.fit(x = X_train, y = Y_train, epochs = 20, batch_size = 12)### END CODE HERE ### Epoch 1/20600/600 [==============================] - 9s - loss: 0.6325 - acc: 0.7983 Epoch 2/20600/600 [==============================] - 8s - loss: 0.2446 - acc: 0.9067 Epoch 3/20600/600 [==============================] - 9s - loss: 0.2561 - acc: 0.9217 Epoch 4/20600/600 [==============================] - 8s - loss: 0.1242 - acc: 0.9567 Epoch 5/20600/600 [==============================] - 8s - loss: 0.0767 - acc: 0.9767 Epoch 6/20600/600 [==============================] - 8s - loss: 0.0568 - acc: 0.9850 Epoch 7/20600/600 [==============================] - 9s - loss: 0.0530 - acc: 0.9783 Epoch 8/20600/600 [==============================] - 9s - loss: 0.0596 - acc: 0.9817 Epoch 9/20600/600 [==============================] - 9s - loss: 0.1353 - acc: 0.9583 Epoch 10/20600/600 [==============================] - 9s - loss: 0.0962 - acc: 0.9733 Epoch 11/20600/600 [==============================] - 9s - loss: 0.0702 - acc: 0.9783 Epoch 12/20600/600 [==============================] - 9s - loss: 0.0369 - acc: 0.9850 Epoch 13/20600/600 [==============================] - 9s - loss: 0.0613 - acc: 0.9800 Epoch 14/20600/600 [==============================] - 10s - loss: 0.0885 - acc: 0.9700 Epoch 15/20600/600 [==============================] - 9s - loss: 0.0483 - acc: 0.9850 Epoch 16/20600/600 [==============================] - 10s - loss: 0.0658 - acc: 0.9833 Epoch 17/20600/600 [==============================] - 10s - loss: 0.0229 - acc: 0.9900 Epoch 18/20600/600 [==============================] - 10s - loss: 0.0031 - acc: 0.9983 Epoch 19/20600/600 [==============================] - 9s - loss: 0.0293 - acc: 0.9883 Epoch 20/20600/600 [==============================] - 9s - loss: 0.0186 - acc: 0.9900 Note that if you run fit() again, the model will continue to train with the parameters it has already learnt instead of reinitializing them. Exercise: Implement step 4, i.e. test/evaluate the model. 123456### START CODE HERE ### (1 line)preds = happyModel.evaluate(x = X_test, y = Y_test)### END CODE HERE ###print()print (&quot;Loss = &quot; + str(preds[0]))print (&quot;Test Accuracy = &quot; + str(preds[1])) 150/150 [==============================] - 1s Loss = 0.0749938476086Test Accuracy = 0.973333337307 If your happyModel() function worked, you should have observed much better than random-guessing (50%) accuracy on the train and test sets. To give you a point of comparison, our model gets around 95% test accuracy in 40 epochs (and 99% train accuracy) with a mini batch size of 16 and “adam” optimizer. But our model gets decent accuracy after just 2-5 epochs, so if you’re comparing different models you can also train a variety of models on just a few epochs and see how they compare. If you have not yet achieved a very good accuracy (let’s say more than 80%), here’re some things you can play around with to try to achieve it: Try using blocks of CONV-&gt;BATCHNORM-&gt;RELU such as: 123X = Conv2D(32, (3, 3), strides = (1, 1), name = &apos;conv0&apos;)(X)X = BatchNormalization(axis = 3, name = &apos;bn0&apos;)(X)X = Activation(&apos;relu&apos;)(X) until your height and width dimensions are quite low and your number of channels quite large (≈32 for example). You are encoding useful information in a volume with a lot of channels. You can then flatten the volume and use a fully-connected layer. You can use MAXPOOL after such blocks. It will help you lower the dimension in height and width. Change your optimizer. We find Adam works well. If the model is struggling to run and you get memory issues, lower your batch_size (12 is usually a good compromise) Run on more epochs, until you see the train accuracy plateauing. Even if you have achieved a good accuracy, please feel free to keep playing with your model to try to get even better results. Note: If you perform hyperparameter tuning on your model, the test set actually becomes a dev set, and your model might end up overfitting to the test (dev) set. But just for the purpose of this assignment, we won’t worry about that here. ConclusionCongratulations, you have solved the Happy House challenge! Now, you just need to link this model to the front-door camera of your house. We unfortunately won’t go into the details of how to do that here. What we would like you to remember from this assignment: Keras is a tool we recommend for rapid prototyping. It allows you to quickly try out different model architectures. Are there any applications of deep learning to your daily life that you’d like to implement using Keras? Remember how to code a model in Keras and the four steps leading to the evaluation of your model on the test set. Create-&gt;Compile-&gt;Fit/Train-&gt;Evaluate/Test. Test with your own image (Optional)Congratulations on finishing this assignment. You can now take a picture of your face and see if you could enter the Happy House. To do that: Click on “File” in the upper bar of this notebook, then click “Open” to go on your Coursera Hub. Add your image to this Jupyter Notebook’s directory, in the “images” folder Write your image’s name in the following code Run the code and check if the algorithm is right (0 is unhappy, 1 is happy)! The training/test sets were quite similar; for example, all the pictures were taken against the same background (since a front door camera is always mounted in the same position). This makes the problem easier, but a model trained on this data may or may not work on your own data. But feel free to give it a try! 123456789101112### START CODE HEREimg_path = &apos;images/my_image.jpg&apos;### END CODE HEREimg = image.load_img(img_path, target_size=(64, 64))imshow(img)x = image.img_to_array(img)x = np.expand_dims(x, axis=0)x = preprocess_input(x)print(happyModel.predict(x)) Other useful functions in Keras (Optional)Two other basic features of Keras that you’ll find useful are: model.summary(): prints the details of your layers in a table with the sizes of its inputs/outputs plot_model(): plots your graph in a nice layout. You can even save it as “.png” using SVG() if you’d like to share it on social media ;). It is saved in “File” then “Open…” in the upper bar of the notebook. Run the following code. 1happyModel.summary() 12plot_model(happyModel, to_file=&apos;HappyModel.png&apos;)SVG(model_to_dot(happyModel).create(prog=&apos;dot&apos;, format=&apos;svg&apos;)) Reference Convolutional Neural Networks - Week 2 Keras Documentation Happy House Datasets]]></content>
      <categories>
        <category>Work</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Deep Learning</tag>
        <tag>Keras</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Networks - Week 2 - (2)]]></title>
    <url>%2F2018%2F05%2F13%2F41-Convolutional-Neural-Networks-Week-2-2%2F</url>
    <content type="text"><![CDATA[这是第2周的第二部分，内容比较少，主要讲解使用卷积神经网络时的一些建议，欢迎大家关注！ Practical advices for using ConvNetsUsing Open-Source Implementation哈哈，这节原来是讲如何从 Github 上查看别人的神经网络代码，估计大家都会，在这里就不说了。 Transfer Learning这里不是讲迁移学习的主要内容，而是讲我们在训练自己的网络时，不仅可以借用他人的网络架构，甚至可以将别人训练好的参数迁移到自己的网络中，从而节约计算成本，减少计算时间。毕竟别人训练的参数可能是花了上周甚至上月才训练好的，通过迁移他人训练好的参数，即使我们的数据集不太大，或许也能够获得一个好的训练效果。 Data Augmentation对于计算机视觉来说，数据量是最重要的。它不像其它领域，能获得足够的数据，很多时候在计算机视觉领域，数据往往总是不够用。因此在训练计算机视觉的模型中，常常会使用到 Data augmentation。 Data augmentation 有许多种方法，比较常见的比如说镜像映射 (Mirroring)，这是最简单的。其次是随机裁剪 (Random cropping)，即随机从原始图像裁剪下一块作为新的样本，这不是一个很好的方法，比如说上图，如果你想识别出一只猫，那么裁剪的部分要比较大。但这两种方法都是十分普遍使用的，还有其他一些方法，比如说旋转 (rotation)、切割 (shearing)、扭曲 (local warping)等。 还有一类比较实用的方式，那就是颜色变换 (color shifting)。这种方法通过更改图像RGB色调的值来实现 data augmentation。 但是色调应该怎么调比较好呢？在 AlexNet 的文章中，给出了一种算法：PCA Color Augmentation ，这样算法是基于主成分分析的思想。在这里不多说了，感兴趣的可以搜文章来看。 State of Computer Vision目前，深度学习已经广泛应用在计算机视觉、自然语言处理、语音识别、在线广告等多个领域当中。对于不同的应用领域，能获得的数据量都是不同的，比如说语音识别领域，能获得大量数据；图像识别，能获得中等数据；而物体探测，能获得的数据量就比较少。 通常学习算法有两个获取知识的来源，一就是已经标签好的数据 (labeled data)，用于监督式学习；另一种就是手动调节 (hand-engineering)，这指的是通过手动调整算法的架构和超参数等，使得算法获得更好的训练效果。 那么对各领域的不同数据量，我们在应用学习算法的方式也不一样。当数据量大的时候，可以使用更简单的算法，更少地去进行手动调节，让算法自己学习，获取知识；而当数据量很少的时候，则应该更多地进行手动调节，更费心思地去设计算法，让算法能从少量数据中获取知识。由于计算机视觉领域能获得数据并不多，这也是目前计算机视觉更依赖于 hand-engineering 的原因。 Two sources of knowledge Labeled data Hand engineered features/ network architecture/ other components Tips for doing well on benchmark/ winning competitions(1) Ensembling Train several networks independently and average their outputs 集成，这个讲的是可以独立训练多个神经网络，比如说随机选择3个、5个或7个神经网络进行训练，然后将它们的输出结果进行平均，注意是平均预测结果 $\hat{y}$ ，而不是输出结果的权重。通过集成平均的方式，可能会比基准训练效果提高1%~2%。但这种方式十分消耗计算成本。 (2) Multi-crop at test time Run classifier on multiple versions of test images and average results 这是第二种提高基准预测效果的方式，就是对测试集进行多次裁剪，扩充测试集。这种方式同样消耗计算成本，但会比集成平均好一些。 最后给出几条关于开源代码的建议： Use architectures of networks published in the literature Use open source implementations if possible Use pretrained models and fine-tune on your dataset Reference Convolutional Neural Networks - Week 2]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Networks - Week 2 - (1)]]></title>
    <url>%2F2018%2F05%2F12%2F40-Convolutional-Neural-Networks-Week-2-1%2F</url>
    <content type="text"><![CDATA[这周是课程4的第二周，在这一部分，我们讲讲神经网络的 case studies，也就是一些比较经典有效的神经网络类型。 欢迎大家关注！ Case StudiesWhy look at case studies?这周主要是讲解一些比较经典有效的卷积神经网络，哪怕我们想要解决的任务不同，但这些神经网络的架构仍能给我们很好的启示。见下图： (1) Classic networks: LeNet-5 AlexNet VGG (2) ResNet (3) Inception Classic NetworksLeNet-5我们在前面举的例子，其实就是沿着LeNet-5的思路来讲解的，在这里就不再详细讲LeNet-5的结构，大家见下图： 或者可以阅读参考文献 2. 这篇文章是在1998年发表的，当时基本没用到 padding，而且average pooling也比较常见，另外激活函数也只有 sigmoid和 tanh。神经网络尽管很小，只有60,000多个参数，对于当时的计算水平来说，想要计算这样一个神经网络成本已经是很高了。虽然目前卷积神经网络的发展很快，出现了很多新方法，但在框架上基本沿用了过去的思想，因为还是十分值得我们借鉴的。 AlexNet AlexNet 是2012年提出来的，见参考文献 3. AlexNet虽然和 LeNet-5 有相似的地方，但显然复杂很多，中间还采用了 same padding。LeNet-5 大约有60,000个参数，而AlexNet大约有6千万个参数，激活函数使用了ReLU，因此在效果上比 LeNet-5 更优。在文章中，作者还设置了一些层：Local Response Normalization (LRN)。LRN层的作用是按第三维度，对前两个维度进行标准化。后来的研究发现，LRN层的作用并不大，因此在这里不提。 VGG-16 VGG-16即有16层神经网络，其主要特点是不会包含太多超参数，它在每个卷积层和中都是使用 $3 \times 3$ 的滤波器，步长为2 和 same padding；在最大池化层中均使用 $2 \times 2$ 的滤波器及步长为2. 整个神经网络的架构比较单调却也足够复杂。 图中的卷积层 “$\times 2$” 和 “$\times 3$” 分别表示着有2层和3层卷积层，池化层的主要目的就是降低图像维度，整个框架十分 uniform. 现在的文献还出现了VGG-19，这是VGG网络更大的版本，大家想要看更多细节，可以直接去搜文章来读。 ResNetsResidual block由于梯度消失或梯度爆炸等各种各样的原因，通常一个深度神经网络是十分难以训练的。这节我们介绍 skip connections ，它可以使你从某一层的激活节点投入到更深层中。那么，你就可以建立 ResNet 来训练一个深度神经网络了，即使超过100层也不在话下。 ResNet是有一系列的残差块 (residual block) 建立起来的，什么是残差块？我们先看一个神经网络中的其中两层： 那么，$a^{[l]}$ 要想传递到 $a^{[l+2]}$，通常的方式是： z^{[l+1]}=W^{[l+1]}a^{[l]}+b^{[l+1]} \\ a^{[l+1]}=g(z^{[l+1]}) \\ z^{[l+2]}=W^{[l+2]}a^{[l+1]}+b^{[l+2]} \\ a^{[l+2]}=g(z^{[l+2]})显然，传递过程是比较繁琐的，我们做一些改变。将 $a^{[l]}$ 直接跳跃到第二个 Relu 激活函数之前，这种跳跃称为捷径 (shortcut). 那么我们将最后一个等式改为：$a^{[l+2]}=g(z^{[l+2]}+a^{[l]}）$ . 这就是一个 residual block。 shortcut 的专业术语为 skip connection. 通过 skip connection ，$a^{[l]}$ 就被插入到下一层的激活函数之前了。 Residual Network在Residual Network 中，许多残差块被插入其中，用于训练更深更大的神经网络，例如： 见上图，每两层就形成一个残差块，那么这样一个10层的神经网络就相当于存在5个残差块。 实际上，假设没有残差块，即不存在 skip connection，那么对于一个很深的神经网络，训练误差开始会趋向于减少，到达最低点后又会慢慢增大。尽管理论上我们认为越复杂的神经网络，其训练会越来越精确，即误差越来越小。但实际上这种平坦（不存在跳跃）的深层网络，意味着你的优化算法更难去训练，而且消耗时间也更多，这是误差由小变大的原因。 但是在 ResNet 中，即使层数很多，也可以保证训练误差是不断持续减小的，直至达到平稳。这就解决了梯度消失和梯度爆炸等多种问题。 那 ResNet 是如何起到作用的呢？我们见下一节。 Why ResNets work我们之前说到，建立更深更复杂的网络通常会降低训练效果，然而对 ResNet 来说，则未必会出现这样的现象，为什么呢？ 我们用上面这个例子解释。假设存在上面这个大型神经网络，第 $l$ 层为输出，我们在输出 $a^{[l]}$ 后添加两层，得到新的输出 $a^{[l+2]}$ ，并在第 $l$ 层和第 $l+2$ 层之间建立一个残差块，那么根据我们上节的解释，有： a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(w^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]}) \tag{1}我们发现，当我们使用 $L2$ 正则项的时候，会产生权值衰减 (weight decay) ，即 $w^{[l+2]}$ 的值会不断缩小，同理 $b^{[l+2]}$ 也会不断衰减。那么当 $w^{[l+2]}$ 和 $b^{[l+2]}$ 衰减到 0 时，则有： g(w^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})=g(a^{[l]})=a^{[l]} \tag{2}由于 $a^{[l]}$ 总是大于等于0 ，且激活函数是 ReLU，所以 $g(a^{[l]})=a^{[l]}$ 。这样的恒等函数 (identity function) 可让残差块训练十分容易。同时那么结合式(1)和(2) ，我们可得 $a^{[l+2]}=a^{[l]}$ 。由此即可说明，添加两层后，建立残差块并不会损害神经网络的训练效果。那么在保证不损害神经网络总体的训练效果下，层数越多，自然能学到的东西也越多，训练的精度也会越高。 在深层平坦网络中，由于层数越深，那么参数的学习也将越来越难，这是太多层造成训练效果差的原因。而在 ResNet 中，由于大量的残差块可使得多数层进行跳跃式的连接，且恒等函数十分容易学习，从而保证了不会损害总体训练效果，如果运气好反而能够提升训练效果，这是 ResNet 有效的原因，详见参考文献 5。 有一点值得注意的就是在残差块中，$z^{[l+2]}$ 和 $a^{[l]}$ 是可加的，那么必须保证两者具有相同的维度。因此，在 ResNet 中会经常使用到 same convolutions ，可能是 same padding ，也可能是 $1 \times 1$ 的滤波器，来保证残差块中前后层的维度一致。 假如残差块中的输入和输出维度不一致，比如说 $a^{[l]}$ 的维度为128，$z^{l+2}$ 的维度为256，那么我们必须添加一个额外的参数矩阵 $W_s$ ，维度为 $256 \times 128$ ，使得输入输出的维度一致，即 $a^{[l+2]}=g(z^{[l+2]}+W_sa^{[l]})$ 。矩阵 $W_s$ 可以使让其自己学习的参数矩阵，也可以是通过 $a^{[l]}$ 进行 padding 得到的固定矩阵。 Network in Network and $1 \times 1$ Convolutions 什么是 $1 \times 1$ 卷积呢？我们先看 $1 \times 1$ 滤波器，见下图： 假设有一张 $6 \times 6 \times 1$ 的图像，通过 $1 \times 1$ 滤波器进行卷积，那么图像矩阵的每个元素都乘2，似乎没有太大的用处，仅仅增加了一倍而已。 但假设有一张 $6 \times 6 \times 32$ 的图像，那么 $1 \times 1 \times 32$ 滤波器会显得更有意义。在输入矩阵和滤波器进行卷积之后，再使用 ReLU 进行激活可得输出为 $ 6 \times 6 \times n_c^{[l+1]}$。$n_c^{[l+1]}$ 为滤波器的数量。 总的来说，$1 \times 1$ 卷积事实上就像全连接层，输入矩阵第三维度的所有元素都和所有滤波器进行了全连接（表达得不太清楚），看图可帮助理解。 这就是 $1 \times 1$ 卷积，也叫 Network in Network，详细可见参考文献 6. 那么 $1 \times 1$ 卷积影响了其他许多神经网络的架构，包括在之后会介绍的 Inception network. $1 \times 1$ 卷积到底怎么用呢？它可以用于降维。假设你的输入矩阵是 $28 \times 28 \times 192$ ，那么想要减小前两个维度，可以使用池化层；然而想要减少第三个维度呢？比如说降为 $28 \times 28 \times 32$ ，那么只能通过使用 32 个 $1 \times 1 \times 192$ 的滤波器来说实现了。当然，如果你仍想保持 $28 \times 28 \times 192$ 的维度也可以，那么$1 \times 1 \times 192$ 滤波器的作用就仅仅是给你增加一个激活函数 ReLU 的作用了。 Inception Network MotivationMotivation for inception network当我们在设计卷积神经网络层的时候，你会考虑使用什么类型的层？使用多大的滤波器？Inception Network 会帮助你确定这些超参数，尽管它可能会使整个网络架构更加复杂，但却是十分有效的。 假设你的输入矩阵维度为 $28 \times 28 \times 192$ ，Inception Network 要做的就是，不去考虑要选多大的滤波器，也不去考虑使用卷积层还是池化层，全做就是了！ 如上图，我们分别试了 $1 \times 1$ ，$3\times 3$，$5 \times 5$ 不同大小的滤波器，以及最大池化层，然后将不同方法得到的输出结果都堆叠起来。当然，必须保证输出结果的前两个维度一致，因此都必须采用 same convolutions. 那么我们得到的所有堆叠起来的输出结果维度为 $28 \times 28 \times 256$. 这样的一个网络就是Inception Network，详见参考文献 7 . 其基本思想就是无需你考虑超参数的选择，只要将所有方法都实现一遍并将结果结合起来，让神经网络自己学习所有的参数。 The problem of computational cost显然，尽管 Inception Network 可以把所有超参数都考虑并计算，但其消耗的计算成本是否也会很高呢？ 我们看刚刚的例子中 $5 \times 5$ 滤波器那一部分，也就是输出结果的紫色一块。输入维度为 $28 \times 28 \times 192$，32个 $5 \times 5 \times 192$ 的滤波器，输出维度为 $28 \times 28 \times 32$ ，那么总的来说，我们需要计算的参数个数为：$28 \times 28 \times 32 \times 5 \times 5 \times 192$ 约为1.2亿。数量很可怕，如下图。 但若是采用 $1 \times 1$ 卷积的思想，那你的计算成本至少可以降下10倍，我们可以看看。输入维度还是 $28 \times 28 \times 192$ ，但首先我们通过 $1 \times 1$ 卷积把第三维度降为16，然后在使用 $5 \times 5 $ 的滤波器去求最终结果。 见上图，我们看 $1 \times 1$ 卷积可以把第三维度从192大幅度降为16，得到中间的小块就像一个瓶颈层 (bottleneck layer) 。现在我们再看看需要计算的参数数量，在 $1 \times 1$ 卷积中，需要计算 $28 \times 28 \times 16 \times 192$，约为240万；在$5 \times 5$ 滤波器的卷积层中，需要计算 $28 \times 28 \times 32 \times 5 \times 5 \times 16$ ，约为1千万。因此总的计算个数为1千2百万，几乎是之前的十分之一。可能你会问，中间瓶颈中维度的急剧下降会不会导致神经网络训练效果变差？但许多研究者发现，瓶颈层并不会影响训练结果，且其降维效果节省了大量的计算成本，这也是 Inception Network 的优点。 Inception NetworkInception module 这就一个 Inception 模块，我们上面讲的例子就是这个模块中的一个部分，即 $5 \times 5$ 滤波器的部分。其他滤波器和池化层的操作方式都相似。图中很清晰，蓝色框表示卷积层，红色框表示池化层，绿色框表示输出结果。 Inception network 其实 Inception network 事实上就是 Inception 模块的组合，大红色圈中就是一个个 Inception 模块，但是我们注意到在部分Inception 模块后面还有一些层，即大绿色圈，那这些是什么？ 我们刚刚说了，蓝色框表示卷积层。那么在蓝色框后有一个黄色框，表示全连接层，最后一个白色圈是 Softmax 分类，输出的预测结果。这是 Inception Network 的另一个细节，即每一个 Inception 模块的输出结果都可以进行 Softmax 分类预测。 最后说一个有趣的事情，你们知道Inception Network是怎么提出来的吗？它是由作者根据电影《盗梦空间》的灵感提出来的，哈哈！很不可思议吧！ Reference Convolutional Neural Networks - Week 2 LeCun et al., 1998. Gradient-based learning applied to document recognition Krizhevsky et al., 2012. ImageNet classification with deep convolutional neural networks Simonyan &amp; Zisserman 2015. Very deep convolutional networks for large-scale image recognition He et al., 2015. Deep residual networks for image recognition Lin et al. 2013. Network in Network Szegedy et al., 2014. Going deeper with convolutions]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Networks - Week 1 - (3)]]></title>
    <url>%2F2018%2F05%2F09%2F39-Convolutional-Neural-Networks-Week-1-3%2F</url>
    <content type="text"><![CDATA[本文继续上文的内容，最近这几篇文章讲解的都是卷积神经网络的基础，自己对每一节课的内容对做了详细笔记，这也是挺不容易的，花了很多时间。但是也学到了很多，希望能对得起自己的努力。本文主要讲的是卷积神经网络的实例，以及池化等概念，欢迎大家关注！ Foundations of CNNSimple Convolutional Network Example本节具体讲解一个卷积神经网络每一层传递过程的例子，直接上图吧： 假设我们有一张彩色图像，我们要做图像分类，比如说识别是否为猫图，那么我们可以用卷积神经网络试试。假设彩色图像转化为像素矩阵的维度为 $39\times 39\times 3$ ，那么根据上篇文章各参数的定义，$n_H^{[0]}=n_W{[0]}=39,n_c^{[0]}=3$ ，且在第1层网络中，$f^{[1]}=3,s^{[1]}=1,p^{[1]}=0$，有10个滤波器。显然，我们可以得到输出图像矩阵维度为 $37 \times 37 \times 10$ 。 在接下来的一层中，类似上述步骤，那么可得输出矩阵维度为 $17 \times 17 \times 20$ ，再下一层类似，得到输出矩阵维度为 $7 \times 7 \times 40$ 。实际上，输出矩阵就包含了1960个元素，我们将输出的矩阵拉直成一个向量，然后将其输入到逻辑回归或 Softmax 中进行分类。 这就是卷积神经网络一个典型的例子。那么设计一个卷积神经网络很重要的就是选择滤波器大小和数量、步长、是否padding等参数，这些我们在以后讲解。 上面的例子是一个较常见的卷积层 (Conv layer)，在卷积神经网络中，还存在其他两种类型的网络层，池化层 (Pooling layer) 和全连接层 (Fully connected layer) 。在定义上，池化层和全连接层，相较于卷积层会更简单一些。 Pooling Layers和卷积层不同，在卷积神经网络中通常使用池化层来减少参数的规模，并加快计算速度，同时也可使得某些特征的检测变得更具有鲁棒性。 Pooling layer: Max pooling举个例子，假设有一个 $5\times 5$ 的原始图像矩阵作为输入，滤波器维度为 $3\times 3$ ，步长为1，那么提取输入矩阵左上角 $3\times 3$ 的部分，求最大值，然后移动一步，继续求最大值，不断移动直到输入矩阵的右下角 $3\times 3$ 的部分求最大值完毕。显然可以得到一个 $3\times 3$ 的输出矩阵。 如果图像是彩色三维的，那么对第3个维度每一层的运算步骤是相同且独立的，这就是max pooling ，最大池化。 为什么最大池化能检测图像特征呢？或许是因为每个小区域的最大值都代表着这个小区域最明显的特征，如果存在某些特征能被检测出来，那么基本上是像素的最大值；如果没有特征能被检测出来，那么可能在这片小区域的像素最大值都很小，也就是说存在的特征并不明显。 事实上，到目前为止，还没有人能真正解释得清楚最大池化起作用的原因，人们只是发现运用最大池化后，效果会很好。另外，在最大池化中有众多超参数，然而却没有参数需要训练。一旦你确定了滤波器的维度和步长，那么计算过程也确定了，梯度下降不会对结果产生任何改变。 Pooling layer: Average pooling还有一类池化层，那就是平均池化。平均池化并不常用，但我们简要提一下。在平均池化中，我们并非如最大池化中取最大值，而是求每一块小区域的均值作为输出。例如，设滤波器维度和步长均为2，那么平均池化运算为： \begin{bmatrix} 1 & 3 & 2 & 1 \\ 2 & 9 & 1 & 1 \\ 1 & 4 & 2 & 3 \\ 5 & 6 & 1 & 2 \\ \end{bmatrix} \rightarrow \begin{bmatrix} 3.75 & 1.25 \\ 4 & 2 \\ \end{bmatrix}在一些非常深的神经网络中，最大池化运用地比平均池化更为普遍一些。 Summary of pooling总结一下，关于池化，存在超参数：滤波器大小 $f$ 、步长 $s$ 、最大池化和平均池化的选择。通常，$f$ 为2或3，$s$ 为2，这是最常见的。 在池化层中，padding很少会使用到，且池化没有任何训练参数。 设池化层输出的维度为 $N_H \times N_W \times N_c$ ，那么输出的维度为 $\lfloor \frac{n_H-f}{s}+1 \rfloor \times \lfloor \frac{n_W-f}{s}+1 \rfloor \times n_c$ 。 Convolutional neural network example这节我们看一下如何将不同类型的层在一个神经网络中连接起来。假设我们有一张 $32 \times 32 \times 3$ 的图像矩阵，图像为数字7，我们要建立一个卷积神经网络看是否能将图像的数字7识别出来。 首先我们建立一个卷积层，使用 $5 \times 5$ 的滤波器6个，步长为1 ，no padding，那么这层的输出为 $28 \times 28 \times 6$ ，再添加偏差和激活函数，得到这层的最终输出，称为 conv 1 output。 其次，建立池化层，设定滤波器和步长分别为 $f=2,s=2$ ，使用最大池化法，那么输出为 $14 \times 14 \times 6$ ，我们称为 pool 1 output。 通常在文献中，对层数有两种说法。一是将卷积层和池化层并称为一层，二是将卷积层和池化层分开，单独各称为一层。实际上，人们通常认为有权重（即有参数）的层才算神经网络层，而池化层不存在权重和参数，因此在这里我们将卷积层和池化层共称为一层。 接着，我们继续建立一个卷积层和池化层，步骤如下，超参数设定见下图： 那么经过卷积层2，得到输出 $10 \times 10 \times 16$ ，经过池化层2，得到输出 $5 \times 5 \times 1$6 。我们将卷积层2和池化层2统称为第二层。那么输出共有400个元素，我们将输出结果拉直成一维向量。 最后建立全连接层，全连接层1包含120个节点，上一层的400个节点和全连接层1 的120个节点完全连接。全连接层和我们之前所说的标准神经网络是一样的，那么这里的参数 $W_3$ 的维度则为 $120 \times 400$ 。然后继续建立全连接层，不断将输出的维度缩小，直到最终 Softmax 函数的输出为10，表示从0 到 9 这10个数字。 这就是一个完整典型的卷积神经网络，其中包含了许多超参数，在以后的课程中会给出如何选择这些超参数的建议。 那么我们最后总结一下每一层神经网络输入和输出的维度，见下表： Actication shape Activation Size Paramerter Input (32,32,3) 3072 0 CONV1(f=5,s=1) (28,28,8) 6272 208 POOL1 (14,14,8) 1568 0 CONV2(f=5,s=1) (10,10,16) 1600 416 POOL2 (5,5,16) 400 0 FC3 (120,1) 120 48001 FC4 (84,1) 84 10081 Softmax (10,1) 10 841 值得注意的几点是： (1) 池化层是没有训练参数的； (2) 卷积层的参数，相对于输入矩阵包含的元素，是非常少的； (3) 神经网络越深的层中，输出的元素逐渐越来越少；但如果减少得太快，那么对神经网络效果也不会太好。 (4) 为了将不同类型的层结合在一起，从而建立一个有效的卷积神经网络，必须对每层输入和输出的维度和结构有足够清晰的认识。 Why convolutions?这节我们来聊聊为什么卷积有效，以及如何使用样本去训练卷积神经网络。首先，和普通全连接层相比，卷积层主要有两个优势：参数共享 (parameter sharing) 和稀疏连接 (sparsity of connections) 。 Parameter sharing: A fearture detector (such as a vertical edge detector) that’s useful in one part of the image is probably useful in another part of the image. Sparsity of connections: In each layer, each output value depends only on a small number of inputs. 我们还是拿上节例子来看，第一层输入的维度是 $32 \times 32 \times 3$ ，拉直成一维向量长度就是3072，经过卷积层后输出维度为 $28 \times 28 \times 8$ ，拉直成一维向量长度就是6272。对于输入和输出，如果我们采用的不是卷积层，而是普通的全连接层，那么需要的参数为 $3072 \times 6272$，大约一千九百万个参数左右。 当然，在深度学习快速发展的今天，当然存在训练超过一千九百万个参数的神经网络，但考虑到我们的输入仅仅是一张小图片，这个训练成本就十分高了。而在卷积神经网络中，每个滤波器维度为 $5\times 5$ ，加上偏差，就是26个参数，共有8个滤波器，总共就是208个参数。相对于输出和输出的维度，参数的数量是十分小了。 那么为什么卷积层的参数可以如此之少呢？主要有两个原因，第一就是参数共享。我们知道，滤波器实际上就是参数，那么同一个滤波器可以不断地检测图像的不同区域，不断地检测每个区域的特征。那么输出矩阵中每一个元素都是由相同的参数计算得到的，这就是参数共享，在一定程度上就大大减少了所需的参数个数。 当然，一张图片的不同区域可能服从的分布不同，但只要存在一定的相似度，那么就可以使用同一滤波器进行特征检测，这也是有效的。 第二个原因就是稀疏连接。什么意思呢？我们看下图： 上图是一个卷积运算，我们看输出矩阵中左上角带绿色圆圈的0，它是由输入矩阵左上角的部分经过卷积计算得到的，也就是说，输出的0只和输入的左上角有关，和输入矩阵的其它部分无关。同理，输入矩阵中中间红色部分，只能计算得到输出矩阵中带红色圆圈的30，而和其它输出无关。 这也就意味着，每个输入和输出部分都是一一对应的，而不像全连接层输入和输出是完全多对多连接的，这就是稀疏连接。 正是这两个原因，使得卷积神经网络可以用更少的参数去训练更大的样本。另外很多时候，卷积神经网络还有平移不变性的优势。什么是平移不变性？很简单。假如一张图片左上角是只猫，那么平移几个像素后，滤波器还是能很好地检测出猫，这就是平移不变性。具体来讲，就是尽管图像发生了平移，但还能保留许多相似的特征，卷积神经网络能很好地发掘这些相似的特征，从而做出准确的判断。 Putting it together最后我们看看如何去训练卷积神经网络。假设你已经建好了一个卷积神经网络用于猫图识别，$X$ 为输入图像，$y$ 为分类标签，见下图： 定义代价函数： Cost \ J=\frac{1}{m} \sum^m_{i=1}L(\hat{y}^{(i)},y^{(i)})对于参数 $W$ 和 $b$ ，我们都采取随机初始化。那么在训练过程中，可以使用梯度下降，以及其他一些算法，比如 momentum, RMSProp, Adam 等。 Reference Convolutional neural networks - Week 1]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Networks - Week 1 - (2)]]></title>
    <url>%2F2018%2F05%2F05%2F38-Convolutional-Neural-Networks-Week-1-2%2F</url>
    <content type="text"><![CDATA[卷积神经网络还是比较复杂的，上篇文章中介绍了边缘检测等一些概念，本文继续讲解一些基本概念，比如 Padding 等。欢迎大家关注！ Foundations of CNNPadding在上文的例子中，我们是以一个 $6 \times 6$ 像素的图片，以 $3 \times 3$ 的滤波器进行卷积，得到 $4 \times 4$ 的输出矩阵。我们定义图片的维度为 $n \times n$ ，滤波器维度为 $f \times f$，那么得到被卷积的图片维度为 $(n-f+1)\times(n-f+1)$ 。 卷积运算有两个缺点：第一就是你每进行一次卷积运算，你的图像都会缩小一点。如果你的图片本来就很小，那么你不能进行太多次卷积运算；即使你的图片足够大，若经过一个层数很多的神经网络时，每一层都缩小一点，那么输出的图片也会很小。第二，我们看图片角落或边缘的像素，在卷积运算中，计算的次数远小于中间的像素，因为有许多 $3 \times 3$ 的区域不断在中间像素中重叠计算。这样一来，我们就丢失了许多图片边缘的信息。 Padding为了解决这些问题，我们可以对图片进行填充，这就是 Padding。 如上图，我们在原来的 $6\times 6$ 原始图像的灰色矩阵外围添加一层像素边界，这层边界将图片边缘给包围了起来。那么原本 $6\times 6$ 的像素图片就变为 $8\times 8$ 的像素图片，经过一个 $3\times 3$ 的滤波器进行卷积得到的输出矩阵维度同样是 $6\times 6$ 。我们令这层边界的灰值为0，同时以 $p$ 代表填充边界的层数。那么，被卷积的图片维度为 $(n+2p-f+1)\times (n+2p-f+1)$ 。 通过 Padding，我们在卷积之后仍能保留图片同样的大小不变，同时图片边缘的像素也会被多次进行卷积运算，避免了信息的丢失。 Valid and Same convolutionsPadding 的层数可以任意选择。通常有两种比较普遍的 Padding 方式：“Valid convolution” 和 “Same convolution” “Valid” : 这种卷积方式意味着不进行 Padding，以原始图片进行卷积。 “Same” : Pad so that output size is the same as the input size. 对于第二种方式，我们上面所说，Padding 后进行卷积输出的图片维度为$(n+2p-f+1)\times (n+2p-f+1)$ 。那么要使输出图像和原始图片大小一致，必须保证 $n+2p-f+1=n$ ，可解得 $p=\frac{f-1}{2}$ ，这就是 Same Convolution。 在计算机视觉中，滤波器的维度 $f$ 通常是奇数。如果 $f$ 是偶数的话，那么Padding 只能是非对称的，卷积之后输出图像和原始图像大小不再一致。当 $f$ 是奇数时，那么就可以进行 Same Convolution 了。其次，奇数维度的滤波器（例如 $3\times 3$ 或 $5\times 5$），都有一个中心位置。这个中心位置在计算机视觉中是一个很好的辨识器。在多数文献中，$3\times3$ 的滤波器是十分常见的，有时也会出现 $5\times 5$ 或 $7\times 7$ 的滤波器，甚至 $1\times 1$ 也是合理的。 Strided ConvolutionsStrided Convolutions 不太好翻译，网上众说纷纭，类似反卷积、条纹卷积之类的，其实按意义上来译的话，应该是跨步卷积，也就是带有步长的卷积。在这里我们姑且就直接按英文看吧。 Strided Convolutions 也是卷积神经网络的一种基本运算方式。我们举个简单例子，如果我们想将一个 $7\times 7$ 的图像矩阵用一个 $3\times 3$ 的滤波器进行卷积，除了像之前一样卷积一次移动一步之外，可以进行多步地移动。 二步卷积运算即： \begin{bmatrix} 2 & 3 & 7 & 4 & 6 & 2 & 9 \\ 6 & 6 & 9 & 8 & 7 & 4 & 3 \\ 3 & 4 & 8 & 3 & 8 & 9 & 7 \\ 7 & 8 & 3 & 6 & 6 & 3 & 4 \\ 4 & 2 & 1 & 8 & 3 & 4 & 6 \\ 3 & 2 & 4 & 1 & 9 & 8 & 3 \\ 0 & 1 & 3 & 9 & 2 & 1 & 4 \\ \end{bmatrix} \ast \begin{bmatrix} 3 & 4 & 4 \\ 1 & 0 & 2 \\ -1 & 0 & 3 \\ \end{bmatrix} = \begin{bmatrix} 91 & 100 & 83 \\ 69 & 91 & 127 \\ 44 & 72 & 74 \\ \end{bmatrix}我们设步长为 $s$ ，那么在 Strided Convolution 之后输出的图像维度为 $(\frac{n+2p-f}{s}+1)\times (\frac{n+2p-f}{s}+1) $ 。当步长无法整除时，则向下（绝对值接近 0 的方向）四舍五入取最接近的整数值，即 $\lfloor \frac{n+2p-f}{s}+1\rfloor\times \lfloor \frac{n+2p-f}{s}+1 \rfloor $。 Technical note on cross-correlation vs. convolution在一些数学书或信号处理教程中，有一个概念和卷积十分相似，那就是互相关 (cross-correlation)。互相关和卷积运算比较，它多了一步，就是在卷积的乘法和加法之前，将滤波器矩阵以斜对角线进行翻转 (filp)，例如： \begin{bmatrix} 3 & 4 & 5 \\ 1 & 0 & 2 \\ -1 & 9 & 7 \\ \end{bmatrix} \rightarrow \begin{bmatrix} 7 & 2 & 5 \\ 9 & 0 & 4 \\ -1 & 1 & 3 \\ \end{bmatrix}然后再用翻转的滤波器矩阵进行卷积运算，这就是互相关。但大多数深度学习文献中，就直接将互相关称为卷积运算。 互相关和卷积还满足结合律，即：$(A \ast B) \ast C = A \ast (B \ast C)$ 。尽管互相关和卷积只差了一步，但在大部分文献上都称为卷积运算，这并不影响我们看文献，也不影响我们进行卷积计算。因此，在本门课程中，同样不区分互相关和卷积。 Convolutions Over Volume我们之前举的例子都是灰色图片，因此转化为灰值矩阵也是二维的。那么我们本节看看如何对一张彩色图片（即多维图像矩阵）进行卷积。 Convolutions on RGB images假设有一张像素维度为 $6\times 6\times 3$ 的彩色图像，前两个维度代表图像的高度和宽度，最后一个维度表示红绿蓝三种色调。那么为了检测这张彩色图像的边缘或其他特征，滤波器的维度同样必须扩展至和图像矩阵一致，即 $3\times 3\times 3$ 。在卷积之后，输出的图像矩阵维度还是 $4\times 4$ 的，下图会比较简单明了： 在卷积中，原始图像矩阵提取和滤波器维度一致的部分，与滤波器进行元素相乘并求和，然后再移动一步重复进行计算，直到原始图像矩阵的最后一部分计算完为止。 如果你只想检测红色色调的边缘，那么你的滤波器每一层可设置为： \begin{bmatrix} 1 & 0 & -1 \\ 1 & 0 & -1 \\ 1 & 0 & -1 \\ \end{bmatrix}, \begin{bmatrix} 0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \\ \end{bmatrix}, \begin{bmatrix} 0 & 0 & 0 \\ 0 & 0 & 0 \\ 0 & 0 & 0 \\ \end{bmatrix} \rightarrow (3 \times 3 \times 3)同样的，如果你想检测所有色调的垂直边缘，那么滤波器的后面两层都与第一层一样。 Multiple filters如果我们想要同时对一张图像进行垂直边缘检测、水平边缘检测或其他各种角度的边缘检测，那应该如何进行卷积呢？很简单，可以设置多个滤波器，让原始图像与多个滤波器同时进行卷积运算，如图： 见上图，黄色滤波器用于检测垂直边缘，而橙色滤波器用于检测水平边缘，那么我们得到两个二维的输出矩阵，将它们重叠形成一个三维的 $4\times 4\times 2$ 的矩阵，便是我们需要的结果。 总结一下，在 no padding 和 单步长的情况下，设 $n_c$ 色调种类，$n_c’$ 为滤波器的数量，那么原始图像矩阵维度为 $n\times n \times n_c$，滤波器维度为 $f \times f \times n_c$，输出矩阵维度为 $(n-f+1)\times (n-f+1) \times n_c’$ 。 One Layer of a Convolutional NetworkExample of a layer我们前面讲了很多关于卷积的知识，但是卷积运算是怎么嵌入到神经网络中呢？我们就上个例子继续讲解吧。 如上图，我们把原始图像矩阵作为输入，将滤波器作为训练参数进行卷积，输出的矩阵再添加偏差 $b​$ ，并使用ReLU函数进行激活，得到最终的输出。 z^{[1]}=w^{[1]}a^{[0]}+b^{[1]} \\ a^{[1]}=g(z^{[1]})训练过程和普通神经网络的训练是相差无几的，只是添加了一个卷积运算。 Number of parameters in one layer用一个具体例子进一步解释卷积神经网络。假设在神经网络的某一层中，有10个 $3\times 3\times 3$ 的滤波器，那么这层会包含多少个参数？事实上，对于每个 $3 \times 3 \times 3$ 的滤波器，就包含了27个参数，同时加上一个偏差参数 $b$ ，即28个参数。那么有10个滤波器，即共有280个参数。 值得注意的是，当你有10个 $3\times 3\times 3$ 的滤波器，那么无论输入的图像矩阵有多大，你的参数个数总保持为280个，这10个滤波器可用于检测垂直边缘、水平边缘以及其他各种特征。那么当图像很大时，如像素矩阵为 $5000\times 5000$ ，或是更大，相对来说280个参数也是十分少了，这在一定程度上也防止了过拟合的发生。 Summary of notation最后，我们来总结一下在整个卷积神经网络中，会涉及到的具体参数有哪些？ If layer $l$ is a conbolution layer: \begin{aligned} f^{[l]}&=filter \ size \\ p^{[l]}&=padding \\ s^{[l]}&=strided \\ n_c^{[l]}&=number \ of \ filters \\ Input&: n_H^{[l-1]} \times n_W^{[l-1]} \times n_c^{[l-1]} \\ Output&: n_H^{[l]} \times n_W^{[l]} \times n_c^{[l]} \\ n_H^{[l]} &= \lfloor \frac{n_H^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \rfloor \\ n_W^{[l]} &= \lfloor \frac{n_W^{[l-1]}+2p^{[l]}-f^{[l]}}{s^{[l]}}+1 \rfloor \\ Each \ filter\ is&: f^{[l]} \times f^{[l]} \times n_c^{[l-1]} \\ Activations&:a^{[l]} \rightarrow n_H^{[l]} \times n_W^{[l]} \times n_c^{[l]} \\ & A^{[l]} \rightarrow m \times n_H^{[l]} \times n_W^{[l]} \times n_c^{[l]} (m \ examples)\\ Weight &: f^{[l]} \times f^{[l]} \times n_c^{[l-1]} \times n_c^{[l]} \\ bias &: n_c^{[l]} \end{aligned}以上就是在卷积神经网络中第 $l$ 层所涉及到的所有参数，当然可能在不同的教程或代码中，这些参数会有不同的表示方法，比如说有人会把色调（即图像矩阵的第3个维度）放到第1个维度中。这都没什么太大区别，只要稍微注意即可。 Reference Convolutional neural networks - Week 1]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Convolutional Neural Networks - Week 1 - (1)]]></title>
    <url>%2F2018%2F05%2F04%2F37-Convolutional-Neural-Networks-Week-1-1%2F</url>
    <content type="text"><![CDATA[欢迎大家来到 深度学习 的第四门课程：卷积神经网络 (CNN)，其实在接触深度学习之前，一直觉得这些DNN、CNN、RNN之类的仿佛是很神秘的东西，但通过前3门课程的学习，开始了解到深度学习其实并不难。同时吴恩达老师讲课也是十分简单易懂、通俗直接，说是新手的入门教程实在是不为过。这门课程和往常一样，都是从最简单的例子——计算机视觉开始讲起，欢迎大家关注！ Foundations of CNNComputer Vision我们知道，当前计算机视觉能如此快速发展应归功于深度学习。在现实很多场景，都使用到了计算机视觉，例如自动驾驶、人脸识别、智能推荐等等。其实，计算机视觉最好的地方有两个：一是可以让机器去观看我们的世界，这样才有进一步理解人类世界的可能；其次是计算机视觉的研究团体相当有活力和创意，可以推动其他领域的发展，例如研究计算机视觉的一些想法可以运用到语音识别当中。所以哪怕你不研究计算机视觉，或许你能从计算机视觉中获取一些灵感，并在你的领域中得到运用。 计算机视觉最简单的例子就是猫图识别了，前面几次课程我们都在不断重复这个例子。但是自动驾驶显然比这个复杂得多，因为在自动驾驶中，你不仅要识别出是否不同的车，还是识别出车的位置，从而避免车的相撞。还有一个十分有趣的例子，那就是神经风格转换 (Neural Style Transfer)，它可以转变你图片的风格。 比如说上图中左上角有一张人脸照，这张照片我们叫内容图片 (content picture)，右上角有一幅毕加索的画，这张图我们叫风格图片 (style picture)。那么我们使用神经网络将两幅图结合起来，即采用风格图片的风格对内容图片进行重画，得到上图底部的图片。 唯一的缺点是计算机视觉的输入十分巨大，仅仅是一张 $64 \times 64$ 像素的图片，结合RGB色调，那么输入层的维度就是 $64 \times 64 \times 3=12288$ ，如果图片是 $1000 \times 1000$ 像素，那么输入层维度可达3百万。由于神经网络的维度太大，很难获得足够的数据防止过拟合的发生，同时要训练这么大的神经网络，其消耗的计算成本也很高。 因此我们需要一种更有效的方法进行计算机视觉的研究，那就是卷积神经网络了。感觉这一节讲了很无聊非重点的一些东西，但是至少能帮助了解计算机视觉，也大概说明了为什么要使用卷积神经网络，对接下来理解卷积神经网络的原理很有帮助。 Edge Detection Example卷积运算是卷积神经网络最基础的一步，在这一节我们通过边缘检测 (edge detection) 这个例子来讲解卷积运算的步骤。 我们可以看看上面这幅图，如果要让计算机识别出图中到底有什么，那么主要有两步，第一步就是检测图片的垂直边缘，那么从竖直方向，可以发现一道道竖直的栏杆和人的轮廓；第二部就是检测图片的水平边缘，从水平方向看，可以看到水平的护栏和自行车的轮廓等。那么这些边缘是怎么检测出来的？我们可以看看具体的运算。 Vertical edge detection \begin{bmatrix} 3 & 0 & 1 & 2 & 7 & 4 \\ 1 & 5 & 8 & 9 & 3 & 1 \\ 2 & 7 & 2 & 5 & 1 & 3 \\ 0 & 1 & 3 & 1 & 7 & 8 \\ 4 & 2 & 1 & 6 & 2 & 8 \\ 2 & 4 & 5 & 2 & 3 & 9 \\ \end{bmatrix}假设有一张 $6 \times 6$ 像素的灰色图片，其灰值矩阵如上所示。因为只有灰色，没有RGB三色调，所以矩阵维度为 $6 \times 6 \times 1$ 。为了检测该灰图的垂直边缘，那么我们可以构建一个 $3\times 3$ 的矩阵做卷积运算，这个矩阵称为滤波器 (filter)，可对垂直边缘进行检测。如下： \begin{bmatrix} 1 & 0 & -1 \\ 1 & 0 & -1 \\ 1 & 0 & -1 \\ \end{bmatrix}有一些研究论文中也有把它称为核 (kernel) ，其实都一样。那么我们便通过这个滤波器对原始的灰值矩阵进行卷积，卷积符号在数学上用星号 “*” 表示，这里有点歧义，在 python 中星号是表示元素乘法运算或矩阵点积运算，稍微注意一下就行。 卷积运算很简单，如上图我们先提取灰值矩阵左上角3行3列的元素与滤波器做简单的乘法运算（非点积运算），然后求和，即： 3 \times 1 +1 \times 1+2 \times 1 +0\times 0+5 \times 0+7 \times 0+1 \times (-1)+8 \times (-1) +2\times (-1)=-5其次，在灰值矩阵中往右移一列，同理继续做卷积运算，见下图： 那么依次将整个灰值矩阵遍历完之后，我们便可得到一个 $4 \times 4$ 的输出矩阵： \begin{bmatrix} -5 & -4 & 0 & 8 \\ -10 & -2 & 2 & 3 \\ 0 & -2 & -4 & -7\\ -3 & -2 & -3 & -16 \\ \end{bmatrix}提示一下： 在实际编程中，不同的语言会用不同的函数名表示卷积运算，比如python中为 conv_forward() ，而 tensorflow 为 tf.nn.conv2d() 。 为什么这样的矩阵就能检测垂直边缘呢？在这个例子中我们并不好理解，那么接下来有一个更简单明了的例子。 如图，我们看这样一个 $6 \times 6$ 灰值矩阵，左3列灰值均为10，右3列灰值为0，那么原始图像很明显，就是一半白一半灰，中间有一条垂直的分界线。同理，我们的滤波器在图像中也可以表现出来，就是白灰黑各三段。通过卷积运算，我们可以得到垂直边缘检测矩阵，其图像十分清晰明了，中间的白色部分显然就是原始图像的垂直分界线。 当然，原始图像的的垂直分界线很细，而垂直边缘检测器得到的中间分界带很宽，这是我们图片太小的缘故。如果使用 $1000 \times 1000$ 像素的图像，那么边缘检测器的效果会更好。 这就是卷积运算的作用，它可以对图像边缘进行检测，也是图像识别的第一步。 More Edge Detection 本节对边缘检测进一步讲解，如正边缘 (positive edge) 和负边缘 (negative edge) 的区别，其他类型的滤波器，及滤波器的参数学习等等。 Vertical edge detection examples 什么是正边缘和负边缘？我们定义为从白到黑的边缘为正边缘，从黑到白的边缘为负边缘。就如上图，如果我们把左上角的图成180度倒转，那么中间分界线由从白变灰变为从灰变白，相应地滤波器中间带从正30变为-30，即从白变黑。 Vertical and Horizontal Edge Detection我们再看看其他类型的边缘检测器。之前介绍了垂直边缘检测器，那么水平边缘检测器也十分简单，如下矩阵： \begin{bmatrix} 1&1&1 \\ 0&0&0 \\ -1&-1&-1 \end{bmatrix} 从上图我们可以看到，原始灰值矩阵包含4个小方块，各存在2小段正边缘和负边缘，通过水平边缘检测器的卷积运算，得到的矩阵中间两行从正到负，说明是左边的正边缘是从白到黑过渡，而右边的负边缘是从黑到白过渡。而在右边矩阵中间，我们看到出现10的灰值，这是过渡区域。过渡区域的大小和图像的大小有关，如果你的图像足够大，那么你就不会看到类似的过渡区域了。总的来说，不同的边缘检测器可以让你检测到不同方向的边缘。 在许多计算机视觉的文献中，还有许多类型的滤波器，比如说 Sobel filter 和 Scharr filter，分别如下： \begin{bmatrix} 1&0&-1 \\ 2&0&-2 \\ 1&0&-1 \end{bmatrix}, \begin{bmatrix} 3&0&-3 \\ 10&0&-10 \\ 3&0&-3 \end{bmatrix}Sobel filter，其优点是增加了中间行的权重，即增大了图片中部像素的权重，使得边缘检测的结果更加鲁棒。Scharr filter 和 Sobel filter 类似，区别很轻微。这两个滤波器都是用于垂直边缘检测的，将它们旋转90度，就成了水平边缘检测器了。 Learning to detect edges随着深度学习的发展，我们甚至可以不再需要自己选择滤波器，而是将滤波器的每个元素当成参数，让其在反向传播中自己学习。 在反向传播中，滤波器的学习就不局限于垂直边缘和水平边缘的方向了，它可以学习去检测各个方向（如45度，70度等），只要能达到最优。那么如何通过反向传播进行参数学习呢？我们在后续见。 Reference Convolutional Neural Networks - Week 1]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>CNN</tag>
        <tag>CV</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[连续系统数值仿真方法——龙格库塔法]]></title>
    <url>%2F2018%2F05%2F03%2F36-%E8%BF%9E%E7%BB%AD%E7%B3%BB%E7%BB%9F%E6%95%B0%E5%80%BC%E4%BB%BF%E7%9C%9F%E6%96%B9%E6%B3%95%E2%80%94%E2%80%94%E9%BE%99%E6%A0%BC%E5%BA%93%E5%A1%94%E6%B3%95%2F</url>
    <content type="text"><![CDATA[在决策理论与方法最后一课中，老师讲了连续系统建模与仿真，事实上在本科就已经接触过许多，在这里我把数值仿真方法中的龙格库塔法给详细介绍一下，这是个比较有趣，同时也比较实用的方法。在求解常微分方程初值问题的数值解经常会用到。本文主要参考书为马东升等主编的 《数值计算方法》，机械工业出版社出版。 龙格库塔法的基本思路初值问题 \left\{ \begin{aligned} y'(x)=f(x,y(x_n)) \\ y(x_0)=y_0 \end{aligned} \right.等价于 \begin{aligned} y(x_{n+1}) &= y(x_n)+ \int^{x_{n+1}}_{x_n}f(x,y(x))dx \\ &=y(x_n)+hf(x_n+ \theta h,y(x_n+\theta h)) , \quad 0]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>决策理论与方法</tag>
        <tag>数值仿真</tag>
        <tag>龙格库塔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[群决策——社会选择函数]]></title>
    <url>%2F2018%2F04%2F27%2F35-%E7%BE%A4%E5%86%B3%E7%AD%96%E2%80%94%E2%80%94%E7%A4%BE%E4%BC%9A%E9%80%89%E6%8B%A9%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[群决策也是决策中的一种重要形式，相较于个人决策，群决策一方面会考虑得更细，另一方面而又考虑得更周到，更全面，它追求的是整体的利益。因为通常重大的决策都会影响一群人，靠单个人决策未必能够满足整体最优。在一个群钟，成员各有所长，也各有偏好，如何集中群中各成员的意见，充分利用众人的经验和智慧，制定出符合众人利益的正确决策，是群决策主要解决的问题。本文主要关注群决策的一小部分——社会选择函数，主要参考了岳超源的《决策理论与方法》。 群决策所涉及的领域很广，有投票表表决（选举）体制，社会选择理论，委员会理论，队论 (team theory) 与分散决策，递阶优化，专家评估，一般均衡理论，对策论，谈判与仲裁等，具体可见下图。 在群决策中，通常采用投票表决的形式，但投票时容易出现投票悖论。由于投票悖论的不可避免性，人们就面临着如何处理投票悖论这一实际问题。为了克服投票悖论造成的困难，人们提出采用某种与群众成员的偏好有关的数量指标来反映群，即社会，对各候选人的总体评价，这种指标称为社会选择函数。 在这里，我们关注于社会选择理论中的社会选择函数，介绍其相关定义及其多种形式。 社会选择函数的定义和性质定义设 $N=\{1,\dots,n\}$ 表示群，即投票人的集合；$A=\{a_1,\dots,a_m\}$ 表示备选方案（候选人）集合；$n_{jk}$ 或 $N(a_j \succ a_k)$ 表示群众认为 $a_j$ 优于 $a_k$ 的成员数。 采用上述记号，过半数规则可以表示为： 对 $a_j,a_k \in A $ ，若 $n_{jk}&gt;n_{kj}$ ，则 $a_j \succ_G a_k$ ；若 $n_{jk}=n_{kj}$ ，则 $a_j \sim_G a_k$ 设群中有 $n$ 个成员，对成员 $i$ 及方案对 $x,y \in A$ ，引入变量 $D_i$ 。$D_i$ 的取值为-1，0，1：若成员 $i$ 认为 $x$ 优于 $y$ ，即 $x \succ_i y$，则 $D_i=1$ ；认为 $x$与 $y$ 无差异，即 $x \sim_i y$，则 $D_i=0$；认为 $y$ 优于 $x$ ，即 $y \succ_i x$ ，则 $D_i=-1$，即： D_i= \left\{ \begin{aligned} 1 \qquad & x P_i y \\ 0 \qquad & x I_i y \\ -1 \qquad & y P_i x \\ \end{aligned} \right. \tag{1}群即社会中各成员的偏好分布为 $D=(D_1,\dots,D_n)$ ；偏好分布的集合 $\mathfrak{D}=\{-1,0,1\}^n$。社会选择函数 $F$ 要从各成员的偏好分布产生社会的排序，即 $\forall D \in \mathfrak{D}$ ，$F(D)=f(D_1,\dots,D_n)$ ，且： F(D)= \left\{ \begin{aligned} 1 \qquad & x \succ_i y \\ 0 \qquad & x \sim_i y \\ -1 \qquad & y \succ_i x \\ \end{aligned} \right. \tag{2}即：$F:\{-1,0,1\} \rightarrow \{-1,0,1\}$ 性质(1) 明确性：$D \neq 0 \rightarrow F(D) \neq 0$ (2) 中性，又称对偶性，对候选人的公平性：$f(-D_1,\dots,-D_n)=-f(D_1,\dots,D_n)$ (3) 匿名性，又称平等原则，各成员的权利相同：$f(D_1,\dots,D_n)=f(D_{\sigma(1)},\dots,D_{\sigma(n)})$ . 其中，$\sigma $ 是 $1,\dots,n$ 的新排列。 (4) 单调性，又称正响应：若 $D \geq D’$ ，则 $F(D) \geq F(D’)$ . (5) 一致性，又称 Weak Pareto 性：$f(1,1,\dots,1)=1$ 或 $f(-1,-1,\dots,-1)=-1$ (6) 齐次性：对任意正整数 $m$，$F(mD)=F(D)$ . (7) Pareto 性：$\forall i,D_i \in \{1,0\}$ 且对某些 $k$ ，$D_k=1 \rightarrow F(D)=1$ ；$\forall i,D_i=0 \rightarrow F(D)=0$ . 社会选择函数的几种形式Condorcet函数Condorcet原则规定，在从多个候选人中选择一个时，如果存在某个候选人 $x$，能在与其他候选人逐一比较时按过半数决策规则击败其他所有人，则 $x$ 称为 Condorcet 候选人，应该由他当选。如果不存在 Condorcet候选人，则应采用函数： f_C(x)=\min_{y \in A /\{x\}}N(x \succ_i y)按 $f_C(x)$ 值的大小来排列候选人 $x$ 的优劣次序。 示例： 23人认为：$a \succ b \succ c$ ；17人认为：$b \succ c \succ a$ ；2人认为：$b \succ a \succ c$ ；10人认为：$c \succ a \succ b$ ；8人认为：$c \succ b \succ a$ ； 所有候选人成对比较的结果是：$a \succ_G b$ ，$b \succ_G c$ ，$c \succ_G a$ ，出现过半数票的循环，需采用 Condorcet 函数，即： N(a \succ_i b) =33,N(a \succ_i c) =25 \rightarrow f_C(a)=25 \\ N(b \succ_i a) =27,N(b \succ_i c) =42 \rightarrow f_C(b)=27 \\ N(c \succ_i a) =35,N(c \succ_i b) =18 \rightarrow f_C(c)=18 \\由上可得，候选人 $a​$ 应该当选。 Borda函数由每个投票人对各候选人排序，设 $A$ 中有 $m$ 个候选人，则将 $m-1,m-2,\dots,1,0$ 这个 $m$ 个数分别赋予排在第一位、第二位……最末位的候选人，然后计算各候选人的得分总数（Borda分）。得到最高 Borda 分的候选人为胜者，Borda分即 Borda 函数为： f_B(x)=\sum_{y \in A/ \{x\}}N(x \succ_iy)候选人按 $f_B(x)​$ 值的大小排序。$f_b(x)​$ 是 $x​$ 与其他候选人逐一比较时 $m-1​$ 次中所得票数的总和。 示例： 同见上例。 Borda分的计算：将 2，1，0 分别赋予排在第一、第二、第三位的候选人，则有： $a$ 的Borda分：$2 \times 23+1 \times (2+10)=58$ $b$ 的Borda分：$2 \times (17+2)+1 \times (23+8)=69$ $c$ 的Borda分：$2 \times (10+8)+1 \times 17=53$ 由上可得，候选人 $b$ 应该当选。 Copeland函数令 $f_{cp}(x)=N\{y:y \in A \cup x \succ_G y \}-N\{y:y \in A \cup y \succ_G x \}$ ，并以 $f_{cp}(x)$ 的大小来排定 $x$ 的优劣。其中， $N\{y:y \in A \cup x \succ_G y \}$ 表示 $x$ 能按过半数决策规则击败的方案集 $A$ 中的候选人个数，$N\{y:y \in A \cup y \succ_G x \}$ 则表示在方案集 $A$ 中能按过半数规则击败 $x$ 的候选人个数，因此 $f_{cp}(x)$ 是 $x$ 在与其他候选人逐一比较时获胜次数与失败次数之差。 同样以上例为例子： N(a \succ_i b) =33>N(a \succ_i c) =25 \\ N(b \succ_i a) =27N(c \succ_i b) =18 \\因此，$f_{cp}(a)=N\{y:y \in A \cup a \succ_G y \}-N\{y:y \in A \cup y \succ_G a \}=1-1=0​$ ，$f_{cp}(b)=1-1=0​$， $f_{cp}(c)=1-1=0​$ . 根据 Copeland 函数，$a,b,c$ 成平局。 Nanson函数Nanson的淘汰过程可表述如下： 令 $A_1=A$ ，对 $j \geq 1$，令 A_{j+1}=A_j / \{x \in A_j;f_B(x) \leq f_B(y), \forall y \in A_j \}且 $\exists y \in A $ ，使 $f_B(x)&lt;f_B(y)$ 其中 $f_B(x)=\sum_{y \in A/ \{x\}}N(x \succ_iy)$ 为 Borda 分。 上式的含义是集合 $A_j$ 中淘汰 Borda 分最小的方案 $x$ 后，得到结合 $A_{j+1}$ 。 令 $f_N(x)=\max \{j:x \in A_j\}$ ，即方案 $x$ 在第 $j$ 次被淘汰，则 $x$ 的 Nanson函数值等于 $j$ 。$f_N(x)$ 的值最大的方案为当选者。 示例： 还是上例，先令 $A_1=A=\{ a,b,c\}$ ，计算 Borda 分： f_B(a)=58,f_B(b)=69,f_B(c)=53由于 $c$ 得分最低而被淘汰，$f_N(c)=1$ ，且得 $A_2=\{a,b\}$ ；这时有 $23+10=33$ 人认为 $a \succ b$ ，所以 $f_B(a)=33,f_B(b)=27$ ，$b$ 被淘汰，$f_N(b)=2$，且 $A_3=A_2 / \{b\}=\{ a\}$ ；因只剩一人，$f_N(a)=3$ ，$a$ 为胜者。社会选择的排序为 $a \succ_G b \succ_G c$ 。 Dodgson函数根据候选人要能成为简单过半数胜者（或非失败者），需要改变偏好序的投票人人数来给候选人打分，分值越小越好。 设有 $n$ 个投票人，$m$ 个候选人，候选人之间成对比较的结果记为 $n_{jk}$ ，即： n_{jk}=N(a_j \succ_i a_k),i,k=1,\dots,m,i \neq k用 $n_0$ 表示候选人 $a_j(j=1,\dots,m)$ 作为简单过半数胜者（或非失败者）至少应有的票数，则有： n_0= \left\{ \begin{aligned} n/2 \qquad \qquad 当 n 为偶数时\\ (n+1)/2 \qquad 当 n 为奇数时 \end{aligned} \right.设 $n_{jj}=n_0$ ，则 Dodgson 的社会选择函数为： f_D(a_j)=\sum^m_{k=1} \frac{|n_0-n_{jk}|+(n_0-n_{jk})}{2} \qquad j=1,\dots,m$f_D(a_j)$ 的值越小，$a_j$ 越优。 在计算 $f_D(\cdot)$ 时，也可用候选人之间成对比较的结果构成 Dodgson矩阵： D= \begin{bmatrix} 1 & n_{12}/n_{21} & \dots & n_{1m}/n_{m1} \\ n_{21}/n_{12} & 1 & \dots & n_{2m}/n_{m2} \\ \vdots & \vdots & & \vdots \\ n_{m1}/n_{1m} & n_{m2}/n_{2m} & \dots & 1 \\ \end{bmatrix}并对第 $j$ 行中 $n_{jk}&lt;n_{kj}$ 的各项求 $n_0$ 与 $n_{jk}$ 之差，然后相加得到 $f_0(a_j)$ 。 示例： 还是上例。。各候选人两两比较的结果是： N(a \succ_i b) =33,N(a \succ_i c) =25 \\ N(b \succ_i a) =27,N(b \succ_i c) =42 \\ N(c \succ_i a) =35,N(c \succ_i b) =18 \\出现了多数票循环：$a \succ_G b,b \succ_G c,c \succ_G a $。 将成对比较的结果列入 Dodgson矩阵，有： \begin{bmatrix} -& 33/27 &25/35 \\ 27/33 &- & 42/18 \\ 35/25 & 18/25 &- \end{bmatrix}其中，由于 $n_{0}=30,n_{13}=25$ ，候选人 $a$ 要能在与 $c$ 比较时不成为失败者，至少需要5位投票人改变其偏好序，由原先认为 $c \succ_i a$变成$a \succ_i c$ ，因此 $f_D(a)=5$ ；类似地，有 $f_D(b)=3,f_D(c)=12$ 。由 $f_D(b)&lt;f_D(a)&lt;f_D(c)$ ，可得社会选择的排序是：$b \succ_G a \succ_G c$。 参考文献 岳超源. 决策理论与方法[M]. 科学出版社, 2003.]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>决策理论与方法</tag>
        <tag>群决策</tag>
        <tag>社会选择函数</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多目标决策——用KKT条件求非劣解]]></title>
    <url>%2F2018%2F04%2F26%2F34-%E5%A4%9A%E7%9B%AE%E6%A0%87%E5%86%B3%E7%AD%96%E2%80%94%E2%80%94%E7%94%A8KKT%E6%9D%A1%E4%BB%B6%E6%B1%82%E9%9D%9E%E5%8A%A3%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[之前曾写过一篇 高级运筹学之经典题目 ，有一题就是用KKT条件求解非线性规划。然而，在多目标决策中，想要找到最优解并不容易，退而求其次，我们可以根据目标寻找非劣解，KKT条件在寻找非劣解的过程中起到十分有效的帮助。KKT条件是什么？如何用KKT条件求非劣解？这是本文的主要关注点。本文主要参考岳超源的 《决策理论与方法》。 非劣解和KKT条件非劣解非劣解又称非控解 (non-dominance solution)、有效解 (efficient solution)、帕累托最优解 (Pareto-optimal solution)、锥最优解 (cone-optimal solution)。 设 $f(x)$ 为多目标决策问题向量目标函数，其分量 $f_j(x),j=1,2,\dots,n$ 均越大越优，对 $x^\ast \in X$ ，若在 $X$ 中不存在 $x$ 使 $f_j(x) \geq f_j(x^\ast)$ ，对 $j=1,2,3\dots,n$ ，且至少对一个 $j$ 严格不等式成立，则称 $x^\ast$ 为向量优化问题的非劣解。 如图，对于 $f_1(x)$ 和 $f_2(x)$ 来说，分别存在相应的最优解。因此，两个最优解之间的边界就是非劣前沿，可行域 $X$ 中与之对应的部分就是非劣解集。 KKT条件对多目标优化问题 \max \{f_1(x),\dots,f_n(x)\}受约束于： g_1(x) \leq 0 \\ \dots \\ g_2(x)\leq0若满足约束条件的非劣解 $x^\ast$ 是正则点，则存在向量 $\mu$ ，它的各分量 $\mu_i \geq 0,i=1,\dots,m$ ，并存在向量 $\lambda$ ，它的各分量 $\lambda_j \geq 0,j=1,\dots,n$ ，它使 x^\ast \in X \\ \mu_ig_i(x^\ast)=0 ,i=1,\dots,m \\ \sum^n_{j=1} \lambda_j \nabla f_j (x^\ast)-\sum^m_{i=1} \mu_i \nabla g_i (x^\ast)=0上述公式统称为KKT条件，KKT条件是多目标优化问题最优解 $x^\ast$ 的必要条件。若 $f(x)$ 是凹函数，$X$ 是凸集，则KKT条件是最优解 $x^\ast$ 的充分条件。 非劣解的生成知道了非劣解和KKT条件，我们则可以通过KKT条件对非劣解进行推导，求解主要有多种方法：线性加权法、 $\varepsilon$ 约束法 、序贯式解法和理想点法，在这里主要介绍前两种。 线性加权法 对多目标函数 $f_j(x),j=1,\dots,n$ 加权 $w_j$ ，则多目标优化问题可以变换为加权单目标优化问题： \max f(x,w)=\sum^n_{j=1}w_jf_j(x) \tag{1}受约束于：$x \in X$ 则优化问题的KKT条件为： x^\ast \in X \\ \mu_ig_i(x^\ast)=0,i=1,\dots,m \\ \nabla \left[ \sum^n_{j=1}w_jf_j(x^\ast)\right]-\sum^m_{i=1}\mu_i \nabla g_i(x^\ast)=0 \\ \tag{2} 由于： \nabla \left[ \sum^n_{j=1}w_jf_j(x^\ast)\right]=\sum^m_{j=1}w_j \nabla f_j(x^\ast)=0 \tag{3}将上式代入KKT条件，得： \sum^m_{j=1}w_j \nabla f_j(x^\ast)-\sum^m_{i=1}\mu_i \nabla g_i(x^\ast)=0 \tag{4}只要把式 (4) 中的 $w_j$ 看作 $\lambda_j$ ，$j=1,\dots,n$ ，即把权向量 $w$ 看作向量 $\lambda$ ，则式 (4) 就是多目标优化问题的非劣解的KKT条件。因此加权的单目标问题的最优解和原来的多目标问题的非劣解都满足相同的KKT条件。只要权向量的所有分量 $w_j \geq 0 ,j=1,\dots,n$ ，就能保证加权后的单目标优化问题的最优解是原来的多目标优化问题的非劣解。 $\varepsilon$ 约束法对多目标优化问题，可以选择某个目标，比如说第 $k$ 个，求 $f_k(x)$ 的极大值，形成如下单目标优化问题 \max f_k(x) \tag{5}受约束于： x \in X \\ f_j(x) \geq \varepsilon_j ,j=1,\dots,n,j \neq k \tag{6}这一单目标优化问题可以用通常的数学规划方式求解，它的最优解在一定条件下是原来的多目标优化问题的非劣解。 此时，KKT条件的第三个条件可写为： \lambda_k \nabla f_k(x^\ast)+\sum^n_{j=1,j \neq k}\lambda_j \nabla f_j(x^\ast) - \sum^m_{i=1}\mu_i \nabla g_i(x^\ast)=0 \tag{7}式中$\lambda_j \geq 0(i=1,\dots,n)$，$\mu_i \geq 0(i=1,\dots,m)$ 。设 $\lambda_k &gt;0$ ，则式 (7) 就是如下的单目标优化问题的KKT第三条件： \max \lambda_k f_k(x) \tag{8}受约束于： g_i(x) \leq 0 ,i=1,\dots,m \\ f_j(x) \geq \varepsilon_j ,j=1,\dots,n,j \neq k \tag{9}由于 $\lambda_k &gt;0$ ，因此用 $\lambda_k$ 除目标函数不会改变单目标优化问题的解；为了使式 (9) 符合KKT条件的标准形式，与式 (7) 等号左边第二项对应的约束条件应写作： -f_j(x)+\varepsilon_j \leq 0 \tag{10}上面的单目标优化问题即： \max f_k(x) \\ g_i(x) \leq 0 ,i=1,\dots,m \\ -f_j(x)+\varepsilon_j \leq 0,j=1,\dots,n ,j \neq k \tag{11}式 (10) 中的 $\varepsilon_j$ 是与 $x$ 无关的常数，这样式 (7) 等号左边第二项为： - \sum^n_{j=1,j \neq k} \lambda_j \nabla(-f_j(x^\ast)+\varepsilon_j)=\sum^n_{j=1,j \neq k} \lambda_j \nabla f_j(x^\ast) \tag{12} $\varepsilon_j$ 的选择必须使相应的单目标优化问题有解，而且所有由目标构成的约束条件在 $x=x^\ast$ 处都应当是起作用的，即： f_j(x^\ast) =\varepsilon_j,j=1,\dots,n,j \neq k \tag{13}用约束法求得的最优解 $x^0$ 有如下性质： (1) $\exists k \in J$ ，$x^0$ 是以 $f_k(x)$ 为目标函数的约束问题的唯一解； (2) $\forall k \in J$，$x^0$ 都是以 $f_k(x)$ 为目标函数的约束问题的解，则 $x^0$ 是原多目标优化问题的非劣解； (3) 对任何给定的非劣解 $x^\ast$ ，总能找到一个 $\varepsilon$ ，$\forall k \in J$，$x^*$ 是它们相应的约束问题的解。 参考文献 岳超源. 决策理论与方法[M]. 科学出版社, 2003.]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>决策理论与方法</tag>
        <tag>多目标决策</tag>
        <tag>KKT条件</tag>
        <tag>运筹学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态决策——隐马尔科夫模型]]></title>
    <url>%2F2018%2F04%2F25%2F33-%E5%8A%A8%E6%80%81%E5%86%B3%E7%AD%96%E2%80%94%E2%80%94%E9%9A%90%E9%A9%AC%E5%B0%94%E7%A7%91%E5%A4%AB%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[动态决策也是 决策理论与方法 中的一种重要形式，之前讲了 不确定型决策 和 风险决策 ，以及不同决策下的一些最常用的算法。今天主要讲解动态决策，当然解决动态规划的算法有许多，比如动态规划、决策树、马尔科夫模型等等，当然这次我们要重点关注的是马尔科夫模型的进阶版——隐马尔科夫模型，该模型与贝叶斯方法多少存在了点相同之处，主要参考文献为李航的 《统计学习方法》 ，清华大学出版社出版。 隐马尔科夫模型的定义隐马尔科夫模型是关于时序的概念模型，描述由一个隐藏的马尔科夫链随机生成不可观测的状态随机序列，再由各个状态生成一个观测而产生观测随机序列的过程。隐藏的马尔科夫链随机生成的状态的序列，称为状态序列；每个状态生成一个观测，而由此产生的观测的随机序列，称为观测序列。序列的每一个位置又可以看作一个时刻。 一个隐马尔科夫模型 (HMM) 是一个五元组：$(Q,V,A,B,\pi)$ . 其中： $Q=\{ q_1,q_2,\dots,q_N\}$ 为状态的有限集合； $V=\{v_1,v_2,\dots,v_M\}$ 为观测值的有限集合； $A=[a_{ij}]_{N \times N}$ , $a_{ij}=P(i_{t+1}=q_j|i_t=q_i),i,j=1,\dots ,N$ 为状态转移概率矩阵； $B=[b_j(k)]_{N \times M}$ , $b_j(k)=P(o_t=v_k|i_t=q_j),k=1,\dots M,j=1,\dots,N$ 为观测概率矩阵； $\pi=(\pi_i)$ ，$\pi_i=p(i_1=q_i),i=1,\dots,N$ 为初始状态分布。 隐马尔科夫模型 $\lambda$ 也可表示为：$\lambda=(A,B,\pi)$ 。在此，马尔科夫模型做了三个基本假设： (1) 马尔科夫假设（状态构成一阶马尔科夫链） $P(i_t|i_{t-1},o_{t-1},\dots,i_1,o_1)=P(i_t|i_{t-1}), \ t=1,2,\dots,T$ (2) 不动性假设（状态与具体时间无关） $P(i_{t+1}|t_i)=P(i_{s+1}|i_s), \ t,s=1,\dots,T$ (3) 观测独立性假设（观测仅与当前状态有关） $P(o_t|i_T,o_T,i_{T-1},o_{T-1},\dots,i_{t+1},o_{t+1},i_t,i_{t-1},o_{t-1},\dots,i_1,o_1)=P(o_t|i_t)$ 隐马尔科夫模型的3个基本问题： (1) 概率计算问题：给定模型 $\lambda=(A,B,\pi)​$ 和观测序列 $O=(o_1,o_2,\dots,o_T)​$ ，计算在模型 $\lambda​$ 下观测序列 $O​$ 出现的概率 $P(O|\lambda)​$ . (2) 预测问题：也称解码问题。给定模型和观测值序列，求可能性最大的状态序列。 (3) 学习问题：已知观测序列，估计模型 $\lambda=(A,B,\pi)$ 参数，使得在该模型下观测序列概率 $P(O|\lambda)$ 最大，即用极大似然估计的方法估计参数。 由于学习问题涉及到EM算法训练参数，因此在这里我们先关注前两个问题，最后一个问题或许在以后进行详细讲解。 概率计算算法前向算法 前向概率：给定隐马尔科夫模型 $\lambda$ ，定义到时刻 $t$ 部分观测序列为 $o_1,o_2,\dots,o_t$ 且状态为 $q_i$ 的概率为前向概率，记作：$\alpha_t(i)=P(o_1,o_2,\dots,o_t,i_t=q_i|\lambda)$ 算法： 输入：隐马尔科夫模型 $\lambda$ ，观测序列 $O$ ；输出：观测序列概率 $P(O|\lambda)$ . (1) 初值：$\alpha_1(i)=\pi_ib_i(o_1) , \ i=1,2,\dots,N$ (2) 递推：对 $t=1,2,\dots,T-1$，$\alpha_{t+1}(i)=\left[\sum^N_{j=1}\alpha_t(j)a_{ji} \right]b_i(o_{t+1})$ (3) 终止：$P(O|\lambda)=\sum^N_{i=1}\alpha_T(i)$ 图片来源： 隐马尔可夫模型攻略 如图，我们需要对每一层的每个节点进行概率计算，$\alpha_t(i)$ 即为第 $t$ 层第 $i$ 个节点的前向概率。我们举个简单栗子吧！ 销售模型考虑一个销售模型 $\lambda=(A,B,\pi)$，状态集合 $Q=$ {畅销，平销，滞销}，观测集合 $V=$ {大量进货，小量进货}。设 $T=3$，$O=$ (大量进货，小量进货，大量进货)，试用前向算法计算 $P(O|\lambda)$ 。 A= \begin{bmatrix} 0.5 & 0.2 & 0.3 \\ 0.3 & 0.5 & 0.2 \\ 0.2 & 0.3 & 0.5 \\ \end{bmatrix}, B= \begin{bmatrix} 0.5 & 0.5 \\ 0.4 & 0.6 \\ 0.7 & 0.3 \\ \end{bmatrix}, \pi=(0.2,0.4,0.4)^T解：根据前向算法： (1) 计算初值：$\alpha_1(1)=\pi_1b_1(o_1)=0.10$ ; $\alpha_1(2)=\pi_2b_2(o_1)=0.16$ ; $\alpha_1(3)=\pi_3b_3(o_1)=0.28$ (2) 递推计算： \alpha_2(1)=\left[\sum^3_{i=1}\alpha_1(i)a_{i1} \right]b_1(o_2)=0.154 \times 0.5=0.077 \\ \alpha_2(2)=\left[\sum^3_{i=1}\alpha_1(i)a_{i2} \right]b_2(o_2)=0.184 \times 0.6=0.1104 \\ \alpha_2(3)=\left[\sum^3_{i=1}\alpha_1(i)a_{i3} \right]b_3(o_2)=0.202 \times 0.3=0.0606 \\ \alpha_3(1)=\left[\sum^3_{i=1}\alpha_2(i)a_{i1} \right]b_1(o_3)=0.04187 \\ \alpha_3(2)=\left[\sum^3_{i=1}\alpha_2(i)a_{i2} \right]b_2(o_3)=0.03551 \\ \alpha_3(3)=\left[\sum^3_{i=1}\alpha_2(i)a_{i3} \right]b_3(o_3)=0.05284 \\(3) 终止：$P(O|\lambda)=\sum^3_{i=1}\alpha_3(i)=0.13022$ 在这里我们使用了前向算法，还有一种后向算法，在计算过程上和前向算法也类似，在这里不做过多解释，大家可参考文献。在决策中，假设成本和定价固定，每天商家的进货量和销售状态随机，那么当商家每天的进货量为观测集 $O$ 时，我们可以计算出这样进货量的概率。然而给定进货量的多少时，我们是否能预测它的销售状态是畅销、平销还是滞销呢？这就要靠下面方面才可以解决了。 预测算法维特比 (Viterbi) 算法维特比算法实际是用动态规划解隐马尔科夫模型预测问题，即用动态规划求概率最大路径（最优路径）。这时一条路径对应着一个状态序列。 首先导入两个变量 $\delta$ 和 $\psi$ 。定义在时刻 $t$ 状态为 $i$ 的所有单个路径 $(i_1,i_2,\dots,i_t)$ 中概率最大值为： \delta_t(i)=\max_{i_1,i_2,\dots,i_{t-1}}P(i_t=i,i_{t-1},\dots,i_1,o_t,\dots,o_1|\lambda),i=1,2,\dots,N由定义可得变量 $\delta$ 的递推公式： \begin{aligned} \delta_{t+1}(i) &= \max_{i_1,i_2,\dots,i_t}P(i_{t+1}=i,i_t,\dots,i_1,o_{t+1},\dots,o_1|\lambda) \\ &= \max_{1 \leq j \leq N}[\delta_t(j)a_{ji}]b_i(o_{t+1}), \quad i=1,\dots,N;t=1,\dots,T-1 \end{aligned}定义在时刻 $t$ 状态为 $i$ 的所有单个路径 $(i_1,i_2,\dots,i_{t-1},i)$ 中概率最大的路径的第 $t-1$ 个结点为： \psi_t(i)=\arg\max_{1\leq j \leq N}[\delta_{t-1}(j)a_{ji}] ,i=1,2,\dots,N算法： 输入：模型 $\lambda=(A,B,\pi)$ 和观测 $O=(o_1,o_2,\dots,o_T)$ ； 输出：最优路径 $I^\ast=(i_1^{\ast},i_2^{\ast},\dots,i_T^{\ast})$ . (1) 初始化：$\delta_1(i)=\pi_ib_i(o_1),\psi_1(i)=0, \quad i=1,2,\dots,N$ (2) 递推. 对 $t=2,3,\dots,T$，$\delta_t(i)=\max_{1\leq j \leq N}[\delta_{t-1}(j)a_{ji}]b_i(o_t)$ , $\psi_t(i)=\arg\max_{1\leq j \leq N}[\delta_{t-1}(j)a_{ji}]$ (3) 终止：$P^{\ast}=\max_{1 \leq i \leq N}\delta_T(i),i^{\ast}_T=\arg\max_{1\leq i \leq N}[\delta_T(i)]$ (4) 最优路径回溯. 对 $t=T-1,T-2,\dots,1$，$i_t^{\ast}=\psi_{t+1}(i^{\ast}_{t+1})$ ，求得最优路径 $I^{\ast}=(i_1^{\ast},i_2^{\ast},\dots,i_T^{\ast})$ . 实例我们还是以上节中的销售模型作为例子，已知观测序列 $O=$(大量进货，小量进货，大量进货)，试求最优状态序列，即最优路径 $I^{\ast}=(i_1^{\ast},i_2^{\ast},i_3^{\ast})$ . 解：(1) 初始化.。在 $t=1$ 时，对每一个状态 $i$ ，$i=1,2,3$，求状态为 $i$ 观测 $o_1$ 为大量进货的概率，记此概率为 $\delta_1(i)$ ，则 \delta_1(1)=0.10,\delta_1(2)=0.16,\delta_1(3)=0.28记 $\psi_1(i)=0,i=1,2,3$ . (2) 在 $t=2$ 时，对每一个状态 $i$ ，$i=1,2,3$，求在 $t=1$ 时状态为 $j$ 观测为大量进货并在 $t=2$ 时状态为 $i$ 观测为 $o_2$ 为小量进货的路径的最大概率，记此最大概率为 $\delta_2(i)$ ，记录概率最大路径的前一个状态 $j$ : \delta_2(1)=\max_{1\leq j\leq3}[\delta_1(j)a_{j1}]b_1(o_2)=\max_j{0.10 \times 0.5,0.16 \times 0.3,028 \times 0.2} \times 0.5=0.028 \\ \psi_2(1)=3 \\ \delta_2(2)=0.0504,\psi_2(2)=3 \\ \delta_2(3)=0.042,\psi_2(3)=3同理，在 $t=3$ 时， \delta_3(1)=0.00756,\psi_3(1)=2 \\ \delta_3(2)=0.01008,\psi_3(2)=2 \\ \delta_3(3)=0.0147,\psi_3(3)=3(3) 以 $P^{\ast}$ 表示最优路径的概率，则 P^{\ast}=\max_{1 \leq i \leq 3 }\delta_3(i)=0.0147最优路径的终点是 $i^{\ast}_3$: i_3^{\ast}=\arg \max_i[\delta_3(i)]=3(4) 由最优路径的终点 $i_3^{\ast}$，逆向找到 $i_2^{\ast},i_1^{\ast}$ : 在 $t=2$ 时，$i_2^{\ast}=\psi_3(i_3^{\ast})=\psi_3(3)=3 $ 在 $t=1$ 时，$i_1^{\ast}=\psi_2(i_2^{\ast})=\psi_2(3)=3 $ 于是求得最优路径，即最优状态序列 $I^{\ast}=(i_1^{\ast},i_2^{\ast},i_3^{\ast})=(3,3,3)$ . 显然，如果进货方式为（大量进货，小量进货，大量进货），那么最有可能的销售状态都为滞销。根据这样的结果，商家可以动态调控进货量，算出如何进货将导致什么销售状态的概率，从而避免滞销。 以上只是对隐马尔科夫模型进行加以说明的简单例子，在实际背景上可能还需考虑更多细节，然而隐马尔科夫模型显然在动态决策中可以进行很好的应用。本文仅涉及了隐马尔科夫的两个问题，还有学习问题在以后有机会介绍EM算法时会进行详解。 参考文献 李航. 统计学习方法[M]. 清华大学出版社, 2012. 隐马尔科夫模型 隐马尔可夫模型攻略]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>决策理论与方法</tag>
        <tag>动态决策</tag>
        <tag>隐马尔科夫</tag>
        <tag>HMM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[风险型决策——贝叶斯分析]]></title>
    <url>%2F2018%2F04%2F24%2F32-%E9%A3%8E%E9%99%A9%E5%9E%8B%E5%86%B3%E7%AD%96%E2%80%94%E2%80%94%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[通常现实生活中的决策，风险型决策和不确定型决策占了大部分。之前写过用粗糙集方法去解决不确定型决策，这次我们主要采用贝叶斯分析的方法去解决风险型问题。本文主要参照了岳超源的《决策理论与方法》 一书，由科学出版社出版。 贝叶斯风险与贝叶斯规则我们知道，风险型决策的基本方法是将状态变量视为随机变量，用先验状态分布表示状态变量的概率分布，用期望值准则计算方案的满意程度。而贝叶斯决策则认为先验状态分布与实际情况存在一定误差，为了提高决策质量，需要通过调查或随机试验，收集有关状态变量的补充信息，对先验分布进行修正，用后验状态分布进行决策。 首先，我们定义一下风险函数。给定自然状态 $\theta$ ，采取决策规则 $\delta$ 时，其损失函数为 $l(\theta,\delta(x))$ ，那么风险函数则为损失函数对随机实验后果（观测结果） $x$ 的期望值，记作 $R(\theta,\delta)$，即 R(\theta,\delta)=E_{\theta}^{X}[l(\theta,\delta(x))] \tag{1}贝叶斯风险当自然状态的先验概率为 $\pi(\theta)$，决策人采用策略 $\delta$ 时，风险函数 $R(\theta,\delta)$ 关于自然状态 $\theta$ 的期望值称为贝叶斯风险，记作 $r(\pi,\delta)$，即 r(\pi,\delta)=E^{\pi}[R(\theta,\delta)]=E^{\pi}\big[E_{\theta}^{X}[l(\theta,\delta(x))]\big] \tag{2}当 $\theta$、$x$ 为连续型随机变量，$\pi(\theta)$ 为先验概率密度函数，则： \begin{aligned} r(\pi,\delta) & =\int_{\theta \in \Theta}R(\theta,\delta)\pi(\theta)d\theta \\ &=\int_{\theta \in \Theta}\int_{x \in X}l(\theta,\delta(x))f(x|\theta)dx\cdot \pi(\theta)d\theta \end{aligned} \tag{3}当 $\theta$、$x$ 为离散型随机变量，$\pi(\theta)$ 为先验概率，则： \begin{aligned} r(\pi,\delta) & =\sum_{\theta \in \Theta}R(\theta,\delta)\pi(\theta) \\ &=\sum_{\theta \in \Theta}\sum_{x \in X}l(\theta,\delta(x))p(x|\theta)\cdot \pi(\theta) \end{aligned} \tag{4}如果 $r(\pi,\delta_1)&lt;r(\pi,\delta_2)$，则称策略 $\delta_1$ 优于 $\delta_2$ ，记作 $\delta_1 \succ \delta_2$。这就是正规型的贝叶斯分析。 贝叶斯决策规则先验分布为 $\pi(\theta)$ 时，若策略空间存在某个策略 $\delta^{\pi}$ ，能够使： \forall \delta \in \Delta, \ r(\pi,\delta^{\pi}) \leq r(\pi.\delta)则称 $\delta^{\pi}$ 是贝叶斯规则，亦称贝叶斯策略。也就是说，最优的决策规则是贝叶斯规则$\delta^{\pi}$ ，它能使贝叶斯风险 $r(\pi,\delta)$ 极小化，即进行贝叶斯分析时应该选择 $\delta^{\pi}$， 使： r(\pi,\delta^{\pi})=\min_{\delta \in \Delta}{r(\pi,\delta)} \tag{5}贝叶斯分析的扩展型在解实际问题时，求使(3)式极小的 $\delta(x)$ 往往十分困难，尤其在状态和观察值比较复杂时，$\Delta$ 集中的策略数目很大，穷举所有的 $\delta(x)$ 有困难，且计算量颇大。因此实际计算时往往采用扩展型的贝叶斯分析。 因为自然状态的概率分布 $\pi(\theta)$ 、似然函数 $f(x|\theta)$ 和损失函数 $l(\theta,\delta(x))$ 均为有限值。由 Fubini 定理，式(3)中的积分次序可换，即： \begin{aligned} r(\pi,\delta) &=\int_{\theta \in \Theta}\int_{x \in X}l(\theta,\delta(x))f(x|\theta)dx\cdot \pi(\theta)d\theta \\ &=\int_{x \in X} \left[ \int_{\theta \in \Theta}l(\theta,\delta(x))f(x|\theta) \pi(\theta)d\theta \right]dx \end{aligned} \tag{6}显然，要使式(6)达到最小，应对每个 $x \in X$，选择一 $\delta$ ，使式(6)中括号内的积分（记作 $r’$）极小： r'=\int_{\theta \in \Theta}l(\theta,\delta(x))f(x|\theta) \cdot \pi(\theta)d\theta \tag{7}因为观察值 $x$ 的边缘分布 $m(x)&gt;0$ ，使式(7)为极小，必然会使下式极小： \begin{aligned} r''&=(m(x))^{-1} \cdot\int_{\theta \in \Theta}l(\theta,\delta(x))f(x|\theta) \cdot \pi(\theta)d\theta \\ &=\int_{\theta \in \Theta}l(\theta,\delta(x))\left[ \frac{f(x|\theta) \cdot \pi(\theta)}{m(x)} \right]d\theta \\ &=\int_{\theta \in \Theta}l(\theta,\delta(x)) \pi(\theta|x)d\theta \end{aligned} \tag{8}当 $\theta$、$x$ 为离散型随机变量时，式(8)即： r''=\sum l(\theta,\delta(x)) \pi(\theta|x) \tag{9}对每个观察值 $x​$ ，选择行动 $\delta​$ ，使之对给定 $x​$ 时自然状态 $\theta​$ 的后验分布 $\pi(\theta|x)​$ 的期望损失为最小，或者使式(7)最小化，即可求得贝叶斯规则 $\delta^{\pi}​$ 。 实例农民选择作物问题，设某地旱年 $\theta_1$ 占60%，正常年景 $\theta_2$ 占40%；$a_1$ 种植耐旱作物，$a_2$ 种不耐旱作物，结果矩阵见下表。为了更有把握地进行决策，决策者决定收集各状态更准确的信息——了解当年的气象预报。设气象预报的准确性为0.8，且决策者的效用函数为 $u(y)=\frac{1}{0.865}(1-e^{-0.02y})$ 。问应该如何种植作物最优？ $a_1$ $a_2$ $\theta_1$ 20 0 $\theta_2$ 60 100 解： 设 $x_1$ 预报干旱，$x_2$ 预报正常年景，则 $p(x_1|\theta_1)=0.8,\ p(x_2|\theta_2)=0.8$ ，且 $m(x_1)=p(x_1|\theta_1)\pi(\theta_1)+p(x_1|\theta_1)\pi(\theta_2)=0.8 \times 0.6+0.2 \times 0.4=0.56$ . 类似地，$m(x_2)=0.44$。 同时有，$\pi(\theta_1|x_1)=p(x_1|\theta_1)\pi(\theta_1)/m(x_1)=0.8 \times 0.6/0.56=0.86$ ，$\pi(\theta_1|x_2)=p(x_2|\theta_1)\pi(\theta_1)/m(x_2)=0.2\times 0.6/0.44=0.27$ ，类似地，$\pi(\theta_2|x_1)=0.14$，$\pi(\theta_2|x_2)=0.73$ 。 正规型分析 主要分析4种情况：(1)预报旱年种耐旱作物，预报正常种不耐旱作物；(2)预报旱年种不耐旱作物，预报正常种耐旱作物；(3)不管预报什么年都种耐旱作物；(4)不管预报什么年都种不耐旱作物 （1）策略 $\delta_1$ : $a_1=\delta_1(x_1), \ a_2=\delta_1(x_2)$ \begin{aligned} r(\pi,\delta_1) &= \sum_i \sum_j l(\theta_i,\delta_1(x_j))p(x_j|\theta_i)\pi(\theta_i) \\ &= l(\theta_1,a_1)p(x_1|\theta_1)\pi(\theta_1)+ l(\theta_1,a_2)p(x_2|\theta_1)\pi(\theta_1) \\ &+l(\theta_2,a_1)p(x_1|\theta_2)\pi(\theta_2) l(\theta_2,a_2)p(x_2|\theta_2)\pi(\theta_2) \\ &= 0.62 \times 0.8 \times 0.6+1.0 \times 0.2 \times 0.6+0.19 \times 0.2 \times 0.4+0.0 \times 0.8 \times 0.4 \\ &=0.4328 \end{aligned}（2）策略 $\delta_2$ ：$a_1=\delta_2(x_2), \ a_2=\delta_2(x_1)$ \begin{aligned} r(\pi,\delta_2) &= \sum_i \sum_j l(\theta_i,\delta_2(x_j))p(x_j|\theta_i)\pi(\theta_i) \\ &= l(\theta_1,a_1)p(x_2|\theta_1)\pi(\theta_1)+ l(\theta_1,a_2)p(x_1|\theta_1)\pi(\theta_1) \\ &+l(\theta_2,a_1)p(x_2|\theta_2)\pi(\theta_2) +l(\theta_2,a_2)p(x_1|\theta_2)\pi(\theta_2) \\ &= 0.62 \times 0.2 \times 0.6+1.0 \times 0.8 \times 0.6+0.19 \times 0.8 \times 0.4+0.0 \times 0.8 \times 0.4 \\ &=0.6152 \end{aligned}（3）策略 $\delta_3$ ：$a_1=\delta_3(x_1), \ a_2=\delta_3(x_2)$ ，可得 $r(\pi,\delta_3)=0.45$ （4）策略 $\delta_4$ ：$a_2=\delta_4(x_1), \ a_2=\delta_4(x_2)$ ，可得 $r(\pi,\delta_4)=0.6$ 显然，$r(\pi,\delta_1)&lt;r(\pi,\delta_3)&lt;r(\pi,\delta_4)&lt;r(\pi,\delta_2)$ ，$\delta_1 \succ \delta_3 \succ \delta_4 \succ \delta_2$ ，$\delta_1$ 是贝叶斯行动。 扩展型分析 给定 $x_1$ ： (1) 采用 $a_1$ ： \begin{aligned} r''&=\sum l(\theta,\delta(x)) \pi(\theta|x) \\ &=l(\theta_1,a_1)\pi(\theta_1|x_1)+l(\theta_2,a_1)\pi(\theta_2|x_1) \\ &=0.62 \times 0.86+0.19 \times 0.14 \\ &=0.56 \end{aligned}(2) 采用 $a_2​$ : \begin{aligned} r''&=l(\theta_1,a_2)\pi(\theta_1|x_1)+l(\theta_2,a_2)\pi(\theta_2|x_1) \\ &=1.0 \times 0.86+0 \times 0.14 \\ &=0.86 \end{aligned}所以在预报旱年的情况下，应种植耐旱作物。 给定 $x_2$ ： (1) 采用 $a_1$ ： \begin{aligned} r''&=l(\theta_1,a_1)\pi(\theta_1|x_2)+l(\theta_2,a_1)\pi(\theta_2|x_2) \\ &=0.62 \times 0.27+0.19 \times 0.73 \\ &=0.306 \end{aligned}(2) 采用 $a_2$ ： \begin{aligned} r''&=l(\theta_1,a_2)\pi(\theta_1|x_2)+l(\theta_2,a_2)\pi(\theta_2|x_2) \\ &=1.0 \times 0.27+0 \times 0.73 \\ &=0.27 \end{aligned}所以在预报正常年景的情况下，应种植不耐旱作物。 由此得形式贝叶斯规则 $\delta^{\pi}$ 为：$a_1=\delta^{\pi}(x_1), \ a_2=\delta^{\pi}(x_2)$ 参考文献 岳超源. 决策理论与方法[M]. 科学出版社, 2003.]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>决策理论与方法</tag>
        <tag>风险决策</tag>
        <tag>贝叶斯分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[已知需求分布下报童问题的决策偏差]]></title>
    <url>%2F2018%2F04%2F13%2F31-%E5%B7%B2%E7%9F%A5%E9%9C%80%E6%B1%82%E5%88%86%E5%B8%83%E4%B8%8B%E6%8A%A5%E7%AB%A5%E9%97%AE%E9%A2%98%E7%9A%84%E5%86%B3%E7%AD%96%E5%81%8F%E5%B7%AE%2F</url>
    <content type="text"><![CDATA[在报童问题中，每天的报纸需求是随机的，报童每天只有一次机会去订购当天的报纸，且中途不能补货。如果报童的订货量远远大于当天的需求，那么他只能亏损处理没卖出的剩余报纸；如果报童的订货量小于当天的需求，那么他就卖不够，拿不到最大收益。那么，报童应该如何确定订货量去平衡卖不出和卖不够的亏损呢？ 显然，报童确定订货量的目标是期望收益最大化。然而研究发现，在大多数情况下报童的选择会与期望收益最大化方案大相径庭，甚至和大多数理论都不一致，比如说风险厌恶、风险偏好、前景理论、浪费厌恶、缺货厌恶等等，那么为什么会出现这样的情况？本文将介绍 Maurice et al. (2000) 在 Management Science 上发表的文章：Decision Bias in the Newsvendor Problem with a Known Demand Distribution: Experimental Evidence 。这篇文章将对报童问题的行为决策做出描述和解释。 Introduction报童问题发生在各行各业中，企业管理者时常也会面临报童问题。通常，经理的决策并非就是最大期望收益方案，为什么他们并不直接追求收益最大化呢？本文首先给出了几个原因： 相较于收益最大化，决策者有其他偏好 。如风险厌恶型决策者的订货量总会少于最大收益方案。 决策者需要探索性尝试来确认库存水准 。 决策者对每天的需求分布预测有偏差 。然而,在文章中是假设决策者已知需求分布的，因为通常企业经理都能获取到相似产品的历史数据。 文章中采用了两个实验来调查经理的库存决策，其中发现两种订货模式：(1) 高利润产品的订货量总是小于收益最大化方案；(2) 低利润产品的订货量总是大于收益最大化方案。 Descriptive Models of Newsvendor Decision Making设决策者销售时段前的初始订货量为 $q$ ，在一个销售时段内的随机需求量为 $D$ ，均值为 $\mu$ 。令 $F$ 为需求分布函数，则 $f$ 为需求密度函数。为简化模型，假设 $F$ 是连续可导且严格递增的。而且，假设决策人对分布函数的估计无差。那么，决策者每订货一个单位的成本为 $c$ ，售价为 $p$ ，$p&gt;c$ . 那么当$q&gt;D$ 时，在销售时段结束后每单位的退回价为 $s$ ，且 $s&lt;c$ 。 设 $\pi(q,D)$ 为净收益，则 \pi(q,D)=(p-s) \min(q,D)-(c-s)q期望收益为： E[\pi(q,D)]= \int_0^q f(x) \pi(q,x)dx+(1-F(q))\pi(q,q)令最大期望收益方案的订货量为 $q_n$，即 $q_n=\arg \max E[\pi(q,D)]$ ，可解得： F(q_n)=\frac{p-c}{p-s} \tag{1}证明可见附录。 这个比例 $(p-c)/(p-s)$ 称为临界分位数，文章将其作为产品的分类标准，即将高利润产品定义为： \frac{p-c}{p-s} \geq \frac{1}{2} \tag{2}反之则为低利润产品。 文章中还对风险中性、风险偏好、风险厌恶、前景理论、损失厌恶、浪费厌恶、缺货厌恶、低估机会成本等多种情况下的决策模型进行解释和求解，在这里不一一叙述。下图为以收益最大化决策方案订货量为基准，其他决策模型的订货量与基准的比较，“+”表示订货量比基准大，“-”表示订货量比基准小，“+/-”表示订货量可能比基准大，也可能比基准小。 Newsvendor Experiments前面的模型都是建立在别人的理论基础上的，每个模型似乎得到的决策方案都不尽相同，那么哪种会更符合企业经理的决策呢？文章又通过两个实验来验证在不同边际利润下决策者的决策方案，并解释这些方案与利润最大化方案的区别在哪里。 实验 1 ：均匀分布实验第1个实验主要调查在重复环境下受测者对高利润产品的低利润产品的订货决策，需求分布函数已知且服从参数区间为 $[1,300]$ 均匀分布。 Methods 34名受测者来自杜克大学MBA专业的学生，每个受测者都会收到一个计算机程序，这个程序中有一个销售 “wodgets” 的库存问题。受测者无法获知销售的次数，以及未来每轮销售中产品的成本和价格。程序将提示受测者做出30次订货决策。 受测者在每次决策前都会被提供产品的成本和需求量，”Wodgets” 销售价格为12法郎，回收价格为 0。低利润 “Woegets”的成本为9法郎，高利润 “Woegets” 的成本为3法郎。那么，低利润的临界分位数为 $(12-9)/(12-0)=25\%$ ，高利润的临界分位数为 $(12-3)/(12-0)=75\%$ 。 根据均匀分布的分布函数，可得：对于高利润产品，收益最大化的订货量为 $q_n=225$ ，期望收益为 675 法郎；对于低利润产品，收益最大化的订货量为 $q_n=75$ ，期望收益为 75 法郎。 每个受测者对于高利润产品和低利润产品都分别做出15次订货决策，其中20个受测者先对高利润产品做决策，14个受测者先对低利润产品做决策。受测者可获得每次决策后产生的收益等所有信息。 Results 从上面两图可见，可得出以下结论： 对于高利润产品，受测者的订货量总是低于收益最大化方案；而对于低利润产品，受测者的订货量总是高于收益最大化方案。 受测者对于高利润产品的订货量均值为176.68，对于低利润产品的订货量均值为134.06，平均来说，高利润产品的订货量远大于低利润产品。 对于高利润产品，其平均订货量与收益最大化订货量相差48个单位，期望收益相差 5% ；对于低利润产品，其平均订货量与收益最大化订货量相差59个单位，期望收益相差 61%。 文章还定义了调整分数 (adjustment score)，来对结果更深入地进行分析： Adjustment \ Score=\frac{q_t-q_{t-1}}{d_{t-1}-q_{t-1}} \tag{3}式中，$t$ 为销售阶段，$q$ 为订货量，$d$ 为需求量。 当调整分数为正时，存在两种情况：(1)上一阶段中，若需求量大于订货量，则这一阶段的订货量要大于上一阶段订货量；(2)上一阶段中，若需求量小于订货量，则这一阶段的订货量要小于上一阶段订货量。 显然，当调整分数为正时，很好理解，打个比方，去年货订得比需求多，卖不完，那么今年订少点，去年订的货不够卖，今年订多点。我们把这样的调整称为正向调整。 当调整分数为负时，也有两种情况，但和正向调整思路相反，我们把这样的调整称为负向调整。 如上图所示， 大部分决策者的订货量基本不发生变化； 大部分订货量进行正向调整的决策要高于负向调整； 在前期的销售阶段，决策者会更倾向于调整订货量。 实验 2 ：高需求分布实验实验 1 的结论已经和大多数原则产生不同，比如说风险厌恶、风险偏好、浪费厌恶、缺货厌恶等，因为这些理论都只追求一个目标最优；然而，前景理论它也是行为决策的一种，它认为相比于盈利，损失更令人难以承受。因此，当销售获利时，决策者总会减少订货量，从而避免在下个销售时期内亏损。因此，文章设计了第2个实验，观察决策者在绝对获利情况下的决策方案。 Methods 相较于实验 1 ，实验 2 对需求分布函数做了部分调整，即增加了参数为[901,1200] 的均匀分布区间，表示高需求范围。那么我们做一下简单计算可以发现，即使决策者订货量最大为 1200，而需求量最小为 901，低利润产品仍能盈利12法郎，而高利润产品能盈利 7212 法郎。 那么在低需求范围下，高利润和低利润产品的收益最大化订货量分别为225和75；而在高需求范围下，高利润和低利润产品的收益最大化订货量分别为1125和975。 实验 2 重新挑选了44位杜克大学MBA学生进行实验，实验流程和实验1 相同。 Results 结果显示，当上个销售阶段的需求量和订货量相差很大时，受测者更倾向于进行正向调整。这和前景理论的结果并非完全一致。 General Discussion文章中主要的结论就是，在行为决策中，决策者的决策方案往往会和期望最大化原则背道而驰。在文章的两个实验中，可见决策者在对不同边际利润下的产品会做出不同的选择，如对于高利润产品，决策者的订货量会低于收益最大化订货量，而对于低利润产品，决策者的订货量会高于收益最大化订货量。 这个结果在大多数决策原则下是不能够解释的。当然，这个结果和前景理论会有相似的地方，但也不能完全被前景理论所解释。 在文献中，报童问题通常是采用期望收益最大化原则进行求解，而在本文中第一次研究了报童问题的行为决策方案。决策者通常会对模型求解出来的最优方案做出修正，本研究对此做出解释，这是值得大家关注的。事实上，行为决策的出现说明了传统收益最大化的原则，其假设上是有缺陷的，在研究上应该采用更新的技术去对过去的理论进行完善和补充。 Appendix式 (1) 证明： \begin{aligned} E[\pi(q,x)] &= p \int_0^qxf(x)dx+pq \int_q^{\infty}f(x)dx+s \int_0^q(q-x)f(x)dx-cq \\ &=p \int_0^qxf(x)dx+pq \big[1-\int_0^q f(x)dx \big]+s \int_0^q qf(x)dx-s \int_0^q xf(x)dx-cq \\ &=(p-s)\int_0^q xf(x)dx-(p-s)qF(q)+(p-c)q \\ &=(p-s)\big[qF(q)-\int_0^q F(x)dx\big]-(p-s)qF(q)+(p-c)q \end{aligned}$E[\pi(q,x)]$ 对 $q$ 求导，得： \begin{aligned} \frac{\partial E[\pi(q,x)]}{\partial q} &=(p-s)qf(q)-(p-s)F(q)-(p-s)qf(q)+(p-c) \\ &=(p-c)-(p-s)F(q) \\ \end{aligned}令导数为 0 ，可解得： F(q)=\frac{p-c}{p-s}Reference Schweitzer M E, Cachon G P. Decision bias in the newsvendor problem with a known demand distribution: Experimental evidence[J]. Management Science, 2000, 46(3): 404-420.]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>决策理论与方法</tag>
        <tag>报童问题</tag>
        <tag>行为决策</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Structuring Machine Learning Projects - Week 2 - (3)]]></title>
    <url>%2F2018%2F04%2F10%2F30-Structuring-Machine-Learning-Projects-Week-2-3%2017.02.59%2F</url>
    <content type="text"><![CDATA[这是深度学习第3门课程第2周的最后一部分，主要介绍一下迁移学习和多任务学习，以及 End-to-end deep learning。这是什么意思？欢迎大家关注！ Learning from multiple tasksTransfer learning迁移学习，简单理解就是一个神经网络将从一个任务中训练学习到的知识，应用到另一个任务中的过程，把已学训练好的模型参数迁移到新的模型来帮助新模型训练。比如说，一个图像识别的神经网络，它在识别猫图中学习到了一些特征，并将这些知识（特征）使用在读 X光图像中，这就是迁移学习。那么迁移学习具体是怎么进行的呢？ 我们看上面一个神经网络，这个神经网络的目的主要是为了图像识别，那么输入层的输入 $x$ 则是图片，图片可以是猫、狗、小鸟或其它。当我们在训练之后，我们希望将这个神经网络应用到X光扫描任务，不再是简单的识别猫图，那么我们可以将神经网络的最后的输出层删掉，并删掉输入该层的权重，重新随机初始权重，并建立新的输出层，X光扫描图数据集中进行重新训练。 具体来讲，迁移学习就包含两个步骤，(1)普通图像的训练，在训练中得到所有的参数，如每一层的权重等，保持不变作为其它任务的参数；(2)将普通图像识别的任务迁移到X光图像识别的任务，在这里必须将最后一层的参数 $w^{[l]}$ 和 $b^{[l]}$ 随机初始化，并在X光扫描图数据集中进行重新训练。 若你的X光扫描图数据集比较小，那么你可以仅重新训练最后一层或最后两层的参数，保持其他层数的原参数不变；若你的X光扫描图数据量大，那么你可以重新训练所有层数的参数。 当然如果你选择重新训练所有层数的参数，那么最初的普通图像识别训练阶段就称为 pre-training. 而你后面采用新数据集更新参数的重新训练阶段称为 fine tuning. 那么为什么要这么麻烦？一开始不直接训练X光图呢？ 事实上，图像一般是有共性的，哪些X光图和普通图片在人类眼中简直天壤之别，但是如一些低层次的特征，如图形边缘、曲线、点等，模型在普通图片中更容易发掘此类特征，而且相对于X光照，其他普通图片能获取的数量多得多。因此，首先通过对普通图像进行训练，得到一些有用的知识（参数），并将这些知识迁移到 X光图的识别当中，在重新训练的过程中，需要的X光图数据集可以更小，训练的速度也会更快。 从这里我们便可以知道，由于X光图比其他普通图片更难获取，因此根据X光图和普通图片的一些共同特征，我们采用其他图片替代X光图进行训练。在迁移学习中，我们便将一个能够获取大量数据的问题迁移到一个数据量少的问题上了。当然，如果能获取大量的X光图，那么便不需要训练普通图片了。若是训练普通图片，即使不会降低训练效果，但也不保证会有更好的效果。 总结一下，When transfer learning makes sense? 假设你打算将任务A训练得到的参数迁移到任务B，那么： Task A and B have the same input $x$ . You have a lot more data for Task A than Task B. Low level features from A could be helpful for learning B. 第3点的意思是两个任务的数据必须存在部分共性的特征，这样训练 A 的数据得到的模型参数对训练 B 也有帮助。 因此，当你想要在某个目标问题上训练出好的效果，但又缺少大的数据量，那么你可以对相似问题的数据进行训练，获得某些共性特征，帮助你去解决目标问题，这是迁移学习最有用的地方。 Multi-task learning上节讲了迁移学习，它是将 Task A 的学习迁移到 Task B；而这节主要讲的是多任务学习，它将同时进行多个 Task 的学习。 举个例子，一个无人驾驶的汽车，它最主要的任务就是要探测出行人、其他车辆、路标和红绿灯等。 那么我们建立如上图的神经网络，针对每个样本 $x^{(i)}$ ，其输出 $y^{(i)}$ 是一个 $(4 \times 1)$的向量，每一行代表是否有行人、是否有其他车辆、是否有路标、是否有红绿灯。那么根据模型，我们即可写出损失函数： Loss=\frac{1}{m}\sum^m_{i=1}\sum^4_{j=1}L(\hat{y}_j^{(i)},y_j^{(i)})=-y_j^{(i)}\log \hat{y}_j^{(i)}-(1-y_j^{(i)})\log(1-\hat{y}_j^{(i)})这个多任务学习和我们之前所讲的 Softmax 多分类回归似乎挺相似，那它们之间到底有什么区别呢？其实很容易发现，在Softmax多分类中，每个样本只能归属到其中一类，也就是说每个样本只能有一个标签，比如说猫图识别，若使用Softmax，那么识别得到的要不是猫，要不是狗，要不是其它，不可能既是猫又是其它什么动物。而在多任务学习中，每个样本可以有多个标签，比如说无人驾驶识别路面情况，行人、其他车辆、路标和红绿灯都可能同时出现。于是在这里就存在了多个任务，既要识别行人和车辆，路标和红绿灯等通通都要识别出来。 当然你也可以单独建立4个模型分别检测路面情况，但正如我们上节所说，这4个任务其数据集都有很大的共性，有一些图像特征可以被4个模型所共享，那么建立一个模型训练多个任务，比建立4个模型单独训练一个任务会更高效，而且也能取得更好的效果。 值得注意的是，对部分仅标注了部分物体的图片，在多任务学习的训练中同样有效。比如说，有一些图片在进行人工数据标注时，标注者对图片标注了有行人、无其他车辆，还有路标和红绿灯等信息由于没注意到而缺少标注。那么在这种情况下，多任务学习在训练中不会产生问题，因为在损失函数中，我们只对有标签的值（0和1）进行计算，其余无标签项直接忽略，并不影响计算结果。 那么：When does multi-task learning make sense? Training on a set of tasks that could benefit from having shared lower-level features. Usually: Amount of data you have for each task is quite similar. 通常，多个任务的数据必须是相似的。这有什么用呢？假设有100个任务，对每个任务我们有1,000个样本数据，我们仅关注最后一个任务的 performance. 那么单独训练最后一个任务时，数据量就会显得相对较少。然而，同时训练多个任务时，还有99,000个样本数据量在训练中可以将学习到的知识用于最后一个任务的训练，那么这将极大地提高最后一个任务的 performance。对于每个任务都是一样，其他任务所学到的知识都用于所有任务的相互促进，对模型的效果提高是很大的。 当然，如果多个任务的样本数据量不一时，对于某个目标任务，其他任务的数据量至少要大于该目标任务的数据量，方能对该目标任务的 performance 有所促进。 Can train a big enough neural network to do well on all the tasks. 有一些研究者发现，多任务学习必须在神经网络足够大的情况下才有效，否则效果会比单独模型训练更差。因此，当应用多任务学习时，必须保证神经网络足够大。 相较于迁移学习，多任务学习的使用可能会更少一些，因为它要对多个任务进行学习。通常，多任务学习最常用的例子就是计算机视觉，因为计算机视觉一般要求能够同时检测到多个物体。 What is end-to-end deep learning?当前在深度学习领域最令人振奋的莫过于 end-to-end deep learning （端到端深度学习）了。那么什么是端到端呢？简单来说，通常一整套数据处理系统，或学习系统，需要进行多个阶段的处理。而端到端深度学习，它可以采用一个神经网络去替代多个阶段的数据处理。 举一些例子，如语音识别，我们的目的是要将输入 $x$ ，即一段音频，转化为输出 $y$ ，将音频识别并转化为文本。那么用传统的方法，这涉及到很多步骤。首先，你要提取一些特征，在音频片段中的一些手工特征（不懂？）。其次，应用机器学习算法，识别音频片段中的音节。接下来将这些音节重新拼接成单词，最后才将单词等组成一段段文本。 显然，过程很复杂。而端到端深度学习显得更为简单，它对输入的音频片段直接建立一个大的神经网络进行训练，再直接得到文本输出。有趣的是，和一些研究者耗费很长时间建立的一整套数据处理流程相比，端到端学习得到的效果会更好。这不仅仅发生在语音识别领域，还有计算机视觉和其他领域等。 虽然端到端深度学习能够大大缩减中间的一些繁琐步骤，但同样它也有一定的制约，那就是数据量。比如说，你有3,000个小时的音频片段，那么通过传统的语音识别方法，能取得很好的效果。然而，在端到端学习中，你若要取得好的效果，数据量可能得达到10,000个小时的音频长度。 因此，选择传统方式还是端到端深度学习？还得看你所拥有的数据量 。 Whether to use end-to-end deep learningPros and cons of end-to-end deep learning Pros : Let the data speak 假设你有足够的数据 $X,Y$ ，那么最好应该让神经网络自己去发掘数据中的统计特征，并训练出从 $X$ 映射到 $Y$ 的最合适的函数，而不是让神经网络去反映人类的理解和直觉。比如说语音识别中，音节是人类语言的产物，我们建立的神经网络，应该让它自己去寻找音节和人类语言的对应关系，而不是强迫它将音节当作人类语言的具体表示。 Less hand-designing of components needed 在端到端深度学习中，我们不再需要手工设计数据处理的步骤，简化了工作流程。 Cons : May need large amount of data Excludes potentially useful hand-designed components 当你的数据量不够大时，添加一些人工设计的数据处理步骤，会提高神经网络的训练效果。而当你排除所有的人工设计步骤时，很可能部分有用的知识也回遗失。说到底，关键的问题还是： Do you have sufficient data to learn a function of the complexity needed to map x to y? 以上就是端到端深度学习的基本内容。 这周也就到这里结束了，本文主要内容介绍了迁移学习、多任务学习和端到端学习，内容虽然蛮多，但也只是大概介绍了各种学习的基本思想，想要了解更多的算法推导和实施的部分，需要自己看多点文献去摸索。 Reference Structuring Machine Learning Projects - Week 2]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>Transfer Learning</tag>
        <tag>Multi-task Learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Structuring Machine Learning Projects - Week 2 - (2)]]></title>
    <url>%2F2018%2F04%2F10%2F29-Structuring-Machine-Learning-Projects-Week-2-2%2017.02.59%2F</url>
    <content type="text"><![CDATA[本文为深度学习第3门课程第2周的第2部分，上文讲解了误差分析方法，本文主要讲解的是数据不匹配问题以及解决的一些方法，欢迎大家关注！ Mismatched training and dev/test setTraining and testing on different distributions通常，要想一个神经网络实现比较好的效果，往往需要大量的样本数据去进行训练。为了保证收集的数据量大，那么数据的来源和质量也就不那么重要了，只要有的都可以拿来训练。而在这种情况下，训练集、验证集和测试集的数据分布则显得尤为重要，分布得好，那么模型效果也会有明显提升。比如说猫图识别案例： 在上图中，猫的照片主要来自两个地方，其中200,000张来自网页，而10,000张来自手机相册。显然，来自手机上的图片更为模糊、更难识别，我们的目的就是要检测我们的模型是否能很好地识别来自手机上的猫图。那么你会如何对训练集、验证集和测试集的样本进行分配呢？ Option 1 : 共 210,000 张图片，随机打乱，并随机分配至训练集、验证集和测试集分别为 205,000 张， 2,500 张和 2,500 张。 这种选择是完全随机的，而且三个数据集的分布是一致的。那么从概率的角度上说，验证集和训练集中来自网页的图片数期望为 2381 ，而来自收集的图片数期望为 119 。那么，我们的模型会花大部分时间针对网页图片去进行参数优化，而这显然不是我们想要的，我们想要的是让模型去识别手机的图片。因此说这样的分配并不好。 Option 2 : 将 200,000 张网页图片和 5,000 张手机图片全分配到训练集，再将剩余的 5,000 张手机图片平均分配至验证集和测试集。 这种分法会导致验证集和测试集的数据分布相同，而训练集与验证集、测试集的分布则完全不同。但它对我们想要实现的效果却更有利一些。因为模型会根据验证集（即手机图片）的特征去进行参数优化，从而实现对手机图片更好的识别效果。 Bias and Variance with mismatched data distributions上周的课程我们提到如何估计 Bias 和 Variance，然而当训练集和验证集、测试集的数据分布并不相同时，我们的方法也随之改变，那又该怎么办呢？ 回顾猫图识别案例，假设人类水平误判率为 0，也就是贝叶斯误差为 0。而训练集误差为 1%，测试集误差为 10%，如果你的训练集和验证集数据来自同一分布，那么我们可以直接说模型的 Variance 过大，需要减小。但若训练集和验证集并不服从同一分布，那么我们就不能那么肯定地给出这样的结论。 因为可能存在两种原因：(1)Variance 过大，训练集出现过拟合；(2)训练集和测试集不是同一分布，测试集样本由于图片类似或模糊等原因更难识别。 那么要如何判别是哪种原因导致的问题？我们可以先定义多一个数据集——Training-dev set. 将训练集随机打乱，然后从中划分出来的一部分作为训练验证集，但并不用于训练。 Training-dev set: Same distribution as training set, but not used for training. 情况 1 ： 训练集误差为1%，训练验证集误差为9%，验证集误差为10% 这种情况下，显然是出现了 Variance过大的问题。因为训练验证集与训练集是同一分布，而模型在这两个数据集判别得到的结果误差却大相径庭，说明在训练集训练中出现了过拟合。 情况 2 ： 训练集误差为1%，训练验证集误差为1.5%，验证集误差为10% 这种情况下，则是出现了数据不匹配的问题。因为模型在训练集和训练验证集判别得到的结果误差相差很小，训练集没有出现过拟合。而验证集的误差却尤其大，说明训练集和验证集数据分布不一致，出现 data-mismatch. 情况 3 ： 训练集误差为10%，训练验证集误差为11%，验证集误差为12% 这种情况下，模型在三个数据集的判别效果误差都相近，说明不存在 Variance过大，也不存在data-mismatch等问题，然而我们之前所说人类水平误差为0，训练集训练的效果并不能令人满意，说明出现了 Avoidable Bias过大的问题。 那么在以上分析当中，我们关注的判别误差主要有4个：Human-level (Bayes error) / Training set error / Training-dev set error / Dev error . 当然，你也可以将测试集误差 Test error 也考虑进去，和 Dev error 进行比较，由于验证集和测试集的样本数据必须服从同一分布，那么它们的误差应该是相近的。若差别太大，说明验证集出现过拟合，应该添加验证集的样本量。 Addressing data mismatch对于 data-mismatch 问题，当前还没有完全系统成熟的方法去解决，仅有一些小技巧值得去尝试一下，或许会有一些帮助。 Addressing data mismatch Carry out manual error analysis to try to understand difference between training and dev/test sets Make training data more similar; or collect more data similar to dev/test sets 上面第2个技巧，将训练数据变得与验证集数据更相似。这是怎么做到的？我们可以采用人工数据合成 (Artificial data synthesis)。 举个例子，在汽车语音识别系统中，汽车启动、行驶的声音、大街上的声音等都是噪声的来源，因此汽车语音识别系统的目的就是要在充满噪音的环境下识别人的语音。但是我们的训练数据并不总是在充满噪音的环境下录制的，也有安静的时候录制得到的，因为我们可以录制一段仅有汽车噪音的语音，将噪音与其他语音进行合成，模拟汽车内部的语音环境，既包含人的语音，也包含噪音。用这种方式得到的合成语音数据放到模型中去训练，可能会得到更好的结果。 然而，这种方法也有缺陷，那就是假设你有 1,000 小时长的语音，但只有1小时长的噪音，那么噪音会重复与语音进行人工合成。这就可能导致在训练时，模型对这1小时的噪音产生过拟合。当然，你有 1,000 小时的噪音，那就最好不过了。 Reference Structuring Machine Learning Projects - Week 2]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
        <tag>Mismatched</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Structuring Machine Learning Projects - Week 2 - (1)]]></title>
    <url>%2F2018%2F04%2F09%2F28-Structuring-Machine-Learning-Projects-Week-2%2017.02.59%2F</url>
    <content type="text"><![CDATA[本文是深度学习第3门课程的第二周，主要学习目标有两个，一个是了解什么是多任务学习和迁移学习，另一个是通过训练集、验证集和测试集的算法结果去评估并改进bias、variance和data-mismatch等问题。欢迎大家关注！ Error AnalysisCarrying out error analysis什么是 Error analysis（误差分析）？当你在训练你的模型时，算法效果还达不到人类水平，那么你对算法出现的错误进行人工检验，并深入了解算法的本质和步骤。这样的过程就叫误差分析。 举个例子，在识别猫图的案例中，你的模型能够实现90%的精确度，也就是还存在10%的误差。当你发现在这些误判的图片中，有一些图片是小狗而不是猫。那么你会花上很多时间去收集小狗的图片，提取小狗的特征，并再次将你的模型改进，使它对小狗的图片有更好的处理吗？ 可能小狗的图片仅有那么几张，而你却得多花几个月的时间。这显然是不值得的，那么误差分析会让你更加清晰地认识到什么是值得做的，而什么是不值得做的。 假设验证集中有100张被误判的样本图片，查看每张图片，看到底有几张是小狗图。当你发现100张误判图中只有5张是小狗，那么即使你对算法改进很大，能识别所有小狗图，那你的误差率也只是从10%降低到9.5%，最多只能优化到这种程度。然而，当你发现100张误判图中有50张是小狗，那么当你对算法改进后能识别所有小狗，你的误差率就从10%下降到5%，显然这种情况更值得去改进算法。 这就是误差分析，它可以让你简单判断你想要改进的方向是否值得。对于其他情况同样有效。 Evaluate multiple ideas in parallel Ideas for cat detection: Fix pictures of dogs being recognized as cats Fix great cats (lions, panthers, etc…) being misrecognized Improve performance on blurry images Image Dog Great Cats Blurry Comments 1 $\surd$ Pitbull 2 $\surd$ 3 $\surd$ $\surd$ Rainy day at zoo $\vdots$ $\vdots$ $\vdots$ $\vdots$ $\vdots$ % of total 8% 43% 61% 我们可以简单地制作类似上面的表格，查看一下每张误判图的原因，然后对频发的原因进行改进。比如说上表，43%的误判图是大型猫科动物，61%的误判图是因为图片模糊。显然，相对于小狗，大型猫科动物和图片质量才是造成我们模型误判的主要原因，我们应该往这两方面去改进我们的模型才能取得更好的效果。 Cleaning up incorrectly labeled data我们知道，大部分时候我们对数据进行标注分类是通过人工的方式进行的。只要是人工，那么就很可能会发生一些错误，比如说标注者分心了，或者敲错键盘的键了。如果这些标注错误是随机的，也就是说并非标注者故意犯的错，那么我们是不太需要耗费太多时间去修复的。因为： DL algorithms are quite robust to random errors in the training set. 因为通常训练集样本量大，因此少部分的标记错误并不影响模型的结果。然而，这是针对训练集的情况。而验证集和测试集的样本量远小于训练集的量，那么又该如何处理呢？ 我们可以用上节的方法，也就是 Error Analysis。在上表中添加一列“Incorrectly labeled”，对错误标注的样本进行统计，分析是否需要修正，以及是否值得去修正。 下面给出一些修正的建议： Correcting incorrect dev / test set examples Apply same process to your dev and test sets to make sure they continue to come from the same distribution. Consider examining examples your algorithm got right as well as ones it got wrong. Train and dev/test data may now come from slightly different distributions. 第1个建议是前提条件，在之前我们也是经常提到的，验证集和测试集必须服从同一分布。第3个建议要求放宽了些，训练集可和验证集、测试集服从不同分布，因为深度学习算法在训练集的效果通常是鲁棒的。 第2个建议解释一下，就是对正确判别的样本和误判的样本，都去人工查看检验一下。因为人工标注错误是可能发生在整个数据集的，如果你只查看并修正误判样本的错误标注，那么对你的算法并不好，很可能有些误判样本因为错误标注而变成正判样本。因此最好对所有样本都进行人工查看，当然这并不简单，尤其是你的准确率高达98%的时候，对于2%的误判样本你可以很快便能查看完成，但98%的正判样本会费很多时间。因此这也是考虑的一个方向，不要求一定去做。 Build your first system quickly, then iterate这节给了我们一些建立模型的建议，大家可以参考参考。 Set up dev/test set and metric Build initial system quickly Use Bias/Variance analysis &amp; Error analysis to prioritize next steps. 总的来说，就是： Bulid your first system quickly, then iterate. 建好模型是第一步，这一步要尽快，建好之后再通过进一步的分析不断进行调试，最后实现较好的结果。 Reference Structuring Machine Learning Projects - Week 2]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Structuring Machine Learning Projects - Week 1 - (2)]]></title>
    <url>%2F2018%2F04%2F06%2F27-Structuring-Machine-Learning-Projets-Week-1-2%2017.02.59%2F</url>
    <content type="text"><![CDATA[我们继续上节课的笔记，这节课关注的重点是神经网络的 Human-level performance，神经网络怎样才能达到人类水平？欢迎大家关注！ Comparing to human-level performanceWhy human-level performance ?近年来，越来越多的人拿机器学习系统的表现和人类水平相比，这事实上不仅反映了当前随着深度学习的发展，机器学习算法在多个领域应用的效果和人类水平的表现越来越近，甚至在工作流程中，机器学习系统会比人类更有效率。比如说图像识别，只要训练数据越来越多，训练模型越来越复杂，算法识别图像的水平和人类水平就会越来越相近，直到超越人类水平。 当然，由于客观因素存在，比如说图像很模糊，那么不管怎么训练，算法都不可能实现100%的准确率，必定存在一些误差，这个误差的极限就是 Bayes optimal error。 Why compare to human-level performance Humans are quite good at a lot of tasks. So long as ML is worse than humans, you can: Get labeled data from humans. Gain insight from manual error analysis: Why did a person get this right? Better analysis of bias / variance. Avoidable bias什么是可避免的误差？它和我们上节所说的 Bias Optimal Error有什么区别？我们以一个例子来解释。 针对识别猫图像的例子，人类识别、训练集识别和验证集识别的结果分别如下： 误差 情况 1 情况 2 Humans-level error 1% 7.5% Training error 8% 8% Dev error 10% 10% 情况 1 在第 1 种情况下，训练集的误差远远大于人类水平的误差，说明训练效果并不好，算法不能很好地对训练样本进行拟合。应该我们必须改进算法，之前的课程我们介绍过，改进算法的思想主要是两方面，要不改进 Bias，要不改进 Variance。 显然，相对于训练集与验证集之间的误差，训练集与人类水平之间的误差更大一些，因此我们需要改进 Bias，通过建立更大的神经网络或训练更长时间，使训练样本拟合度更好，减少与真实值的误差。 情况 2 在第 2 种情况下，人类水平的识别误差都达到7.5%，说明图像质量很不好。从另一个角度说，算法的效果是很不错了，因为它的识别效果基本和人类水平相近，很难通过改进Bias，来获得更好的识别效果。 因此，相对于训练集与人类水平之间的误差，训练集与验证集之间的误差更大一些，我们可以选择通过改进 Variance，缩小验证集与训练集之间的识别差距。比如说正则化防止过拟合等等。 通常情况下，human-level error还是要大于Bayes optimal error的。因为人不是万能的。但在这里，我们可以认为 human-level error 可相当于 Bayes optimal error。因为人对图像的识别都是凭经验的，很容易便能发现图像中是不是猫。但如果连人都不能识别出猫的图像，那么说明图像本身就有问题，算法不可能比人识别得更精确。 因此，我们便把Training error与 Bayes optimal error 的差 当成 Avoidable bias，表示当前训练误差还能继续优化的程度。 Understanding human-level performance在上一节，提到 “human-level” error，那么它具体指的是什么？这节我们深入来解释一下人类水平误差。 见上图，对于一张X光照片，要根据照片中的骨骼进行诊断。一般人可能不太懂，会有3%的诊断误差，而一般医生会有1%的诊断误差，有经验的医生会有0.7%的诊断误差。如果是一个团队且有经验的医生，那么诊断为0.5%。那么，我们选哪个作为人类水平的误差？ 首先，我们可以确认贝叶斯误差总是小于或等于0.5%的。通常情况下，我们习惯于将人类水平误差估计贝叶斯误差，比如说识别猫图（只要是正常人，不管大人小孩都能很简单得判断猫，不同人群的识别误差几乎无差异）。但是在这种情况下，由于不同人群的医学水平是不一样的，诊断误差也不一样。那么人类水平误差选哪个？这个还需要通过训练集和验证集的误差来判断。 Error 情况 1 情况 2 情况 3 Human-level 1%/0.7%/0.5% 1%0.7%/0.5% 0.5% Training error 5% 1% 0.7% Dev error 6% 5% 0.8% 情况 1 当训练集和验证集的误差分别为5%和6%时，人类水平误差定义为1%或0.7%或0.5%都无所谓，因为相较于训练集和验证集误差之间的差距，人类水平误差和训练集误差的差距太大了，此时必须改进 Bias，减小 Avoidable bias。 情况 2 当训练集和验证集的误差分别为1%和5%时，人类水平误差同理定义为任一种情况都无所谓，因为相较于训练集和验证集误差之间的差距，人类水平误差和训练集误差的差距太小了，此时必须改进 Variance，防止过拟合。 情况 3 当训练集和验证集的误差分别为0.7%和0.8%时，人类水平误差只能定义为0.5%。为什么呢？若人类水平误差定义为1%，那训练集诊断效果就超过人类啦！这当然是不公平的，因为有经验的医生（不管是个体还是团队），其误差都小于等于训练集误差；若人类水平误差定义为0.7%，那么Avoidable bias为0，Variance为0.1%都太小了，算法很难找到改进的空间了，但显然训练集0.7%的误差还达不到贝叶斯最优；因此，人类水平误差只能定义为0.5%，这样算法才能继续去改进，去减小Avoidable bias。 总结一下，由于贝叶斯误差是未知的，通常情况下我们会以人类水平误差去估计贝叶斯误差 。当然，人类水平误差怎么选，还需看具体情况。不管怎么说，只有更好地对贝叶斯误差进行估计，才能更好得确定 Avoidable Bias 和 Variance，从而对算法采取相应措施进行优化。 Surpassing human-level performance超越人类水平，事实上当前在许多方面算法已经超越了人类水平，在识别误差上越来越小。比如说： Problems where ML significantly surpasses human-level perfornmance Online advertising Product recommendations Logistics (predicting transit time) Loan approvals 当然，对于一些自然理解的任务，比如说语音识别、图像识别等，这些都是人类熟悉的方面，算法要跟上人类水平还有一定的距离，但是只要有足够大的样本量和足够复杂的模型，算法总有一天还是能超越人类的。 Improving your model performanceThe two fundamental assumptions of supervised learning You can fit the training set pretty well. (Avoidable Bias) The training set performance generalizes pretty well to the dev/test set.(Variance) Reducing avoidable bias Train bigger model Train longer/better optimization algorithms (momentum, RMSprop, Adam) NN architecture/hyperparameter search (RNN, CNN) Reducing variance More data Regularization (L2, dropout, data augmentation) NN architecture/hyperparameter search Reference Structuring Machine Learning Projects - Week 1]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Structuring Machine Learning Projects - Week 1 - (1)]]></title>
    <url>%2F2018%2F04%2F03%2F26-Structuring-Machine-Learning-Projects-Week-1%2017.02.59%2F</url>
    <content type="text"><![CDATA[这周我们将深度学习的第三门课程 Structuring Machine Learning Projects ，这门课程比较简短，只有两周的课时，主要讲述机器学习策略，欢迎大家关注！ Introduction to ML StrategyOrthogonalization建立深度学习神经网络的一个麻烦就是，你需要尝试很多东西，比如说调参。有一些比较厉害的大牛，他们通常很清晰对哪些参数进行调节可实现好的效果，这样的过程我们称为正交化。 和我们代数中所学的正交化不同，这里所说的正交化是指模型中参数的设计与调节。举个简单的例子，一台电视机，它有许多按钮，每个按钮只调一个功能，比如说图像长度、宽度、倾斜角度等，这就是正交化，通过调节每个按钮，我们便可以将图像调整到电视机的正中央。然而，如果电视机只有一个按钮，而这个按钮每调节一次，将同时调节图像 0.1倍长度，0.3倍宽度及1.7倍倾斜角度，那么你很难将图像调到正中央，因为多个功能都在相互作用。 所以简单来说，在参数正交化中，我们需要仅仅针对一个参数去进行调节。避免多个参数同时调节，因为多个参数相互作用下往往不能得到更好的效果。 Setting up your goalSingle number evaluation metric在调参过程中，建立一个单一数值的评估度量是十分重要的，因为它能让你快速判断这一次调节的参数是否优于上一次。 举个例子，在某次训练中，我们得到的结果如下： Classifier Precision Recall A 95% 90% B 98% 85% Precision=\frac{True \ positive}{True\ positive+False\ negative},\ Recall=\frac{True \ positive}{True\ positive+False\ negative}对于两个分类器来说，准确率和召回率都是越大越好，那么我们如何判断上面的A、B两个分类器，哪个更好呢？ 通常我们会根据两个指标，将它们综合起来，形成一个新的单一数值来进行评估，如 F1 score： $F1=\frac{2}{\frac{1}{P}+\frac{1}{R}}$ ，F1即是准确率和召回率的均值，在这里使用的是调和平均值算法( Harmonic mean )。根据计算结果，我们容易得到A分类器的F1大于B分类器，说明A分类器效果更好。 Satisficing and Optimizing metric大部分时候想要将所有评估指标都综合在一个单一数值指标里面是十分困难的，而在这个时候，我们建议一个能够保证最低要求( Satisficing )又能追求最优效果( Optimizing )的指标则容易地多。 举个例子，当识别一张图片时，A、B、C三个分类器效果如下： Classifier Accuracy Running time A 90% 80ms B 92% 95ms C 95% 1,500ms 显然，我们想要的是准确率尽量大，训练时间尽量得短。但是，对于这两个指标，我们的要求却又不太一样，比如说运行时间，我只需要它识别一张图片不超过100ms就足够了，再快也没用，反正也体会不到50ms和100ms的区别。而准确率呢？必须让它越大越好，哪怕再大0.1%都十分重要。 因此，我们即可建立一个满意-最优度量( Satisficing-Optimizing metric )。比如，$cost=accuracy-0.5 \times running \ time$ . 在这里，我们需要在运行时间小于100ms的约束条件下，使准确率达到最优。 更一般的情况下，当你有$N$ 个指标需要考虑，那么选一个需要追求最优的指标，而其他 $N-1$ 个指标均可为其设定最低阈值，只要在阈值之内即可，并不要求它们达到最优。 Train / dev / test distributions如何设置训练集、验证集和测试集，这也是一个老生常谈的问题了。其实，关于这个问题，最主要的就是要保证验证集和测试集服从同分布。 验证集的作用是什么呢？我们在训练集中可以使用多种方法去进行训练，但是什么样的方法才是最优的呢？那就是在验证集中训练能够达到最优效果的方法，而为了保证测试集能像验证集一样训练得到最优效果，那么就必须要求验证集和测试集服从同分布。 Guideline Choose a dev set and test set to reflect data you expect to get in the future and consider important to do well on. Size of dev and test sets之前的课程好像提到过，对于训练集和测试集的样本量，在过去机器学习的经验法则中，分别为70%和30%的比例是十分合理的。如果还有验证集，那么60% / 20% / 20%的比例也能满足要求。这是针对数据量比较小的情况，如几千几万的数据量。 但是当数据量上百万上千万时，就没必要设置那么大的验证集和测试集了，应把尽量多的样本用于训练集进行训练，比如98%的样本量。那么验证集和测试集的样本量比例均为1%，这是可以的。事实上，甚至可以省略测试集，直接把验证集当做测试集都是可以的。 Size of test set Set your test set to be big enough to give high confidence in the overall performance of your system. When to change dev / test sets and metrics这节讲得也是一些无关紧要的问题。当你的评估度量在你的验证集或测试集上的效果很好时（如识别猫），而一旦换了一些其他类型的图片（图片变模糊了或其他），评估变差了。那么就应该改变你的评估度量，或者是改变你的验证集和测试集了。 Reference Structuring Machine Learning Projects - Week 1]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[多属性决策——以建设项目的风险评估为例]]></title>
    <url>%2F2018%2F03%2F27%2F25-%E5%A4%9A%E5%B1%9E%E6%80%A7%E5%86%B3%E7%AD%96%E2%80%94%E2%80%94%E4%BB%A5%E5%BB%BA%E8%AE%BE%E9%A1%B9%E7%9B%AE%E7%9A%84%E9%A3%8E%E9%99%A9%E8%AF%84%E4%BC%B0%E4%B8%BA%E4%BE%8B%2017.06.12%2F</url>
    <content type="text"><![CDATA[多属性决策（MADM）处理的是离散型问题，通常针对有限的、预先设定数量的备选方案，通过内部属性相互之间的比较，对各备选方案进行评价后排定各方案的优劣次序，再从中择优的方法。 在这里我们以 Edmundas et al. (2010) 的文章 Risk Assessment Of Construction Projects 为例，讲解多属性决策方法在风险评估中的应用，以及文中出现的两种算法 ( TOPSIS , COPRAS-G ) 的原理和计算方法。 Introduction对于建筑商来说，项目的风险因子是普遍存在的，而且对项目成功实施的影响很大。因此，风险管理是十分重要的，它在辨别不确定性来源，预估不确定性事件的结果，并给出有效的应急方案的过程中起到很大的作用。 在风险管理中，对项目的风险评估显然是一个 多属性决策 的过程。因为在风险评估中，包括了决策人 (decision makers)，目标集 (projects) 和属性集 (attributes)。而属性集是多属性决策的核心，因为它不仅是数据的来源，也是决策人在目标集中做出决策的基础。 在这里，属性集由风险因子构成。风险的来源是多种多样的，具有很大的不确定性，通常可分为3类： 表1 风险因子 External risks Project risks Internal risks Political risks ($x_1$) Time risk ($x_5$) Resource risk ($x_{10}$) Economics risk ($x_2$) Cost risk ($x_6$) Project member risk ($x_{11}$) Social risk ($x_3$) Work quality ($x_7$) Construction site risk ($x_{12}$) Weather risk ($x_4$) Construction risk ($x_9$) Documents and information ($x_{13}$) Technological risk ($x_8$) Data灰色系统理论灰色系统理论是由我国邓聚龙教授于1988年提出来的，在离散数据的处理上十分有效，主要体现在几个方面：计算十分方便，只需少量样本，且样本不不要服从特定分布。 对一个区间尺度，设 $w$ 为该区间的下限，$b$ 为上限，如图： 灰度隶属函数： X(k,x)=\left \{ \begin{array}{rcl} [0,1] ，& k\in [w,b] \\ 0 ，& k]]></content>
      <categories>
        <category>Paper</category>
      </categories>
      <tags>
        <tag>决策理论与方法</tag>
        <tag>实证</tag>
        <tag>MADM</tag>
        <tag>多属性决策</tag>
        <tag>TOPSIS</tag>
        <tag>COPRAS-G</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Improving Deep Neural Networks - Week 3 - (3)]]></title>
    <url>%2F2018%2F03%2F24%2F24-Improving-Deep-Neural-Networks-Week-3-3%2017.05.15%2F</url>
    <content type="text"><![CDATA[本文是第3周课程的最后一部分，主要讲解多类别分类算法，以及 Tensorflow 这个大名鼎鼎的深度学习框架，欢迎大家关注！ Multi-class classificationSoftmax Regression对于二分类问题，Logistic Regression 是一个很好的方法。而对于多分类问题，我们更常采用的是 Softmax Regression。 对于上面一个神经网络，我们需要将输出 $\hat{y}$ 分为4类（即4分类问题），设定前面一层 ( layer $l$ ) 的4个节点分别代表每一类出现的概率，并把该层叫做 Softmax layer。 Softmax Regression 中最重要的就是 Softmax activation function，而我们便是将该 Softmax activation function 用在 Softmax layer 上。 for \ layer \ l:z^{[l]}=\omega^{[l]}a^{[l-1]}+b^{[l]} \\ Activation function: \\ t = e^{(z^{[l]})} , a^{[l]}=\frac{e^{[z^{[l]}]}}{\sum_{j=1}^4 t_i}因此 $a^{[l]}_i=\frac{t_i}{\sum^4_{j=1}t_i}$ ，在softmax激活函数中，输入和输出是相同维度的向量，在上面的例子中，$z^{[l]},t,a^{[l]}$ 均为 $(4\times 1)$ 的向量 。举个比较简单的例子吧，见下图： 针对上图的例子，显然结果为第1类，因为第1类出现的概率为84.2%。下图给出一些 Softmax 多分类的一些例子，都只有一层隐含层，因此呈线性分类。 Training a softmax classifier Softmax regression generalizes logistic regression to more than two classes. Loss function L(\hat{y},y)=-\sum^4_{j=1}y_j \log \hat{y}_j损失函数如上所示，举个例子解释一下这个损失函数，假设一个样本其实际结果为第2类，即向量表示为： $y^{i \ T}=(0,1,0,0)$ ，那么带入到损失函数中，得 $L(\hat{y},y)=-\log \hat{y}_2$ ，为了保证损失函数尽量小，那么 $\hat{y}_2$ 的概率值就得尽可能大。 对于整个训练集来说， Cost function 为： J(\omega^{[l]},b^{[l]},\dots)=\frac{1}{m}\sum^m_{i=1}L(\hat{y}^{(i)},y^{(i)}) Gradient descent with softmax 1Backprop: dz^[l] = y_hat - y Gradient descent 的过程和之前的教程一样，值得注意的是在反向传播中，对 $dz^{[l]}$ 进行初始化时，具体方法如上：$dz^{[l]}=\hat{y}-y$ 。 Introduction to programming frameworksDeep learning frameworks Caffe/Caffe2 CNTK DL4J Keras Lasagne mxnet PaddlePaddle Tensorflow Theano Torch 以上都是比较常见的深度学习框架，该如何做出选择呢？3点建议： Ease of programming(development and deployment) Running speed Truly open(open source with good governance) Tensorflow以一个例子说明 Tensorflow 框架，求如下 cost function 最小化下的参数： cost = \omega^2-10\omega+25显然，我们知道当 $\omega=5$ 时，$cost=0$ 为最小。 Code example: 1234567891011121314151617import numpy as npimport tensorflow as tfcoefficients = np.array([[1],[-10],[25]])w = tf.Variable([0],dtype=tf.float32)x = tf.placeholder(tf.float32, [3,1])cost = x[0][0]*w**2 + x[1][0]*w +x[2][0] # (w-5)**2train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)init = tf.global_variables_initializer()session = tf.Session()session.run(init)print(session.run(w))for i in range(1000): session.run(train, feed_dict=&#123;x:coefficients&#125;)print(session.run(w)) 在 Tensorflow 中无需考虑 backprop 的计算，因为在该框架中会自动执行 backprop，不管多复杂的函数，都可以自动求导，这也是 Tensorflow 如此方便有效的原因。 What you should remember: Tensorflow is a programming framework uesd in deep learning The two main object classes in tensorflow are Tensors and Operators. When you code in tensorflow you have to take the following steps: Create a graph containing Tensors (Variables, Placeholders …) and Operations (tf.matmul, tf.add, …) Create a session Initialize the session Run the session to execute the graph You can execute the graph multiple times as you’ve seen in model() The backpropagation and optimization is automatically done when running the session on the “optimizer” object. Reference Improving Deep Neural Networks - Week 3]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Improving Deep Neural Networks - Week 3 - (2)]]></title>
    <url>%2F2018%2F03%2F23%2F23-Improving-Deep-Neural-Networks-Week-3-2%2017.03.22%2F</url>
    <content type="text"><![CDATA[本文为第3周课程的第二部门，主要讲解 Batch Normalization。欢迎大家关注！ Batch NormalizationNormalizing activations in a network在深度学习的发展中，Sergey loffe &amp; Christian Szegedy 曾提出一种重要的思想—— batch normalization，它可以使调参的过程更简单，更有效率，也使神经网络更具鲁棒性。那么它是怎么work 的呢？ 在第1项课程中曾提到过，我们对输入层 $x$ 进行标准化，可加快梯度下降的速度，得到更优的参数 $[\omega,b]$。那么，对于一个深度神经网络，我们对其每个隐含层都进行标准化，是否同样能够得到优化的效果？这就是 batch-normalization( 简称 batch-norm) 的作用。 Implementing Batch Norm Given\ some\ intermediate\ values\ in \ NN : \ z^ { (1)},...,z^ { (m)} \\ \mu=\frac { 1} {m}\sum_i z^ { (i)} \\ \sigma^2=\frac { 1} {m}\sum_i(z^ { (i)}-\mu)^2 \\ z^ { (i)}_ { norm}=\frac { z^ { (i)}-\mu} {\sqrt { \sigma^2+\varepsilon} }上面公式为隐含层标准化的过程，在标准化中添加 $\varepsilon$ 是为了防止出现 $\sigma^2=0$ 的情况。当经过标准化后，隐含层节点分布服从标准正态分布，即均值为0，方差为1。但如果我们想让隐含层节点服从其它正态分布，而非标准呢？ \tilde { z}^ { (i)}=\gamma z^ { (i)}_ { norm}+\beta其中，$\gamma$ 和 $\beta$ 均为 learnable parameters. 在梯度下降时，或其他一些算法，如momentum、rms、adam等，这些参数都会随之 update。那么，当$\gamma = \sqrt { \sigma^2+\varepsilon}$ 且 $\beta=\mu$ 时，$\tilde { z}^ { (i)}=z^ { (i)}$ 。经过标准化后的 $\tilde { z}^ { (i)}$ 可直接用于下一层的计算。 那为什么非要添加 $\gamma$ 和 $\beta$ 呢？让隐含层节点服从标准正态分布不好吗？那么因为由于标准正态分布均值为0，那么大部分的值都会分布在 0 附近。由此造成的后果是，在经过激活函数( sigmoid )的时候，大部分的值都会限定于 sigmoid 中间近似于线性的部分。 Fitting Batch Norm into a neural network Adding Batch Norm to a network x \xrightarrow { \omega^ { [1]},b^ { [1]} }z^ { [1]} \xrightarrow[BN] { \beta^ { [1]},\gamma^ { [1]} }\tilde { z}^ { [1]} \rightarrow a^ { [1]}=g^ { [1]}(\tilde { z^ { [1]} }) \xrightarrow { \omega^ { [2]},b^ { [2]} }z^ { [2]} \rightarrow \dots从上流程可见，Batch-Norm添加在激活函数之前即可。显然，参数又多了两个，现在共有 4 个参数：$\omega^ { [1]},b^ { [l]},\beta^ { [l]},\gamma^ { [l]}$ . Working with mini-batches Batch-Norm同样可和mini-batches 一起使用，同样在每个batch，每层的激活函数之前进行标准化即可。需要注意的是， $z^ { [l]}=\omega^ { [l]}a^ { [l-1]}+b^ { [l]}$ ，由于在batch norm要进行标准化，并再次进行 rescale 。显然，添加常数 $b^ { [l]}$ 在此并无意义，都会在标准化减去均值时所抵消。因此在这里，可省去一个参数 $b^ { [l]}$ . 同时，要注意 $z^ { [l]}$ 及其他参数都具有相同的维度，即 $(n^ { [l]},1)$ . Implementing gradient descent 123456789for t = 1,...,number of mini-batch: Compute forward prop on X &#123; t&#125; In each hidden layer, use BN to replace z[l] with z_tilde[l] Use backprop to compute dw[l],dbeta[l],dgamma[l] Update parameters : w[l]:= w[l] - alpha * dw[l] beta[l]:= beta[l] - alpha * dbeta[l] gamma[l]:= gamma[l] - alpha * dgamma[l]also work with momentum, rms prop , adam Why does Batch Norm work Learning on shifting input distribution 在训练神经网络时，通常会遇到输入层的分布改变的情况，这叫 covariate shift 。举个比较浅显的例子，如神经网络判别猫的测试，当我们的输入都是黑猫的图片，神经网络可能训练得很好。突然我们输出一些其他颜色猫的图片，那么神经网络就可能判断出错，尽管输入都是猫的图片，但某些特征改变了，输入的分布改变了，从而导致 covariate shift 的产生。 Why this is a problem with neural networks? 我们看上面一个神经网络，为了保证训练得到的 $\hat { y}$ 尽量与实际值相近，每一层的参数 $[\omega,b]$ 都在不断更新迭代。然而，对于某一层的参数值来说，总是受到前面一层参数值的影响，也就是说上一层传递至该层的输出改变，即会导致该层传递至下一层的值也发生改变。这也是我们上一段所说的 covariate shift。 由于 Batch-Norm 对每一层的输入都进行标准化，在一定程度上解决这个问题。因为标准化后，输入的分布均服从标准正态分布，那么不管输入怎么变，其均值和方差都分别为 0 和 1 （或rescale后服从其它正态分布），对下一层造成的影响也比较小。 Batch Norm as regularization (1) Each mini-batch is scaled by the mean / variance computed on just that mini-batch. (2) This adds some noise to the values $z^ { [l]}$ within that mini-batch. So similar to dropout, it adds some noise to each hidden layer’s activations. (3) This has a slight regularization effect. 以上三条讲述的是Batch-Norm的另一个影响，即有部分正则化的作用，可防止过拟合，但不太建议把 Batch-Norm 当作 Regularization 来使用，因为 Batch-Norm的正则化作用并不太明显，其最主要的作用还是在于给隐含层进行标准化，从而加快梯度下降的速度。 Batch Norm at test time我们知道，在训练集中，对每个mini-batch 进行一次batch-norm 。但是在测试集中，对于每个样本都要进行一次batch-norm，那么应该如何估计测试集样本的均值和方差呢？ 一个典型的方法就是通过对训练集每个mini-batch求指数加权移动平均值和方差，直到最后一个均值和方差作为测试集样本的均值和方差。 for \ layer \ [l]:X^ { \ { 1\} }\rightarrow \mu^ { \ { 1\}[l]},X^ { \ { 2\} }\rightarrow \mu^ { \ { 2\}[l]},X^ { \ { 3\} }\rightarrow \mu^ { \ { 3\}[l]},\dots训练集 $l$ 层中得出最后的一个 $u^ { [l]}$ 作为测试集第 $l$ 层的均值，方差同理。 尽管指数加权移动平均得到的均值和方差估计都比较粗糙，但事实上这个方法的鲁棒性是非常好的。 未完待续~~ Reference Improving Deep Neural Networks - Week 3]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Improving Deep Neural Networks - Week 3 - (1)]]></title>
    <url>%2F2018%2F03%2F22%2F22-Improving-Deep-Neural-Networks-Week-3%2017.02.59%2F</url>
    <content type="text"><![CDATA[这周课程是第二门课程的最后一周，本文主要关注于调参，对调参的一些细节以及需要注意的技巧都加以描述，欢迎大家关注！ Hyperparameter tuningTuning process从前面的课程，我们知道调参是训练好一个神经网络关键的一步。但是面对众多的超参数，哪个超参数更为重要，更需要优先考虑呢？另外在调参过程中，我们应该如何更好地去设置它们呢？ \alpha>(\beta=\# hidden \ units=mini\_batch \ size)>(\# layers=learning\ rate\ decay)从调参优先度来看，最重要的应该是学习率$\alpha$ ，其次应是momentum term的$\beta$ ，隐含层节点数和mini-batch size等，最后才考虑层数，权重衰减等。 另外如Adam算法中的$\beta_1,\beta_2,\varepsilon$ 等采用默认数值即可，无需可以调节。 针对第2个问题，如何更好地设置参数？尽可能多地尝试很重要，但尝试也有技巧！ Try random values: Don’t use a grid 什么意思呢？假设你有两个超参数需要调节，通常情况下你会想到都一点一点地增大试试看，直至形成一个面板，再比较超参数在哪个范围效果最好。但在这种情况下，若一个参数很重要，如学习率$\alpha$ ，而另一个无关轻重，如$\varepsilon$ ，那么你每个参数都均等增大尝试5次，得到25个结果，事实上由于$\varepsilon$ 实在影响不大，大部分结果都相近，你只能得到5个区别较大的结果，那就是$\alpha$ 改变的时候。 如上图，更好的尝试办法就是对两个参数都采取随机赋值，这样就算你对参数的重要性一无所知，不知道哪个参数对效果影响细微，也可以得到众多不同的结果。 Coarse to fine 见上图，调参的另一个建议就是在尝试中不断缩小范围。当你发现在随机调参过程中，某片区域的效果明显比其他区域要好，那么最好将范围限定在这片小区域，再次进行更加密集地随机设参，直到找到最优的参数。 Using an appropriate scale to pick hyperparameters Picking hyperparameters at random 从上节中，我们知道调参时随机设参是很重要的，但选择一个合适的尺度是随机设参的前提。比如说我们设置神经网络层数和节点数时，设置范围在 [1,10] 内，采用linear scale，进行均匀分布的随机取法，这样的取法显然是没问题的。但这并不代表所有的参数都能够这样设置。 Appropriate scale for hyperparameters 举多一个例子，假设我们将学习率$\alpha$ 范围设置在区间 [0.0001,1]内，以linear scale采取均匀分布的随机取法，那么会产生怎样的结果？显然，90%取到的参数都会在 [0.001,1]之间，仅有10%的随机取值会在 [0.0001,0.001]内。 而我们想要的结果应该分别在区间 [0.0001,0.001]，[0.001,0.01]，[0.01,0.1]，[0.1,1]中取得相同数量的随机值。因此当前 scale 并不能满足我们的需求，我们需要一种更好的scale去取随机值。 12r = -4 * np.random.rand()aplha = 10 ^ r 采用log scale，可得 $r \in [-4,0]$ ，那么 $\alpha \in [10^{-4},1]$ 。此时，再对$r$ 采用均匀随机取值，即可得到想要的结果。 Hyperparameters for exponentially weighted averages 假设 $\beta \in [0.9,0.999]$ ，那么又应该如何随机取值呢？很简单，用 $1-\beta $ 转化一下，再采用上面的log scale 即可。通过选择合适的scale进行随机取值，能使调参的效率更高。 Hyperparameters tuning in practice: Pandas vs. Caviar通常在神经网络训练过程中，存在两种方式进行调参。 Pandas approach: Babysitting one model 当你的数据集很大，但并没有足够多的计算资源，你只能一次训练一个模型或少量模型。那么在训练中，需要不断调参，设置的每个参数都必须保证cost function尽可能大地下降。 Caviar approach: Training many models in parallel 当你由足够多的计算资源时，可以同时训练多个模型时，可通过每个模型选择不同的参数进行训练，再从中选择 cost function 下降最快的一个模型即可。 第一种方式就像熊猫，它一次只能生一个或几个孩子，每个都必须好好照顾才能保证它们的生存。而第二种方式就像鱼，它每次产卵都有成千上万，只要有部分生命力更强的鱼卵生存下来即可，不在乎全部生存。 未完待续~~ Reference Improving Deep Neural Networks - Week 3]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[粗糙集决策简析]]></title>
    <url>%2F2018%2F03%2F11%2F21-%E7%B2%97%E7%B3%99%E9%9B%86%E5%86%B3%E7%AD%96%E7%AE%80%E6%9E%90%2017.02.59%2F</url>
    <content type="text"><![CDATA[决策理论与方法是这个学期的一门重要课程，在开学的第一周，老师讲了决策的一些概念和方法，如确定性决策、风险决策和不确定性决策等。 对于确定性决策，常用一般的数学规划模型便可清晰地描述决策问题并确定决策方案；对于风险决策等，可考虑概率，采用贝叶斯分析方法；那么对于不确定性决策来说，除了较为简单的悲观准则、乐观准则、等可能准则等决策方式之外，是否还有更为完善的理论或分析方法可解决不确定性决策呢？ 经过一系列的资料收集和文献查阅，我认为粗糙集理论是个比较好的方向。 粗糙集的基本概念知识表达系统一个知识表达系统或信息系统 $S$ 可以表示为有序四元组：$S=\{U,R,V,f\}$ . 其中，$U=\{x_1,x_2,…,x_n\}$ 为论域，是全体样本的集合，$R=C \cup D$ 为属性集合（包括条件属性 $C$ 和决策属性 $D$ ），$V$ 是属性的值域，$f:U \times R \rightarrow V$ 是一种映射，用于确定 $U$ 中每一个对象 $x$ 的属性值。如： 表1 对象 头疼 $r_1$ 肌肉疼 $r_2$ 体温 $r_3$ 流感 $d$ $x_1$ 否 是 高 是 $x_2$ 是 否 高 是 $x_3$ 是 是 很高 是 $x_4$ 否 是 正常 否 $x_5$ 是 否 高 否 $x_6$ 否 是 很高 是 知识在粗糙集理论中，知识被认为是一种分类能力，人们的行为基本上是分辨现实的或抽象的对象的能力。 论域中相互间不可分辨的对象组成的集合，是组成知识的颗粒。知识是有粒度的，粒度越小，能精确表达的概念越多，粒度的形式表示：不可分辨关系/等价类，粒度是知识的最小单位。 每个等价类被成为一个概念，即一条知识（规则）。即每个等价类唯一地表示了一个概念，属于一个等价类的不同对象对该概念是不可区分的。 不可分辨关系和基本集 不可分辨关系 $IND(P)$ : 分类过程中，相差不大的个体被归于同一类，他们的关系就是不可区分关系。 对于任何一个属性集合 $P$ ，不可分辨关系用 $IND$ 表示，定义如下： IND(P)=\{(x,y) \in U \times U :f(x,a)=f(y,a),a \in P\} 基本集：由论域中相互间不可区分的对象组成的集合，是组成论域知识的颗粒。 见表1，可写出 $r_1,r_2,r_3$ 分别及相互，$d$ 的基本集： IND(r_1)=\{\{x_2,x_3,x_5\},\{x_1,x_4,x_6\}\} \\ IND(r_2)=\{\{x_1,x_3,x_4,x_6\},\{x_2,x_5\}\} \\ IND(r_3)=\{\{x_1,x_2,x_5\},\{x_3,x_6\},\{x_4\}\} \\ IND(r_1,r_2,r_3)=\{\{x_1\},\{x_2,x_5\},\{x_3\},\{x_4\},\{x_6\}\} \\ IND(d)=\{\{x_1,x_2,x_3,x_6\},\{x_4,x_5\}\}集合的上近似和下近似 下近似集 根据现有知识 $R$ ，判断 $U$ 中所有肯定属于集合 $X$ 的对象所组成的集合，即 $\underline{R}(X)=\{x \in U , [x]_R \subseteq X\}$ ，其中， $[x]_R$ 表示等价关系 $R$ 下包含元素 $x$ 的等价类。 上近似集 根据现有知识 $R$ ，判断 $U$ 中一定属于和可能属于集合 $X$ 的对象所组成的集合，即 $\overline{R}(X)=\{x \in U , [x]_R \cap X \neq \varphi \}$ ，其中， $[x]_R$ 表示等价关系 $R$ 下包含元素 $x$ 的等价类。 见表1，取属性子集为 $R=\{r_1,r_2,r_3\}$ ，取样本子集 $X$ 为患流感人群，则 $X=\{x_1,x_2,x_3,x_6\}$ ，$X$ 的下近似和上近似分别为： \underline{R}(X)=\{\{x_1\},\{x_3\},\{x_6\}\} \\ \overline{R}(X)=\{\{x_1\},\{x_2,x_5\},\{x_3\},\{x_6\}\}正域、负域和边界域 正域 $Pos(X)=\underline{R}(X)$ ，即根据知识 $R$ ，$U$ 中能完全确定地归于集合 $X$ 的元素的集合。 负域 $Neg(X)=U-\overline{R}(X)$ ，即根据知识 $R$ ，$U$ 中不能确定一定属于集合 $X$ 的元素集。 边界域 $Bnd(X)=\overline{R}(X)-\underline{R}(X)$ ，边界域是某种意义上论域的不确定域，根据知识 $R$ ，$U$ 中既不是肯定归入集合 $X$，又不能肯定归入集合 $\widetilde{X}$ 的元素集。 边界域为集合 $X​$ 的上近似与下近似之差，如果 $Bnd(X)​$ 是空集，则称集合 $X​$ 关于 $R​$ 是清晰的；反之，如果 $Bnd(X)​$ 不是空集，则称集合 $X​$ 为关于 $R​$ 的粗糙集。 粗糙度对于知识 $R$ （即属性子集），样本子集 $X$ 的不确定程度可以用粗糙度 $\alpha_R(X)$ 来表示为： \alpha_R(X)= \frac{\lvert \underline{R}(X) \rvert}{\lvert \overline{R}(X) \rvert}式中，$\lvert \bullet \rvert $ 表示集合的基数或势，对有限集合表示集合中所包含的元素个数。 显然，$0 \leq \alpha_R(X) \leq 1$ ，如果 $\alpha_R(X)=1$ ， 则称集合 $X$ 关于 $R$ 是清晰的；反之，如果 $\alpha_R(X)&lt;1$， ，则称集合 $X$ 为关于 $R$是粗糙的。$\alpha_R(X)$ 可认为是等效关系 $R$ 下逼近集合 $X$ 的精度。 粗糙隶属函数信息系统论域中元素 $x$ 对集合 $X$ 的粗糙隶属函数定义为： \mu_X(x)=\frac{\lvert X \cap [x]_R \rvert}{\lvert [x]_R \rvert}粗糙隶属函数表示在关系 $R$ 下，元素 $x$ 对集合 $X$ 的隶属程度，在0到1之间。 粗糙集的属性约简属性依赖度利用两个属性集合 $D$ 、$C$ 之间的相互依赖程度，确定在决策属性 $D$ 之下的条件属性集合 $C$ 的重要性，即决策属性集合 $D$ 对条件属性集合 $C$ 的依赖程度用如下定义来表示： \gamma _C(D)=\frac{\lvert Pos_C(D) \rvert}{\lvert U \rvert}见表1，计算属性子集 $R=\{r_1,r_2\}$ 的依赖度： \begin{align*} & IND(R)=\{\{x_1,x_4,x_6\},\{x_2,x_5\},\{x_3\}\} \\ & IND(d)=\{\{x_1,x_2,x_3,x_6\},\{x_4,x_5\}\}=\{d_1,d_2\} \\ & \underline{R}(d_1)=\{x_3\},\; \underline{R}(d_2)=\phi \\ & Pos_R(d)=\{x_3\} \\ & \gamma_R(d)=\frac{1}{6} \approx 0.167 \end{align*}属性约简定义1： 设有决策系统 $S=(U,C \cap D,V,f)$ ，若 $Pos_C(D)=Pos_{C-\alpha}(D)$ ，则称属性 $\alpha$ 为 $C$ 中 $D$ 可省略的，否则属性 $\alpha$ 为 $C$ 中 $D$ 不可省略的。 定义2： 对于一个给定的决策系统，条件属性集 $C$ 的 $D$ 约简是 $C$ 的一个非空子集 $P$ 。若满足： (1) 对于 $P$ 中的任何一个 $\alpha$ ，$\alpha$ 都是 $D$ 不可省略的； (2) $Pos_P(D)=Pos_C(D)$ ，则称 $P$ 是 $C$ 的一个约简， $C$ 中所有约简的集合记作 $Red_D(C)$ . 粗糙集理论的应用 以表1 为例，求决策规则，并进行属性约简： 对象 头疼 $r_1$ 肌肉疼 $r_2$ 体温 $r_3$ 流感 $d$ $x_1$ 否 是 高 是 $x_2$ 是 否 高 是 $x_3$ 是 是 很高 是 $x_4$ 否 是 正常 否 $x_5$ 是 否 高 否 $x_6$ 否 是 很高 是 (1) 寻找不可分辨关系 “头疼”：$IND(r_1)=\{\{x_2,x_3,x_5\},\{x_1,x_4,x_6\}\} $ “肌肉疼”：$IND(r_2)=\{\{x_1,x_3,x_4,x_6\},\{x_2,x_5\}\}$ “体温”：$IND(r_3)=\{\{x_1,x_2,x_5\},\{x_3,x_6\},\{x_4\}\}$ “头疼+肌肉疼”：$IND(r_1,r_2)=\{\{x_1,x_4,x_6\},\{x_2,x_5\},\{x_3\}\}$ “头疼+体温”：$IND(r_1,r_3)=\{\{x_1\},\{x_2,x_5\},\{x_3\},\{x_4\},\{x_6\}\}$ “肌肉疼+体温”：$IND(r_2,r_3)=\{\{x_1\},\{x_2,x_5\},\{x_3,x_6\},\{x_4\}\}$ “头疼+肌肉疼+体温”：$IND(r_1,r_2,r_3)=\{\{x_1\},\{x_2,x_5\},\{x_3\},\{x_4\},\{x_6\}\}$ (2) 针对各个属性下的初等集合寻找下近似和上近似 以“头疼+肌肉疼+体温” 为例，设集合 $X$ 为患流感人群的集合，$X=\{x_1,x_2,x_3,x_6\}$ . 集合 $X$ 的下近似为：$\underline{R}(X)=Pos_R(X)=\{x_1,x_3,x_6\}$ 集合 $X$ 的上近似为：$\overline{R}(X)=\{x_1,x_2,x_3,x_5,x_6\}$ 集合 $X$ 的负域为：$Neg(X)=\{x_4\}$ 集合 $X$ 的边界域为：$Bnd(X)=\{x_2,x_5\}$ (3) 由下近似可得： Rule1 : IF ( 头疼 = 否 ) and ( 肌肉疼 = 是 ) and ( 体温 = 高 ) THEN 患有流感 Rule2 : IF ( 头疼 = 是 ) and ( 肌肉疼 = 是 ) and ( 体温 = 很高 ) THEN 患有流感 Rule3 : IF ( 头疼 = 否 ) and ( 肌肉疼 = 是 ) and ( 体温 = 很高 ) THEN 患有流感 由负域得到： Rule4 : IF ( 头疼 = 否 ) and ( 肌肉疼 = 是 ) and ( 体温 = 正常 ) THEN 没患流感 由边界域得到： Rule5 : IF ( 头疼 = 是 ) and ( 肌肉疼 = 否 ) and ( 体温 = 高 ) THEN 可能患流感 (4) 属性约简 由(2)可得，$Pos_R(X)=\{x_1,x_3,x_6\}$ ，同理我们对不同属性子集求得以下正域： $Pos_{R-r_1}(X)=\{x_1,x_3,x_6\}$ $Pos_{R-r_2}(X)=\{x_1,x_3,x_6\}$ $Pos_{R-r_3}(X)=\{x_3\}$ $Pos_{R-\{r_1,r_2\}}(X)=\{x_1,x_3,x_6\}$ $Pos_{R-\{r_1,r_2\}}(X)=\{x_1,x_3,x_6\}$ $Pos_{R-\{r_1,r_2\}}(X)=\{x_1,x_3,x_6\}$ $Pos_{R-r_1-r_2}(X)=\{x_1,x_3,x_6\}$ $Pos_{R-\{r_1,r_2\}}(X)=\{x_3,x_6\}$ $Pos_{R-\{r_1,r_3\}}(X)=\phi $ $Pos_{R-\{r_2,r_3\}}(X)=\phi $ 由于 $Pos_R(X)=Pos_{R-r_1}(X)=Pos_{R-r_2}(X)$ ，根据定义，$\{r_1,r_3\}$ 和 $\{r_2,r_3\}$ 均为条件属性集 $C$ 的 $D$ 约简。 参考文献 粗糙集决策方法 粗糙集理论介绍 粗糙集决策方法 刘盾. 基于粗糙集理论的多属性决策方法[D]. 西南交通大学, 2011. SunB,MaW,ZhaoH.Roughset-basedconflictanalysismodelandmethodovertwouniversesM.ElsevierScienceInc.2016.]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>学习笔记</tag>
        <tag>决策理论与方法</tag>
        <tag>Rough Set</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Improving Deep Neural Networks - Week 2 - (2)]]></title>
    <url>%2F2018%2F03%2F08%2F20-Improving-Deep-Neural-Networks-Week-2-2%2F</url>
    <content type="text"><![CDATA[第二周课程的第二部分，主要为 momentum 、 RMSprop、Adam optimization 等快速梯度下降的优化算法，欢迎大家关注！ Optimization algorithmsGradient descent with momentum Gradient descent example 如图，针对上面一个 cost function（椭圆），标准梯度下降（蓝线）会随着迭代不断逼近椭圆中心。其中，选择合适的学习率很重要，若学习率过大，则会出现紫线的情况，容易错过中心；若学习率过小，步伐很小，达到中心的速度也会很慢。 那么，是否有什么办法能够让学习步伐更大，而又能朝着正确方向进行训练呢？简单来说，就如上图，怎么才能保证在竖直方向上偏离很小，而在水平方向上学习步伐更大呢？ momentum 是一个好方法，事实上 momentum 就是将 exponentially weighted averages 运用到 mini-batch gradient descent 中。下面详解 momentum 过程： 1234567# MomentumOn iteration t : Compute dw , db on current mini-batch V_dw = beta * V_dw + (1 - beta) * dw V_db = beta * V_db + (1 - beta) * db w := w - alpha * V_dw b := b - alpha * V_db 显然，对梯度进行移动平均，在竖直方向上的波动就会趋于平缓，而在水平方向上，由于梯度都朝着正确的方向下降，因此在水平上的移动仍保持较大的步伐。这就是为什么结合 momentum 的 gradient descent 能够快速到达 cost 最低点的原因。 Implementation details (1) In pratice, $\beta$ equals 0.9 works well. Feel free to try different values and do some hyperparameter search, but 0.9 appears to be a pretty robust value. (2) In pratice, people don’t usually do bias correction because after 10 iterations, moving average will haved warmed up and is no longer a bias estimate. (3) $V_{dw}$ should initialized with 0 and it should be a matrix of zeros with the same dimension as $dW$, which has the same dimension as $W$. So as $V_{db}$. (4) The term $(1-\beta)$ can be omitted. So you end up with $V_{dw}=\beta V_{dw}+dW$ and $V_{db}=\beta V_{db}+db$ . $(1-\beta)$ 可以被省略的原因是因为它可以被提出来放到学习率 $\alpha$ ，只要 $\alpha$ 随之发生改变则不会影响梯度下降的效果。但不建议这么做，因为你需要重新调整学习率。 (5) Momentum takes past gradients into account to smooth out the steps of gradient descent. It can be applied with batch gradient descent, mini-batch gradient descent or stochastic gradient descent. RMSprop (Root Mean Square Prop)RMSprop 的作用和 momentum 相同，都是为了加快梯度下降的速度。那么 RMSprop 相对于 momentum 来说，又有哪些不同？ 123456On iteration t: Compute dw, db on current mini-batch S_dw = beta * S_dw + (1 - beta) * dw^2 S_db = beta * S_db + (1 - beta) * db^2 w := w - alpha * dw / sqrt(S_dw) b := b - alpha * db / sqrt(S_db) 由于我们希望在竖直方向上（仍见上 cost function 图）减小其波动，而在水平方向上保持宽大的步伐。那么，则需 $S_{dw}$ 更小，$S_{db}$ 更大，才能保证 $\omega$ 收敛速度更快，$b$ 收敛更慢，即梯度在水平方向上更快下降，而在竖直方向上更为平缓。 使用 RMSprop 后可采用更大的学习率 $\alpha$ 而不必担心会在竖直方向上跨度很大。 Adam optimization algorithm上两节讲了 momentum 和 RMSprop 两种快速梯度下降的优化方法，而本节的 Adam optimization algorithm 恰恰是前面两种方式的结合，它们的结合又会产生怎样的效果呢？我们拭目以待。 1234567891011121314# Adam ： Adaptive Moment EstimationV_dw = 0, S_dw = 0, V_db = 0, S_db = 0On iteration t: Compute dw, db on current mini-batch V_dw = beta1 * V_dw + (1 - beta1) * dw V_db = beta1 * V_db + (1 - beta1) * db S_dw = beta2 * S_dw + (1 - beta2) * dw^2 S_db = beta2 * S_db + (1 - beta2) * db^2 V_dw^&#123;corrected&#125; = V_dw / (1 - beta1^t) V_db^&#123;corrected&#125; = V_db / (1 - beta1^t) S_dw^&#123;corrected&#125; = S_dw / (1 - beta2^t) S_db^&#123;corrected&#125; = S_db / (1 - beta2^t) w:=w-alpha*V_dw^&#123;corrected&#125;/(sqrt(S_dw^&#123;corrected&#125;)+epsilon) b:=b-alpha*V_db^&#123;corrected&#125;/(sqrt(S_db^&#123;corrected&#125;)+epsilon) Hyperparameters choice: (1) $\alpha$ : needs to be tune (2) $\beta_1$ : 0.9 （可不调） (3) $\beta_2$ : 0.999 （可不调） (4) $\varepsilon$ : $10^{-8}$ (don’t really need to set it because it doesn’t affect performance much at all. ) 后面三个参数都可以固定不调，我们只需不断调整 $\alpha$ 得到最快的梯度下降速度即可。 Learning rate decayLearning rate decay ，就是通过不断缓慢地减小学习率 $\alpha$ ，从而提升梯度下降速度的一种优化方法。为什么减小学习率能加快梯度下降的速度？那是因为在梯度下降过程中，若学习率一直保持不变，则会一直保持同样的步伐，即使逼近最优点，也只能在最优点附近徘徊而无法收敛。只有不断减小学习率，才能慢慢地向 cost 最优点靠近并接触（可参考下图）。 Implementing learning rate decay Recall that “1 epoch” means 1 pass through data . Therefore, set : \alpha = \frac{1}{1+decay_{rate} \times epoch_{num}} \alpha_0 \tag{1}where, $\alpha_0$ is initial learning rate, $decay_{rate}$ is decay rate, another hyperparameter. 从式(1)可见，随着迭代次数的增大，学习率 $\alpha$ 也在不断减小。 Other learning rate decay methods (1) $\alpha = 0.95^{epoch-num} \alpha_0$ (2) $\alpha =\frac{k}{\sqrt{epoch-num}} \alpha_0$ or $\alpha =\frac{k}{\sqrt{t}} \alpha_0$ , where $k$ is a constant, $t$ denotes mini-batch number t. (3) discrete staircase: 在每个时刻，连续地对学习率减半。 The problem of local optima在深度学习的发展初期，大家都比较担心的是局部最优的问题。但随着深度学习理论的丰富，人们对局部最小的看法也在不断改变。 事实上，在 cost function 中，多数梯度为0的点都是鞍点（什么是鞍点可自行百度）。对于一个局部最优点，即意味着在所有维度的投影下，cost 都呈现凸函数或偶函数的图像，这是局部最优。 但在高维度中，几乎很小的可能出现所有的维度投影都为凸函数或偶函数，更大的可能是在一个维度下呈现凸函数，而在另一个维度下呈现凹函数，比如说鞍点（见下图）。 由于在深度神经网络中，局部最优点出现的可能性微乎其微，人们不再担心这个问题，那更关注的问题是什么？ plateaus便是其中之一。 plateaus 是梯度接近于 0 的平缓区域，在这里学习速度会大大降低，鞍点通常被plateaus 所包围。 因此，对于深度神经网络来说： Unlikely to get stuck ina bad local optima Plateaus can make learning slow. 但，至少 momentum , RMSprop, Adam 等优化算法能提高梯度下降，加快脱离 plateaus 的速度。 参考文献 Improving Deep Neural Networks - Week 2]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Improving Deep Neural Networks - Week 2 - (1)]]></title>
    <url>%2F2018%2F03%2F07%2F19-Improving-Neural-Networks-Week-2%2F</url>
    <content type="text"><![CDATA[欢迎来到课程第二周，上周课程主要讲了训练神经网络的一系列优化方法，如正则化、Dropout、随机初始权重和梯度检验等，这周主要内容是上一周的进一步拓展，同样是一些优化算法，但或许在难度上会更大一些。 Optimization algorithmsMini-batch gradient descent当训练集数量很大（例如 5,000,000 条数据），mini-batch gradient descent 可加快训练的速度。那么mini-batch gradient descent 该如何实现呢？ 首先，将整个 training set 划分为多份小训练集（每个小训练集 1,000 条数据），这些小的训练集称为 mini-batches，那么整个 training set 共有 5,000 个 mini-batches. 顾名思义，mini-batch gradient descent 就是对 mini-batches 进行梯度下降，而非对整个 training set 求梯度下降。 注： 在之前，我们用小括号 $x^{(i)}$ 表示第 $i$ 个训练样本，用中括号 $z^{[l]}$ 表示神经网络第 $l$ 层的节点值。现在，我们用大括号 $x^{\{t\}}$ 表示第 $t$ 个 mini-batches训练集. mini-batch gradient descent 过程如图： “1 epoch” : a single pass through training set, that means it has been taken 5,000 gradient descent steps. Understanding mini-batch gradient descent 采用两种梯度下降的方式，得到的 cost曲线图，我们可以发现，普通梯度下降算法 (Batch gradient descent) 的cost 下降较为平缓，而 mini-batch 梯度下降 cost 曲线会带有噪音。至于出现噪声的原因没搞懂，在这里把原话记下来供大家参考理解： It should trend downwards, and the reason it’ll be a little bit noisy is that, maybe X{1}, Y{1} is just the rows of easy mini batch so your cost might be a bit lower, but then maybe just by chance, X{2}, Y{2} is just a harder mini batch. Maybe you needed some mislabeled examples in it, in which case the cost will be a bit higher and so on. So that’s why you get these oscillations as you plot the cost when you’re running mini batch gradient descent. Choosing your mini-batch size If mini-batch size = m : Batch gradient descent $(X^{\{1\}}, Y^{\{1\}})=(X, Y)$ If mini-batch size = 1 : Stochastic gradient descent $(X^{\{1\}}, Y^{\{1\}})=(x^{(1)}, y^{(1)})$ (Every example is its own mini-batch) 三种梯度下降方式的比较（椭圆为 cost function ）： Batch gradient descent: 几乎没有噪音，步伐较大，能平滑直接地朝椭圆中心下降，但当训练集太大时，每次迭代都将消耗太长时间（见图中蓝线）。 Stochastic gradient descent: 随机走动，大体会向中心下降，但也常常会往错误方向走，难以收敛至最低点，噪音大（可通过减少学习率解决），最大的不足是: 计算梯度下降速度很快，都由于要对每一个样本进行梯度计算，从而导致效率十分低下（见图中紫线）。 Mini-batch gradient descent: batch-size 在普通梯度下降和随机梯度下降之间， 因此结合了两者的优点。(1) 多个样本结合进行向量化计算梯度，比单个样本计算梯度更快更有效率；(2) 处理整个 training set 同样变得更为方便，每次迭代计算多次梯度，无需耗费太长时间（见图中绿线）。 Tips : (1) 对于小数据集（如训练样本在2,000以内），直接采用 batch gradient descent; (2) 使用 mini-batch gradient descent，典型的 mini-batch size 通常采用2的次方，如64，128，256，512等; (3) Make sure mini-batch fit in CPU / GPU memory. Exponentially weighted averages 指数加权移动平均，相信大家都应该知道，这一节就不多记了。 指数加权移动平均公式： V_0=0 \\ V_t=\beta V_{t-1}+(1-\beta) \theta_t当 $\beta​$ 越大时，指数加权移动平均线波动越小，越平缓，反之波动越大。如图： $\beta=0.9$，为红线；$\beta=0.98$，为绿线；$\beta=0.5$，为黄线； Understanding exponentially weighted averages Implementing EWA 12345V_theta = 0Repeat &#123; get next theta_t V_theta = beta * V_theta + (1 - beta) * theta_t&#125; 求指数加权移动平均比求算术平均要更好，因为加权移动平均只需保留 $V_{\theta}$ 在内存中，然后不断更新迭代，就能计算平均数，大大加快了运算速度。而算术平均则需要将所有值储存，再除以个数才能得到平均数，虽然能保证平均数更加准确，但效率更低，且消耗内存更大。 Bias correction in exponentially weighted averages指数加权移动平均相对算术平均得到平均数误差要大一些，在这里采用 Bias correction 对加权移动平均数进行修正。 从上面两节可知，加权移动平均初始值 $V_0=0$ ，那么 $V_1=0.98V_0+0.02\theta_1=0.02\theta$ ，显然，加权移动平均数在开始时是十分不准确的，那么如何纠正呢？ Bias correction : set $\hat{V_t}=\frac{V_t}{1-\beta^t}$ 在前期，$\hat{V_t}$ 能较好地修正 $V_t$ ，而随着时间 $t$ 的不断增大，$\beta_t$ 越来越趋近于 0，$\hat{V_t}$ 和 $V_t$ 将慢慢重合，保证了指数加权移动平均数的准确性。 未完待续~~ 参考文献 Improving Deep Neural Networks - Week 2]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Improving Deep Neural Networks - Week 1 - (2)]]></title>
    <url>%2F2018%2F03%2F05%2F18-Improving-Deep-Neural-Networks-Week-1-2%2F</url>
    <content type="text"><![CDATA[有时候感觉更新博客实在是挺麻烦的，写一篇博文还是蛮耗时间的，或许万事开头难吧，但每次更新后看到自己的主页上多了一篇文章，仿佛自己又充实了一点，欣慰的感觉油然而起，所以还是希望能坚持下去。 未来的你会感谢今天努力的自己！ 最近不经意总是看到这么一句鸡汤，那就送给自己吧。 P.S ：第1周的学习笔记还没完结，见 上篇博文 ，现在继续开始吧 …… Setting up your optimization problemNormalizing inputs嗯 … 初始数据标准化的重要性，我想不需要多讲，大家都知道。不管是什么模型，当对于量纲不同的数据特征来说，标准化是最重要，也是最开始就必须干的事。常用的标准化方法，如 Z-Score 法等。 在这里需要注意的是，Training Set 和 Test Set 应使用同一种方法进行标准化，而且标准化中运用到的均值和标准差，必须是 全部数据的均值和标准差 （包括Training set和Test set），不应使用 Training set 和 Test set 的均值和标准差分别进行标准化。 Vanishing / Exploding gradients什么是梯度消失 (gradients vanishing )？什么是梯度爆炸 (gradients exploding )？简单来说就是在神经网络训练过程中，参数矩阵的梯度（也就是导数、斜率）在每一步的迭代中变得越来越小（梯度消失），或越来越大（梯度爆炸），它们将导致训练越来越困难。那它们是怎么产生的呢？ 看上面一个神经网络，层数很多，但每层的节点都只有两个。显然，每层都存在参数矩阵 ($ \omega^{[1]},\omega^{[2]},…,\omega^{[L]}$) ，那么梯度下降的过程如下： 12345678910# g(z)=z , b[l]=0# 在每一层的传递中# z[1]=w[1]x# a[1]=g(z[1])=z[1]# a[2]=g(z[2])=g(w[2]a[1])# 以此类推，那么有# y_hat=w[L]w[L-1]w[L-2]...w[3]w[2]w[1]x# 假设每一层w的初始值都为二维矩阵 [1.5 0 ; 0 1.5]，当L很大时，显然y_hat=1.5^(L-1)x 也将变得十分巨大# 假设每一层w的初始值都为二维矩阵 [0.5 0 ; 0 0.5]，当L很大时，显然y_hat=1.5^(L-1)x 将变得尤其小# 这就是梯度爆炸或梯度消失产生的原因 梯度消失有什么坏处？若梯度远远小于层数，那么梯度下降的每一步都会变得很小，也就是说即使训练再长时间，也很难学习到东西。 那么如何解决？随机初始权重是一个方法，详见下一节。 Weight initialization for Deep Networks如何进行随机初始权重？下面举一个简单的例子。 Single neuron example 对于每一层的输入 $x_i$ ，有 $z=\omega_1x_1+\omega_2x_2+…+\omega_nx_n$ （在此忽略常数 $b$），当 $n$ 越大时，为了不使 $z$ 爆炸，$\omega_i$ 得越小。那么随机初始权重如下： 12345678910Var(w_i) = 1/n # 设参数 w_i 的方差为 1/n# 对于第l层，随机初始权重方法应为(Xavier initialization)：w[l] = np.random.randn( w[l].shape) * np.sqrt(1/n[l-1])g[l](z) = tanh(z)# 对于Relu激活函数，方差设为 2/n 更好，即w[l] = np.random.randn( w[l].shape) * np.sqrt(2/n[l-1])g[l](z) = Relu(z)# 此时，参数矩阵 w 既不太大于1，也不太小于1，在梯度下降时不至成指数爆炸，也不会急速减小，即使不能完全避免梯度爆炸或梯度消失，但至少起到了很大帮助。 What you should remember: The weights $W^{[l]}$ should be initialized randomly to break symmetry. It is however okay to initialize the biases $b^{[l]}$ to zeros. Symmetry is still broken so long as $W^{[l]}$ is initialized randomly. Numerical approximation of gradients该节讲的是比较基础的梯度估计，估计大家都在高数或数分中学过，在此不废时间记了。 Gradient checking在检查 back propagation 的 bug 时，gradient checking 是一个很有效的方法。本节主要讲讲如何进行 gradient checking。 首先，将 $W^{[1]},b^{[1]},…,W^{[L]},b^{[L]}$ 分别拉直成一列并连接在一起，形成一个大的向量 $\theta$ ；同理，将 $dW^{[1]},db{[1]},…,dW{[L]},db{[L]}$ 拉直连接，形成 $d\theta$ . 那么，cost function 即为 $\theta$ 的函数。 那么，for each i : \begin{aligned} d\theta_{appro}[i] &= \frac{J(\theta_1,\theta_2,...,\theta_i+\varepsilon,...)-J(\theta_1,\theta_2,...,\theta_i-\varepsilon,...)}{2\varepsilon} \\ &\approx d\theta[i]=\frac{\partial J}{\partial \theta_i} \end{aligned} \tag{1}Check : \frac{\lVert d\theta_{approx}-d\theta \rVert _2}{\lVert d\theta_{approx} \rVert_2+\lVert d\theta \rVert_2} \tag{2}当取 $\varepsilon$ 为 $10^{-7}$ 时，若公式(2) 的值约为 $10^{-7}$ ，说明梯度计算几乎没有出错，可以放心了；若约为 $10^{-5}$ ，那么还得稍稍注意一点，查看是否哪里出现了bug；若约为 $10^{-3}$ 或以上，那么很可能出现了计算错误，应细心分析。 Gradient Checking Implementation Notes本节讲述在进行 gradient checking 时应注意的一些细节。 Don’t use in training - only to debug 在训练中无需进行checking，防止计算过慢 If algorithm fails grad check, look at components to try to identify bug. 在检查 bug 的时候，可针对每个 $i$ ，去检查 $d\theta_{approx}[i]$ 和 $d\theta[i]$ ，因为每个 $d\theta[i]$ 对应着 $db^{[L]}$ 和 $dW^{[L]}$ . Remember regularization. Doesn’t work with dropout. 由于dropout在训练过程中会随机减少隐含层的节点进行训练，导致 cost function 十分难以计算，同时也导致了梯度难以计算，因此在gradient checking并不和dropout 同时使用。 Run at random initialization; perhaps again after some training. 梯度下降时 $\omega$ 和 $b$ 应越来越收敛，但当随机初始权重时得到的权重矩阵和常数矩阵恰好在0附近时， $\omega$ 和 $b$ 可能随着训练越来越大，在此时进行grad check很可能出错。因此可以经过训练一阵后，再次进行grad check会更好。 What you should remember from gradient checking Gradient checking verifies closeness between the gradients from backpropagation and the numerical approximation of the gradients (computed using forward propagation) Gradients checking is slow, so we don’t run it in every iteration of training. You would usually run it only to make sure your code is correct, then turn it off and use backprop for the actual learning process. 参考文献 Improving Deep Neural Networks - Week 1]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Improving Deep Neural Networks - Week 1 - (1)]]></title>
    <url>%2F2018%2F03%2F04%2F17-Improving-Deep-Neural-Networks-Week-1%2F</url>
    <content type="text"><![CDATA[吴恩达老师的深度学习课程是质量很高的一门课程，之前上过他的机器学习，听完后不能自拔，学到很多东西。对于他新开的这门深度学习，我是充满了期待，在这里将听课的一些要点和自己的学习感想记录下来，分享给大家，希望和大家共同进步！ 本次课是深度学习专项课程的第二门：Improving Deep Neural Networks ，本文从第一周开始。 Setting up your Machine Learning ApplicationTrain / Dev / Test sets Applied ML is a highly iterative process 建立一个机器学习模型是个多次重复的过程，我们需要考虑很多参数，如神经网络的层数和节点等，还有更多的超参数，如学习率、激活函数的选择等。事实上，很难知道如何选择这些参数可以使得模型效果更好，往往我们是采用不断尝试的过程，也就是调参。 上图便反映了建立机器学习模型中不断循环往复的过程。那么如何尽量地缩短这个过程呢？最开始也最重要的就是合理地划分 Train / dev / test set . Train / dev / test set (1) 当数据量不太大时（1万以内），Train / Test : 70% / 30% 是比较合适的，或者 Train / Dev / Test : 60% / 20% / 20% 也可以。 (2) 当数据量较大时（百万级别），Train / Dev / Test : 98% / 1% / 1% ，甚至更少的 Dev / Test 都是可以接受的。 Mismatched train/test distribution (1) Make sure that dev set and test set come from the same distribution. (2) Not having a test set might be okay. (Only dev set. ) Bias / Variance We less talk about Bias-Variance Trade-off in deep learning. Train set error: tell you about the bias problem; Dev set error: variance problem. e.g. HIGH VARIANCE HIGH BIAS BOTH HIGH BOTH LOW Train set error 1% 15% 15% 0.5% Dev set error 11% 16% 30% 1% Basic “Recipe” for Machine Learning通常在机器学习中，我们常常会以 “Bias-Variance Trade-off” 作为评价整个模型的指标。也就是说，针对一个模型，它在训练集中得到的结果如何？是否出现High Bias ？如果Bias 很小，OK。那么在验证集中得到的结果又如何？是否出现High Variance？ 由于在过去( pre-deep learning era )，没有太好的方法在减少Bias的同时，又减少Variance，两者往往会出现冲突。因为最好的办法只有在Bias和Variance之间尽量取得平衡(Bias-Variance Trade-off)，两者之间都不太大。 然而，由于数据量的急剧增多，且深度学习理论的发展，我们现在既能够保证Bias足够小（如添加隐含层、添加节点、设计更复杂的神经网络等），又能保证Variance足够低（如使用更过数据、添加正则项等），在减少任意一方的同时，也不会使另一方增大。 因此，Bias-Variance Trade-off 慢慢不再成为评价深度学习模型的指标，直接以Bias和Variance为准。 Regularizing your neural networkRegularization当模型出现 High Variance 的时候，一个很好的解决方法就是使用正则化 (Regularization) 。如何实现正则化呢？首先我们得从cost function 开始。 Logistic Regression \begin{array}{l} \mathop \min \limits_{\omega ,b} J(\omega ,b)\\ J(\omega ,b) = \frac{1}{m}\sum\limits_{i = 1}^m L( \hat{y}^{(i)},y^{(i)}) + \frac{\lambda }{2m}\left\| \omega \right\|_2^2 \end{array} \tag{1}其中，$J(\omega ,b)$ 为cost function , $\omega \in R^{n_x},b \in R$, $\lambda $ 为正则化参数。 通常，正则项有多种形式，在上述公式中为 L2 正则项。 L2 Regularization: $ \lVert \omega \rVert_2^2=\sum\limits_{j=1}^{n_x} \omega_j^2=\omega^T\omega $ L1 Regularization : $\frac{\lambda }{m}\sum\limits_{j = 1}^{n_x} {\left| {\omega _j} \right|} = \frac{\lambda }{m}{\lVert \omega \rVert_1}$ 一般，在L1正则项中，$\omega ​$ 通常是稀疏的，也就是说在 $\omega ​$中会出现许多0。因此L2正则项会更为常用。 Neural Network \begin{array}{l} J(\omega ^{[1]},b^{[1]}, \ldots ,\omega ^{[L]},b^{[L]}) = \frac{1}{m}\sum\limits_{i = 1}^m L( \hat{y} ^{(i)},y^{(i)}) + \frac{\lambda }{2m} \sum\limits_{L = 1}^L \left\| \omega ^{[L]}\right\|^2\\ \left\| \omega ^{[L]} \right\|_F^2 = \sum\limits_{i = 1}^{n^{[L - 1]}} \sum\limits_{j = 1}^{n^{[L]}} (\omega _{ij}^{[L]})^2 \end{array} \tag{2}其中，$\omega :(n^{[L]},n^{[L - 1]})$ ，该正则项为 “Frobenius norm”。 根据上面的 cost function，我们如何实现梯度下降呢？ \begin{array}{l} \frac{\partial J}{\partial \omega ^\left[ L \right]} = d\omega ^\left[ L \right] = (from \; backprop) + \frac{\lambda }{m}\omega ^\left[ L \right]\\ \omega ^{\left[ L \right]}: = \omega ^\left[ L \right]- \alpha d\omega ^\left[ L \right] \end{array} \tag{3}上两式相互结合，可得： \begin{array}{c} \omega ^\left[ L \right]: = \omega ^\left[ L \right] - \alpha \left[ (from\;backprop) + \frac{\lambda }{m}\omega ^\left[ L \right] \right]\\ = \omega ^\left[ L \right] - \frac{\alpha \lambda }{m}\omega ^\left[ L \right] - \alpha (from\;backprop) \end{array} \tag{4}从上述结果即可得到，将 $\omega ^\left[ L \right]$提取出来， $(1 - \frac{\alpha \lambda }{m})$总是小于1的，因此这就是L2正则项为什么会权值衰减 (weight decay) 的原因。 What you should remember — the implications of L2-regularization on: The cost computation: A regularization term is added to the cost The backpropagation function: There are extra terms in the gradients with respect to weight matrices Weights end up smaller (“Weight decay”): Weights are pushed to smaller values Why regularization reduces overfitting? 正则化是如何避免过拟合的？ 由公式(2)可知，为保证 cost function 尽量小，当设定超参数 $\lambda $ 越大时，参数矩阵 $\omega ^\left[ L \right]$ 就得尽量小。那么当参数矩阵越接近0（在每一次梯度下降中都会越来越小），每一层的激活函数都会越接近于线性函数，由此Variance 就有越来越小，而Bias越来越大，从而避免了过拟合的产生。 以 tanh 函数为例，当定义域范围越靠近0时，函数图像越趋近于线性函数。 Dropout Regularization“Dropout”是什么意思呢？一个简单的理解就是，对于一个复杂的神经网络，我们在其每一层的输出传递中设定一个概率 p，每一层的节点输出，都以p的概率传递到下一层，以1-p的概率被dropout，从而降低了神经网络的复杂度。 很神奇的是，概率p的设定是随机的，但对于神经网络的训练确实有很大帮助。那么如何实现dropout呢？dropout的方式有很多种，较为常见的就是Inverted Dropout。 Inverted Dropout 123456# illustrate with layer l = 3.# keep-prob = 0.8# d3: dropout vector for layer 3d3 = np.random.rand(a3.shape[0], a3.shape[1]) &lt; keep-proba3 = np.multiply(a3, d3)a3 /= keep-prob 在最后一步中，第一层的输出a3要除概率，有点不太理解，公开课上的解释是由于a3 损失了20%的值（被dropout），因此为了保证其均值相同，a3每个元素都应除以概率。 Making predictions at test time 在测试集的预测中，我们不再需要使用dropout，因为dropout带着随机的成分，而我们希望在预测中尽量能保证准确，而非随机。训练集中的dropout在一定程度上是为了简化模型的训练。 With the inverted dropout technique, at test time: You do not apply dropout (do not randomly eliminate units) and do not keep the 1/keep_prob factor in the calculations used in training. Understanding Dropout上节讲了dropout对神经网络的训练虽然起到了简化的作用，但是为什么不会影响正则化的效果呢？这是这节的重点。 Intuition: Can’t rely on any one feature, so have to spread out weights. 如上图，对于每一个中间层节点（紫色圆），其输入的节点都有一定概率被dropout，因此在每一层的信息传递中，不会仅仅依赖于某个特征，且每个节点的权重都不会相差太大，这就避免了部分信息的严重缺失，这是dropout 能work的原因之一。 另外对于不同节点数的层，其概率(keep-prob)可进行合理调整。 当两边节点数较多时，即参数矩阵 维数较大时，keep-prob可设置在0.5左右； 当两边节点数较少时，keep-prob设置应大一些，避免信息流失。 通常，在神经网络较为复杂时（节点、层数较多），如 Computer Vision中图像像素维度很大时 ，dropout使用更为普遍。但对于较小的网络，则不建议使用dropout。 What you should remember about dropout: Dropout is a regularization technique. You only use dropout during training. Don’t use dropout (randomly eliminate nodes) during test time. Apply dropout both during forward and backward propagation. During training time, divide each dropout layer by keep_prob to keep the same expected value for the activations. For example, if keep_prob is 0.5, then we will on average shut down half the nodes, so the output will be scaled by 0.5 since only the remaining half are contributing to the solution. Dividing by 0.5 is equivalent to multiplying by 2. Hence, the output now has the same expected value. You can check that this works even when keep_prob is other values than 0.5. Other regularization methods(1) Data augmentation 当数据量不够大时，或数据获取成本太高时，我们可以采用一些方法对数据进行扩充。比如说猫的图像识别中，对图像进行一个角度的倾斜和反转，可增加一个训练样本。 (2) Early stopping 上图中蓝线是Training error ，紫线为 Dev set error。Early Stopping 顾名思义，即当训练集和测试集的cost function均达到最小时，选取其对应的迭代次数。 显然，在神经网络中，最主要的两个目标就是： Optimize cost function J (gradient descent) Not overfit (Regularization) 对于每个目标，都有多种方法去进行优化，后续将继续讲解。 参考文献 Improving Deep Neural Networks - Week 1]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neural Networks and Deep Learning - Week 4]]></title>
    <url>%2F2018%2F03%2F04%2F16-Neural-Networks-and-Deep-Learning-Week-4%2F</url>
    <content type="text"><![CDATA[这个课程是上学期听的，这学期因为听着第二门课程 (Improving Deep Neural Network)，因此先做第二门课程的笔记了。在这里先占个位，提醒自己如果有时间会慢慢补上以前的笔记，欢迎大家关注！]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neural Networks and Deep Learning - Week 3]]></title>
    <url>%2F2018%2F03%2F04%2F15-Neural-Networks-and-Deep-Learning-Week-3%2F</url>
    <content type="text"><![CDATA[这个课程是上学期听的，这学期因为听着第二门课程 (Improving Deep Neural Network)，因此先做第二门课程的笔记了。在这里先占个位，提醒自己如果有时间会慢慢补上以前的笔记，欢迎大家关注！]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neural Networks and Deep Learning - Week 2]]></title>
    <url>%2F2018%2F03%2F04%2F14-Neural-Networks-and-Deep-Learning-Week-2%2F</url>
    <content type="text"><![CDATA[这个课程是上学期听的，这学期因为听着第二门课程 (Improving Deep Neural Network)，因此先做第二门课程的笔记了。在这里先占个位，提醒自己如果有时间会慢慢补上以前的笔记，欢迎大家关注！]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Neural Networks and Deep Learning - Week 1]]></title>
    <url>%2F2018%2F03%2F04%2F13-Neural-Networks-and-Deep-Learning-Week-1%2F</url>
    <content type="text"><![CDATA[这个课程是上学期听的，这学期因为听着第二门课程 (Improving Deep Neural Network)，因此先做第二门课程的笔记了。在这里先占个位，提醒自己如果有时间会慢慢补上以前的笔记，欢迎大家关注！]]></content>
      <categories>
        <category>Course</category>
      </categories>
      <tags>
        <tag>Deep Learning</tag>
        <tag>Neural Networks</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas系列教程（七）]]></title>
    <url>%2F2018%2F03%2F02%2F12-Pandas%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%EF%BC%88%E4%B8%83%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这是教程系列之七，也是该系列的最后一次课程，对应 Data analysis in Python with pandas 视频29~30，欢迎大家关注。 新建 DataFrame 的多种方式 方式一：直接使用pd.DataFrame() 123456789# 分别定义生成键和值# 这种方式新建的DataFrame，其键按字母排序，即color列在前，id列在后df = pd.DataFrame(&#123;&apos;id&apos;:[100,101,102], &apos;color&apos;:[&apos;red&apos;,&apos;blue&apos;,&apos;red&apos;]&#125;) # 通过设定参数columns可固定每列的位置，同时参数index可设置行标签df = pd.DataFrame(&#123;&apos;id&apos;:[100,101,102],&apos;color&apos;:[&apos;red&apos;,&apos;blue&apos;,&apos;red&apos;]&#125;,columns=[&apos;id&apos;,&apos;color&apos;],index=[&apos;a&apos;,&apos;b&apos;,&apos;c&apos;])# 也可不使用字典的方式新建DateFramepd.DataFrame([[100,&apos;red&apos;],[101,&apos;blue&apos;],[102,&apos;red&apos;]],columns=[&apos;id&apos;,&apos;color&apos;]) 方式二：通过np.array()进行转化 123456import numpy as nparr = np.random.rand(4,2)pd.DataFrame(arr,columns=[&apos;one&apos;,&apos;two&apos;])# 或者 pandas 和 numpy 结合pd.DataFrame(&#123;&apos;student&apos;:np.arange(100,110,1),&apos;test&apos;:np.random.randint(60,101,10)&#125;).set_index(&apos;student&apos;) 方式三：通过pd.Series() 进行转化 12345# 任意生成一序列s = pd.Series([&apos;round&apos;,&apos;square&apos;],index=[&apos;c&apos;,&apos;b&apos;],name=&apos;shape&apos;)# Dataframe 与 Series 的合并pd.concat([df,s],axis=1) DataFrame或Series中函数的使用 Series.apply() 的使用，效果可见代码下图片 123456789101112131415161718train = pd.read_csv(&apos;data/titanic_train.csv&apos;)# 查看字符串的长度train[&apos;Name_length&apos;] = train.Name.apply(len)train.loc[0:4,[&apos;Name&apos;,&apos;Name_length&apos;]]# 将小数向上舍入train[&apos;Fare_ceil&apos;] = train.Fare.apply(np.ceil)train.loc[0:4,[&apos;Fare&apos;,&apos;Fare_ceil&apos;]]# 将字符串分离，并提取前一部分，以 Name 列为例train.Name.str.split(&apos;,&apos;) # 按逗号隔开train.Name.str.split(&apos;,&apos;).apply(lambda x:x[0]).head() # 也可使用函数进行分离并提取：def get_element(my_list,position): return my_list[position]train.Name.str.split(&apos;,&apos;).apply(get_element,position=0).head() DataFrame.apply() 的使用： 12345678drinks = pd.read_csv(&apos;data/drinks.csv&apos;)# 查询选定列中各行的最大值# 参数 axis=0，即为查询选定列中各列的最大值drinks.loc[:,&apos;beer_servings&apos;:&apos;wine_servings&apos;].apply(max,axis=1)# 返回选定列中各行最大值的列名（标签）drinks.loc[:,&apos;beer_servings&apos;:&apos;wine_servings&apos;].apply(np.argmax,axis=1) DataFrame.applymap() 的使用： 12# 将各列数据的类型修改为 floatdrinks.loc[:,&apos;beer_servings&apos;:&apos;wine_servings&apos;].applymap(float) 更多函数用法请参见：pandas.Series.apply 、pandas.DataFrame.apply 、pandas.DataFrame.applymap 参考文献 Data analysis in Python with pandas pandas documentation Data School pandas.Series.apply pandas.DataFrame.apply pandas.DataFrame.applymap]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>pandas</tag>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas系列教程（六）]]></title>
    <url>%2F2018%2F03%2F02%2F11-Pandas%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%EF%BC%88%E5%85%AD%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这是教程系列之六，对应 Data analysis in Python with pandas 视频26~28，欢迎大家关注。 数据去重 读取数据： 123import pandas as pduser_cols = [&apos;user_id&apos;, &apos;age&apos;, &apos;gender&apos;, &apos;occupation&apos;,&apos;zip_code&apos;]users = pd.read_table(&apos;data/u.user&apos;, sep=&apos;|&apos;, header=None, names=user_cols,index_col=&apos;user_id&apos;) 查看是否存在重复数据，以及存在多少重复数据： 12345678# 查看某列是否存在重复数据，以 zip_code 列为例users.zip_code.duplicated()# 查看重复数量users.zip_code.duplicated().sum()# 查看所有列完全相同的数据users.duplicated() 筛选重复数据： 123456789# 筛选重复的数据，默认筛选出后面出现的与前面相同的数据，即保留前面重复的数据users.loc[users.duplicated(),:]users.loc[users.duplicated(keep=&apos;first&apos;),:]# 筛选出前面出现的与后面相同的数据，即保留后面重复的数据，可选参数 keepusers.loc[users.duplicated(keep=&apos;last&apos;),:]# 将前面和后面相同的数据同时筛选出来users.loc[users.duplicated(keep=False),:] 删除重复数据： 123456789101112# 删除后面出现的重复数据# 若要改动原数据集，可修改 inplace 参数users.drop_duplicates(keep=&apos;first&apos;) # 同时删除前面和后面的重复数据users.drop_duplicates(keep=False)# 可自行定义某 n 列完全相同的重复数据users.duplicated(subset=[&apos;age&apos;,&apos;zip_code&apos;])# 删除自行定义的某 n 列完全相同的重复数据users.drop_duplicates(subset=[&apos;age&apos;,&apos;zip_code&apos;]) 避免两种形式的 SettingWithCopyWarning形式（一）：123456# 导入数据import pandas as pdmovies = pd.read_csv(&apos;data/imdb_1000.csv&apos;)# 对 content_rating 列进行频数统计movies.content_rating.value_counts(dropna = False) 上图中，缺失值 NAN 和 NOT RATED 是一个意思，应该如何将其统一为 NAN 呢？ 若单纯地进行赋值，如movies[movies.content_rating==&#39;NOT RATED&#39;].content_rating = np.nan . 则容易产生警告：SettingWithCopyWarning 查询content_rating 列的缺失值之和，发现结果为3，见下图。这说明上面的赋值并没有起到作用。 解决方法： 上图中建议使用.loc[] ，这不失为一个好办法！ 1movies.loc[movies.content_rating==&apos;NOT RATED&apos;,&apos;content_rating&apos;] = np.nan 修改后查询content_rating 列的缺失值之和，发现结果为68，说明NOT RATED 全部统一为了 NAN。 形式（二）：12# 筛选 star_rating 列中评分高于9分的电影top_movies = movies.loc[movies.star_rating &gt;= 9,:] 见上图，如何将第1部电影的播放时长 duration 由 142 改为 150 ？ 根据上面的经验，使用 .loc[] 筛选后进行赋值：top_movies.loc[0,&#39;duration&#39;] = 150 奇怪了！为什么还会出现这样的警告？我们对top_movies查看了一下，惊奇地发现，即使出现了警告，但数据却还是改了，说明上面的赋值起了作用！ 产生警告的原因 对于形式（一） 在单纯赋值的命令中，前一部分movies[movies.content_rating==&#39;NOT RATED&#39;]是一个读取项(get item)，而后一部分.content_rating = np.nan是一个修改项(set item)。问题就出现在这，pandas 并不知道 get item 对原数据集应该是查询(view)还是复制(copy)，如果是view，那么在 set item 上将对原数据集直接产生影响；如果是copy，那么将不修改原数据集，而另产生复制数据集进行修改。因此产生该警告，是为了询问到底是view还是copy。 而.loc[]，则将get item和set item 统一为单一的set item，这样就避免了python产生误解，直接对原数据集进行了修改。 对于形式（二） 产生警告的原因同上。top_movies 本身为get item，但pandas 并不知道这是view 还是copy。要想避免该警告，该清晰地告诉它，这是对原数据集进行copy： 1top_movies = movies.loc[movies.star_rating &gt;= 9,:].copy() DataFrame的显示设置通常在查看数据时，数据仅仅显示一部分，或显示太多位小数，或较长的字符串会省略等等。那么如何对DateFrame的显示进行设置呢？ pandas.get_option() 有许多相关的设置，在这里选取几个比较典型的进行详解。 最大显示行数设置1234567891011# 查看当前 DataFrame 的最大显示行数pd.get_option(&apos;display.max_rows&apos;) # 默认为60# 设定最大显示行数，参数 None 为显示全部pd.set_option(&apos;display.max_rows&apos;,None) # 重置，即返回默认设置pd.reset_option(&apos;display.max_rows&apos;) # 最大显示列数设置同理pd.get_option(&apos;display.max_columns&apos;) 最大列宽设置12345# 查看当前 DataFrame 的最大列宽pd.get_option(&apos;display.max_colwidth&apos;) # 默认为50个字符宽# 设定最大列宽pd.set_option(&apos;display.max_colwidth&apos;,1000) 小数点后几位显示设置12# 设置显示小数点后2位pd.set_option(&apos;display.precision&apos;,2) 每隔3位数值显示逗号123456# 新建 x,y 列drinks[&apos;x&apos;] = drinks.wine_servings * 1000drinks[&apos;y&apos;] = drinks.total_litres_of_pure_alcohol * 1000# 设置每隔 3 位数加一逗号pd.set_option(&apos;display.float_format&apos;,&apos;&#123;:,&#125;&apos;.format) 最后给个小提示：如果在没有连接互联网的情况下，输入命令也可以查询关于get_option()的相关documents. 12345# 查询所有显示设置的命令pd.describe_option()# 查询关于‘row’的显示设置的命令pd.describe_option(&apos;row&apos;) 参考文献 Data analysis in Python with pandas pandas documentation Data School pandas.get_option()]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>pandas</tag>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas系列教程（五）]]></title>
    <url>%2F2018%2F03%2F01%2F10-Pandas%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%EF%BC%88%E4%BA%94%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这是教程系列之五，对应 Data analysis in Python with pandas 视频21~25，欢迎大家关注。 DataFrame.category()的两个功能 查看DataFrame的内存占用信息：DataFrame.info(memory_usage = &#39;deep&#39;) 查看DateFrame每一列的具体内存占用信息：DataFrame.memory_usage(deep = True) 功能一 ：当字符型列为类别时，若类别较少，可将列的类型转化为category，这样将大大减少数据集内存的占用情况，且使得运行也更快一些。 12# 如将 drinks 数据集的 continent 列的类型转化为 categorydrinks[&apos;continent&apos;] = drinks.continent.astype(&apos;category&apos;) 如上图所示，将continent列从object类型转化为category类型后，其每一行的数据都采用编码制进行记录，大大节省了数据的占用空间。 值得注意的是：当类别数量太多时，编码太多，同样不利于减少内存。 类型为category的列，如何设置特定的排序？下面将结合一个例子详细说明： 12# 新建数据集df = pd.DataFrame(&#123;&apos;ID&apos;:[100,101,102,103], &apos;quality&apos;:[&apos;good&apos;,&apos;very good&apos;,&apos;good&apos;,&apos;excellent&apos;]&#125;) 如上图所示，当对quality列排序时，默认是按首字母顺序进行排序。但从逻辑角度说，excellent &gt; very good &gt; good，那么如何将这种常规的字母顺序变为逻辑顺序呢？ 功能二 ：将quality列类型定义category后，并在参数categories和ordered中设定顺序，即可实现数据中每个类别的先后级。 1df[&apos;quality&apos;] = df.quality.astype(&apos;category&apos;, categories=[&apos;good&apos;,&apos;very good&apos;,&apos;excellent&apos;], ordered=True) 使用scikit-learn进行逻辑回归123456789101112131415161718192021# 读取数据集import pandas as pdtrain = pd.read_csv(&apos;data/titanic_train.csv&apos;) # 训练集test = pd.read_csv(&apos;data/titanic_test.csv&apos;) # 测试集# 提取训练特征feature_cols = [&apos;Pclass&apos;, &apos;Parch&apos;] # 选取特征列X = train_loc[:, feature_cols] # 训练集自变量y = train_Survived # 训练集因变量X_new = test.loc[:, feature_cols] # 测试集自变量# Logistic 回归from sklearn.linear_model import LogisticRegressionlogreg = LogisticRegression()logreg.fit(X, y)# 对测试集进行预测，得到预测结果new_pred_class = logreg.predict(X_new)# 对结果新建 DataFrame，并导出到 csv 数据文件中pd.DataFrame(&#123;&apos;PassengerId&apos;:test.PassengerId, &apos;Survived&apos;:new_pred_class&#125;).set_index(&apos;PassengerId&apos;).to_csv(&apos;data/sub.csv&apos;) DataFrame数据导出在pandas中，读取数据DataFrame.read_csv()十分方便，导出数据同样方便，直接DataFrame.to_csv()即可。 其次，介绍一下DataFrame.to_pickle()，该命令导出数据更加简单，它和导出csv数据文件有什么区别呢？ pickle这个用起来特别简单，根本就没有其他参数。它比较特殊的是可以实现将数据或对象序列化为字节流，pickling也就是保存为二进制数，unpickling就是相反的过程。pickle的意思是泡菜，把数据泡起来之后就可以长久存放不容易变质，pickle被当做永久储存数据的一个方法。 我见过用pickle保存数据是在机器学习中。把训练好的模型存成pickle文件，下次使用这个模型的时候直接读取pickle文件，而不需要再次训练。 上面来自 Python数据分析_Pandas04_本地数据的导入导出 的介绍。 DataFrame选取随机样本如何对一个DataFrame选取随机样本，DataFrame.sample()是一个十分简单的方式： 1234567# 以 ufo 数据集为例ufo.sample(n=3) # 随机取出 n 个样本# 参数 random_state 为设定随机种子，设定随机种子后每次选取样本结果不改变ufo.sample(n=3, random_state=40)ufo.sample(frac=0.75, random_state=99) # 随机取出 75% 的样本 创建虚拟变量(dummy variables) 对于上图的Sex列，如何建立哑变量，即将其值 female和 male 转化为0和1呢？ （两种方式）： 12345# 方法 1：创建新列 Sex_male ，并将 Sex 映射过去train[&apos;Sex_male&apos;] = train.Sex.map(&#123;&apos;female&apos;:0, &apos;male&apos;:1&#125;)# 方法 2：使用 get_dummies() 命令pd.get_dummies(train,columns=[&apos;Sex&apos;],drop_first=True) 使用方式 2 会更方便一些，因为它可以将原Sex列自动删除掉，而方式 1 创建了新列Sex_male，但仍保留着原Sex列。 对多类别的列创建虚拟变量，和上同理，见下图： Series.dt.~的使用 以数据集 ufo 为例： 上图中 Time 列的类型为 object ，该如何获取时间的小时数？可使用字符截取： 1ufo.Time.str.slice(-5,-3).astype(int).head() # 取倒数第4、5位 但这样的方式并不方便，更好的方法是将Time列转化为时间类型，这样可更方便地进行操作：ufo[&#39;Time&#39;] = pd.to_datetime(ufo.Time) 将类型转化之后，即可方便地进行各种操作： 12345# 获取小时、每周第几天名称、每周第几天、每年第几天等等ufo.Time.dt.hourufo.Time.dt.weekday_nameufo.Time.dt.weekdayufo.Time.dt.dayofyear 设置时间戳：ts = pd.to_datetime(&#39;1/1/1999&#39;) 设置了时间戳之后，可方便地筛选数据： 画出ufo数据集每年的目击数量： 12345%matplotlib inlineufo[&apos;Year&apos;] = ufo.Time.dt.year # 获取年份作为新的一列# value_counts()进行频数统计，sort_index()进行年份排序ufo.Year.value_counts().sort_index().plot() 具体更多关于Datetime的操作详见 pandas Datatimelike Properties . 参考文献 Data analysis in Python with pandas pandas documentation Data School Python数据分析_Pandas04_本地数据的导入导出 pandas Datatimelike Properties]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>pandas</tag>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas系列教程（四）]]></title>
    <url>%2F2018%2F02%2F28%2F9-Pandas%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%EF%BC%88%E5%9B%9B%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这是教程系列之四，对应 Data analysis in Python with pandas 视频16~20，欢迎大家关注。 缺失数据的处理 查询是否为缺失值：DataFrame.isnull() 查询是否为非缺失值：DataFrame.notnull() 删除缺失值：DateFrame.dropna() 123456# 删除任意列出现缺失值的行ufo.dropna(how=&apos;any&apos;)# 删除所有列出现缺失值的行ufo.dropna(how=&apos;all&apos;).shape# 删除选定列中出现缺失值的行（任意或所有）ufo.dropna(subset=[&apos;City&apos;,&apos;Shape Reported&apos;],how=&apos;any&apos;) 填充缺失值：DataFrame.fillna() 123456# 如将 Shape Reported 列中的缺失值替换为 VARIOUSufo[&apos;Shape Reported&apos;].fillna(value=&apos;VARIOUS&apos;, inplace=True)# 另外除了人为设定填充，还可自动填充，实现参数为 methodufo.fillna(method = &apos;bfill&apos;).tail() # 按后一项往前填充 ufo.fillna(method = &apos;ffill&apos;).tail() # 按前一项往后填充 频数统计命令DataFrame.value_counts()可选用参数dropna，见下图，避免剔除缺失值： 关于pandas index - 1（DataFrame行索引） 索引行数据：DataFrame.loc() 12345# 如索引 drinks 数据集第23行，beer_servings 列drinks.loc[23, &apos;beer_servings&apos;]# 索引多行多列drinks.loc[0:23, [&apos;beer_servings&apos;,&apos;country&apos;]] 将country列设为行标签：drinks.set_index(&#39;country&#39;, inplace=True) 上图中可见country被设为了行标签，但行标签名country却单独作为一行并不美观，去掉行标签名方法：drinks.index.name = None 重设行标签，将行标签country重新变为单独列： 12drinks.index.name = &apos;country&apos; # 重新定义行标签名drinks.reset_index(inplace = Ture) 关于pandas index - 2（Series行索引） 将country列设为行标签：drinks.set_index(&#39;country&#39;, inplace=True) 新建一列：pd.Series() 将新建的列与原数据集合并：pd.concat，参数axis可决定行合并还是列合并： .loc,.iloc,.ix的用法详解 DataFrame.loc()主要用于标签索引 DataFrame.iloc()主要用于位置索引 从上图显然可见，.loc是对行和列的标签进行索引，而.iloc是对行和列出现的位置进行索引。由于python计数方式是半开半闭式的，因此对于两个函数来说，第一个参数虽然相同，但.iloc返回的是前4行，即第0行、第1行、第2行和第3行，而.loc返回的则包含了 0~4 这5个标签的行。 值得注意的是，在筛选数据时，如对ufo.City == &#39;Oakland&#39;进行筛选（存在两种方式）： 12ufo[ufo.City == &apos;Oakland&apos;] # 或ufo.loc[ufo.City == &apos;Oakland&apos;,:] 两种筛选方式的运行步骤并不相同。相对来说，使用.loc进行筛选会更好一些，对程序的兼容性更好，不容易出现错误，具体原因在后续会讲到。 DataFrame.ix()是标签和位置的混合索引，但由于容易引起程序的混乱，在新版本的python中已经被弃用了。 参数inplace的用法参数inplace出现在DataFrame的多个函数属性当中，如DataFrame.drop(),DataFrame.dropna(),DataFrame.rename(),DataFrame.set_index,DataFrame.sort_value()等等。 其主要作用就是让你选择是否直接对原数据集进行修改。默认为inplace = False，即不直接对原数据集进行修改，防止一时手误出错。 参考文献 Data analysis in Python with pandas pandas documentation Data School]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>pandas</tag>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas系列教程（三）]]></title>
    <url>%2F2018%2F02%2F27%2F8-Pandas%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%EF%BC%88%E4%B8%89%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这是教程系列之三，对应 Data analysis in Python with pandas 视频11~15，欢迎大家关注。 参数“axis”的使用 按行操作：axis=0 按列操作：axis=1 使用axis参数的命令：DataFrame.drop(),DataFrame.mean()等 pandas字符串的操作方法对于简单的字符串(string)，如hello，可直接对其属性进行修改，如将其换为大写字母，&#39;hello&#39;.upper()，可得到&#39;HELLO&#39;。 但是对于DataFrame中的字符类型的列呢？下面的例子可加以说明。 123import pandas as pdorders = pd.read_table(&apos;data/chipotle.tsv&apos;)orders.head() (1) DataFrame见上图，将item_name该列的所有小写字母转化为大写字母： (2) 判断item_name该列是否包含Chicken字符段： ​ 将包含Chicken字符段的行挑选出来：orders[orders.item_name.str.contains(&#39;Chicken&#39;)] (3) 将choice_description列中字符的中括号去掉： 123orders.choice_description.str.replace(&apos;[&apos;,&apos;&apos;).str.replace(&apos;]&apos;,&apos;&apos;)# 或orders.choice_description.str.replace(&apos;[\[\]]&apos;,&apos;&apos;) 更多字符串操作方式详见 pandas API reference . 更改Series的数据类型 (1) 上图可清晰地看到drinks数据集每列的类型，那么当要更改其中一列的类型时，该如何操作呢？ 答案十分简单，直接采用series.astype()即可。 1234drinks[&apos;beer_servings&apos;] = drinks.beer_servings.astype(float)# 若想在读取数据时就进行更改：drinks = pd.read_csv(&apos;data/drinks.csv&apos;,dtype=&#123;&apos;beer_servings&apos;:float&#125;) (2) 另外，在图2中，最后一列的价格含有美元$符号，说明该列的数据类型也是字符，如何对该列求平均值呢？ 结合上一小节，可将美元符号去掉，再将其转换为float类型，即可对该列求平均值： 1orders.item_price.str.replace(&apos;$&apos;,&apos;&apos;).astype(float).mean() (3) 最后，在图4中，对于布尔值的结果，如何将其转化为简单的0和1呢？ 1orders.item_name.str.contains(&apos;Chicken&apos;).astype(int) pandas使用“groupby”进行分组操作groupby()是DataFrame的另一个属性，可对DataFrame的列进行分组操作： 12345# 如要根据‘continent’列分组，对‘beer_servings’列进行各种统计drinks.groupby(&apos;continent&apos;).beer_servings.mean() # 求均值drinks.groupby(&apos;continent&apos;).beer_servings.max() # 求最大值drinks.groupby(&apos;continent&apos;).beer_servings.min() # 求最小值drinks.groupby(&apos;continent&apos;).beer_servings.agg([&apos;count&apos;,&apos;min&apos;,&apos;max&apos;,&apos;mean&apos;]) # 综合统计 此外，还可引入matplotlib对分组统计情况绘画条形图： 12%matplotlib inlinedrinks.groupby(&apos;continent&apos;).mean().plot(kind=&apos;bar&apos;) 探索pandas Series 导入数据集：movies = pd.read_csv(&#39;data/imdb_1000.csv&#39;) 对genre列进行频数统计（如需标准化可添加参数 normalize = True ）：movies.genre.value_counts() 获取genre列的标签：movies.genre.unique() 获取genre列的标签数：movies.genre.nunique() 获取genre列和content_rating列的交叉统计表：pd.crosstab(movies.genre, movies.content_rating) 对genre列的频数统计表作条形图：movies.genre.value_counts().plot(kind = &#39;bar&#39;) 对duration列作柱状图：movies.duration.plot(kind=&#39;hist&#39;) 参考文献 Data analysis in Python with pandas pandas documentation Data School]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>pandas</tag>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas系列教程（二）]]></title>
    <url>%2F2018%2F02%2F26%2F7-Pandas%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%EF%BC%88%E4%BA%8C%EF%BC%89%2F</url>
    <content type="text"><![CDATA[这是教程系列之二，对应 Data analysis in Python with pandas 视频6~10，欢迎大家关注。 从DataFrame移除列 十分简单，直接使用DataFrame.drop()即可： 1234567891011import pandas as pdufo = pd.read_csv(&apos;data/ufo.csv&apos;)ufo.head()# 移除单列ufo.drop(&apos;Colors Reported&apos;, axis=1, inplace=True)ufo.head()# 移除多列ufo.drop([&apos;City&apos;,&apos;State&apos;], axis=1, inplace=True)ufo.head() 移除后的结果如图： 移除行同理，如移除前2行：ufo.drop([0,1]),axis=0,inplace=True 对DataFrame或Series进行排序 读取数据集：movies = pd.read_csv(&#39;data/imdb_1000.csv&#39;) 对Series进行排序（使用sort_values()命令）： 1movies.title.sort_values() # movies[&apos;title&apos;].sort_values() 这种形式是将DataFrame中的某列提取出来后进行排序，结果类型不再是DataFrame。如图： 对DataFrame根据某列进行排序： 12345# 参数ascending为升序选项，True为升序，False为降序movies.sort_values(&apos;duration&apos;)# 对DataFrame多列进行组合排序movies.sort_values([&apos;content_rating&apos;,&apos;duration&apos;]) 在此，sort_values()默认并无改动原数据集的顺序，如需改动，可添加参数inplace=Ture。 在DataFrame中根据列值筛选行 首先要了解什么是布尔值：type(True); 根据列值筛选行：（两种方法） 12345678910111213# 以列“duration”为例，挑选 duration &gt;= 200 的行# 使用For-loopboolean = []for length in movies.duration: if length &gt;=200: booleans.append(True) else: booleans.append(False)is_long = pd.Series(booleans)movies[is_long]# 简便方法，避免使用For-loopmovies[movies.duration &gt;= 200] 根据筛选结果再返回其他列值： 12345# 如返回 duration &gt;= 200 的 genre 值movies[movies.duration &gt;= 200].genre #movies[movies.duration &gt;= 200][&apos;genre&apos;]# 可使用DataFrame.loc()获得同样结果movies.loc[movies.duration &gt;= 200, &apos;genre&apos;] 在DataFrame多种筛选条件结合使用 使用和 “&amp;”、或“|” 等逻辑符号： 12movies[(movies.duration &gt;= 200) &amp; (movies.genre == &apos;Drama&apos;)]movies[(movies.duration &gt;= 200) | (movies.genre == &apos;Drama&apos;)] 使用pandas.series.isin()： 12# 筛选犯罪、剧情、动作等电影movies[movies.genre.isin([&apos;Crime&apos;,&apos;Drama&apos;,&apos;Action&apos;])] 额外小问题读取数据文件时只读取特定行或列123456# 读取特定行（如前3行）ufo = pd.read_csv(&apos;data/ufo.csv&apos;, nrows=3)# 读取特定列ufo = pd.read_csv(&apos;data/uso.csv&apos;, usecols=[&apos;City&apos;,&apos;State&apos;])ufo = pd.read_csv(&apos;data/uso.csv&apos;, usecols=[0,4]) 对DataFrame每行进行循环迭代123# 循环遍历每行for index, row in ufo.iterrows(): print(index, row.City, row.State) 删除非数值型列删除非数值型列，换个角度说，即筛选出数值型列。首先可通过DataFrame.dtypes()获得DataFrame中每一列的类型。其次，通过DataFrame.select_dtypes()进行筛选。 1234# 以 drinks.csv 为例import numpy as np # 加载numpy库drinks = pd.read_csv(&apos;data/drinks.csv&apos;)drinks.select_dtypes(include=[np.number]).dtypes DataFrame.describe()参数详解上篇教程中，有介绍DataFrame.describe()的用法，在这里详细地讨论一下参数include的不同选择的区别。 当默认参数include = None时，describe()可对数值型列进行描述统计； 当参数include = &#39;all&#39;时，describe()对所有列进行描述统计； 当参数include为类型列表时，describe()对所选类型的列进行描述统计。 参考文献 Data analysis in Python with pandas pandas documentation Data School]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>pandas</tag>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pandas系列教程（一）]]></title>
    <url>%2F2018%2F02%2F25%2F6-Pandas%E7%B3%BB%E5%88%97%E6%95%99%E7%A8%8B%EF%BC%88%E4%B8%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[本文主要是Python的pandas库教程，很久之前在bilibili中看到这份教程：Data analysis in Python with pandas，除了惊异之外，也觉得十分棒。但Python并不经常用，时常会忘记一些命令和函数，在此把这份教程总结一下分享给大家，同时也让自己更好地回忆一下。 注： 在观看教程之外，实践的最佳体验是使用Jupyter Notebook； 相关的数据文件见百度网盘，密码：4dbx 使用pandas读取表格数据文件 什么是表格数据：结构化数据，存在行和列，如csv，xls文件等。 加载pandas并简单读取前几行： 12345import pandas as pd # 加载pandas# 读取数据，注意数据文件位置和notebook文件放在同一目录下orders = pd.read_table(&apos;data/chipotle.tsv&apos;) orders.head() # 查看前5行 若读取数据时发现数据全在同一列，且无列名，形如： 123456# 使用sep定义分隔符，且定义是否读取列名pd.read_table(&apos;~~~&apos; ,sep=&apos;|&apos;, hearder=None)# 给列命名user_cols = [&apos;user_id&apos;, &apos;age&apos;, &apos;gender&apos;, &apos;occupation&apos;]users = pd.read_table(&apos;~~~&apos;, sep=&apos;|&apos;, header=None, names=user_cols) 从DataFrame筛选数据列 查看特定某列，并获取其数据类型 123456ufo = pd.read_table(&apos;data/ufo.csv&apos;, sep=&apos;,&apos;) # 读取数据# 查看特定某列，两种方式ufo[&apos;City&apos;]ufo.Citytype(ufo[&apos;City&apos;]) #获取数据类型 查看多列：ufo[&#39;City&#39;,&#39;Colors Reported&#39;] 将多列合并为一列（需要定义新列）：ufo[&#39;Location&#39;]=ufo.City + &#39;,&#39; + ufo.State 什么命令需要加括号，什么不需要？ 需要加括号的命令：movies.head()，movies.describe()等； 无需加括号的命令：movies.shape，movies.dtypes等； 通常，对数据集进行增、删、查、改、统计等命令需要加括号，而仅仅查看数据集的属性（如维数、类型等）则无需加括号。 123movies.describe() #默认对数值型数据进行描述性统计movies.describe(include=[&apos;object&apos;]) #对字符型数据进行描述性统计movies.describe(include=&apos;all&apos;) #对数据集所有列进行描述 对DataFrame的列进行重命名 读取列名：ufo.columns; 对列进行重命名的三种方式： 12345678910# 使用rename()函数：ufo.rename(columns = &#123;&apos;Colors Reported&apos;:&apos;Colors_Reported&apos;,&apos;Shape Reported&apos;:&apos;Shape_Reported&apos;&#125;, inplace=True)# 建立名字向量：ufo.cols = [&apos;City&apos;,&apos;colors reported&apos;,&apos;shape reported&apos;,&apos;state&apos;,&apos;time&apos;]ufo.columns = ufo.cols# 直接在读取数据时更改列名：ufo = pd.read_csv(&apos;data/ufo.csv&apos;, names=ufo_cols, header=0)# 在这里必须添加header=0，否则读取数据时会将数据集原有列名作为DataFrame的第一列 对列名进行小修改（如符号替换）：ufo.columns = ufo.solumns.str.replace(&#39; &#39;,&#39;_&#39;) 参考文献 Data analysis in Python with pandas pandas documentation Data School 一些pandas小技巧在后续仍会陆续发出，欢迎大家继续关注！]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>pandas</tag>
        <tag>经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[期现套利实证研究]]></title>
    <url>%2F2018%2F02%2F21%2F5-%E6%9C%9F%E7%8E%B0%E5%A5%97%E5%88%A9%E5%AE%9E%E8%AF%81%E7%A0%94%E7%A9%B6%2F</url>
    <content type="text"><![CDATA[前言期现套利是套利活动当中最常用的方式之一，相较于其他类型的套利方式（如跨期套利、跨市场套利、跨品种套利等），期现套利主要是通过捕捉期货市场与现货市场在价格上出现的差距，遵循“低买高卖”的原则在两个市场上进行反方向操作，以获得无风险收益的过程。 期现套利的具体操作方式当前主要存在两种，(1)由持有成本理论发展而来的传统无风险套利模型，(2)基于均值回复原则的统计套利模型。本博文主要给出之前做好的一个小实证（PPT形式），构建统计套利模型，对沪深300ETF和沪深300股指期货进行期现套利，对收益进行分析，并得出相应的结论。 正文 后记今天是年初六，明天就要开盘了，期待明年股市能有更好的表现。]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>套利</tag>
        <tag>实证</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高级运筹学之经典题目]]></title>
    <url>%2F2018%2F02%2F13%2F4-%E9%AB%98%E7%BA%A7%E8%BF%90%E7%AD%B9%E5%AD%A6%E4%B9%8B%E7%BB%8F%E5%85%B8%E9%A2%98%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[高级运筹学是我这个学期的主要课程，老师讲得比较基本，期末布置了好几道十分经典的题目，在这里记录下来一部分，并给出常规的解法，如解析解和数值解，解析解主要参考书是Hillier的《Introduction to Operations research》，数值解主要采用R语言进行编程求解。 No.1 非线性规划问题（KKT条件）普通非线性规划\begin {array} {l} \max f(X) = \ln ({x_1} + 1) + {x_2}\\ s.t.\left\{ \begin{array}{l} 2{x_1} + {x_2} \le 3\\ {x_1} \ge 0,{x_2} \ge 0 \end{array} \right. \end{array}解析解针对上述非线性规划问题，我们首先写出其KKT条件：(1) $\frac{1}{x_1 + 1} - 2\mu _1 \le 0$(2) $x_1(\frac{1}{x_1 + 1} - 2\mu _1) = 0$(3) $1 - \mu _1 \le 0$(4) $x_2(1 - \mu _1) = 0$(5) $2x_1 + x_2 - 3 \le 0$(6) $\mu _1(2x_1 + x_2 - 3) = 0$(7) $x_1 \ge 0,x_2 \ge 0$(8) $\mu _1 \ge 0$ 根据条件(3)，有$\mu _1 \ge 1$.根据条件(7)，有$x_1 \ge 0 $. 显然，存在$\frac{1}{x_1 + 1} - 2\mu _1 &lt; 0$. 因此，由条件(2)，可得$x_1=0$. 由$\mu_1 \ne 0$可知，根据条件(6)，$2x_1 + x_2 - 3 = 0$ 由上述两个步骤可解得，$x_2=3$. 根据条件(4)，由$x_2 \ne 0$可得$\mu_1=1$. 显然，$x_1=0,x_2=3,\mu_1=1$满足所有的KKT条件。因此，$X=(0,3)$是最优解。 数值解针对非线性规划问题的数值解，我们采用R中的nloptr包进行求解。 代码如下： 123456789101112131415161718fn &lt;- function(x)&#123; return(list( &quot;objective&quot; = -log(x[1]+1)-x[2], &quot;gradient&quot; = c(-1/(x[1]+1),-1)))&#125;ineq &lt;- function(x)&#123; constr &lt;- c(2*x[1]+x[2]-3) grad &lt;-c(2,1) return(list(&apos;constraints&apos;=constr,&apos;jacobian&apos;=grad))&#125;x0 &lt;- c(0,1)lb &lt;- c(0,0)ub &lt;- c(Inf,Inf)local_opts &lt;- list(&apos;algorithm&apos;=&apos;NLOPT_LD_MMA&apos;,&apos;xtol_rel&apos;=1.0e-7)opts &lt;- list(&apos;algorithm&apos;=&apos;NLOPT_LD_AUGLAG&apos;,&apos;xtol_rel&apos;=1.0e-7,&apos;maxeval&apos;=1000,&apos;local_opts&apos;=local_opts)ans &lt;- nloptr(x0=x0,eval_f=fn,lb=lb,ub=ub,eval_g_ineq=ineq,opts=opts)ans$solutionans$objective 结果根据以上代码求解，可得$X=(0,3)$是最优解。 二次规划问题\begin{array}{l} \max f(X) = 10x_1 + 4x_2 - x_1^2 + 4x_1x_2 - 4x_2^2\\ s.t.\left\{ \begin{array}{l} x_1 + x_2 \le 6\\ 4x_1 + x_2 \le 18\\ x_1 \ge 0,x_2 \ge 0 \end{array} \right. \end{array}解析解根据上述二次规划问题，我们将其转化为最小化问题并写出相应的KKT条件： \left\{ \begin{array}{l} 2x_1 - 4x_2 - 10 + \mu _1 + 4\mu _2 \le 0\\ x_1(2x_1 - 4x_2 - 10 + \mu _1 + 4\mu _2) = 0\\ - 4x_1 + 8x_2 - 4 + \mu _1 + \mu _2 \le 0\\ x_2( - 4x_1 + 8x_2 - 4 + \mu _1 + \mu _2) = 0\\ \mu _1(x_1 + x_2 - 6) = 0\\ \mu _2(4x_1 + x_2 - 18) = 0\\ x_1,x_2,\mu _1,\mu _2 \ge 0 \end{array} \right.根据上述KKT条件，我们将其转化为线性规划问题，并采用单纯型法解决，如下为转化成线性问题的标准形式： \begin{array}{l} \max 10x_1 + 4x_2\\ \left\{ \begin{array}{l} 2x_1 - 4x_2 + \mu _1 + 4\mu _2 + z_1 = 10\\ - 4x_1 + 8x_2 + \mu _1 + \mu _2 + z_2 = 4\\ x_1 + x_2 + z_3 = 6\\ 4x_1 + x_2 + z_4 = 18 \end{array} \right. \end{array}由单纯型法可得最优解为$X=(4,2)$，且最大值为48. linprog包运行单纯型法linprog包是R语言中专门解决线性规划问题的包，求解方法主要为单纯型法，且能够给出每一步的单纯型表，十分实用且方便。 根据上题转化的线性规划问题，我们用linprog进行求解：12345library(linprog)cvec &lt;- c(10,4)bvec &lt;- c(10,4,6,18)Amat &lt;- rbind(c(2,-4,1,4),c(-4,8,1,1),c(1,1,0,0),c(4,1,0,0))solveLP(cvec,bvec,Amat,verbose=4) #verbose=4可显示最大求解过程 结果如下： 数值解同理，我们采用nloptr包进行求解。由于该包的函数采用的是迭代式算法，得到近似的最优解，如图： No.2 指派运输问题Move-It公司在两个车间生产升降机卡车并将之运往三个分销中心(1,2,3)。两个车间(A,B)生产该产品的成本相同，每部卡车被运往不同分销中心的成本如下表所示（单位：美元）： 车间\分销中心 1 2 3 A 800 700 400 B 600 800 500 公司每星期能够生产60部升降机卡车。每个车间每周可以生产少于50部的任意数量的卡车，所以可以为减少运输成本来调整两个车间生产卡车的数目。而每个分销中心每周需求20部卡车。管理者的目标是确定如何指派每个车间的生产数量以及如何制定总的运输方案可以使总的运输成本最小。 模型建立对于产销平衡的运输问题，常用的解决方法为表上作业法。而对于产销不平衡的运输问题，则需要虚拟一个产地（销地）进行生产（销售），将产销不平衡问题转化为产销平衡问题进行解决。然而在本题中，由于产量和销量分配的随机性（不可固定），采用解决寻常产销平衡问题的表上作业法是不可靠的。因此，本题主要采用模拟仿真求取数值解。 设运输总成本为$z$美元，车间A生产卡车运输至分销中心1、2和3的数量分别为$x_1,x_2,x_3$，车间B生产卡车运输至分销中心1、2和3的数量分别为$x_4,x_5,x_6$.根据题意中的约束条件，可得指派运输问题的数学模型如下： \begin{array}{l} \min z = 800x_1 + 700x_2 + 400x_3 + 600x_4 + 800x_5 + 500x_6\\ s.t.\left\{ \begin{array}{l} 10 < x_1 + x_2 + x_3 < 50\\ 10 < x_4 + x_5 + x_6 < 50\\ x_1 + x_4 = 20\\ x_2 + x_5 = 20\\ x_3 + x_6 = 20\\ x_i \ge 0(i = 1,2, \ldots ,6) \end{array} \right. \end{array}从上述模型可见，车间A与车间B每周生产卡车的数量均小于50.由于公司每周能够生产60辆卡车，且3个分销中心恰好每周均需求20部卡车，因此产量和销量平衡。然而每个车间的生产数量需要合理指派，方可使得运输成本最小。 模拟仿真求数值解123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263%simulationz&lt;-rep(0,1323)dim(z)&lt;-c(21,21,3)for (i in 1:21)&#123; for (j in 1:21)&#123; if (i+j-2 == 20)&#123; z[i,j,1]&lt;-800*(i-1)+600*(j-1) z[i,j,2]&lt;-700*(i-1)+800*(j-1) z[i,j,3]&lt;-400*(i-1)+500*(j-1) &#125; &#125; &#125;z1&lt;-matrix(0,21,21)z2&lt;-matrix(0,21,21)z3&lt;-matrix(0,21,21)for (i in 1:21)&#123; for (j in 1:21)&#123; z1[i,j]&lt;-z[i,22-j,1] z2[i,j]&lt;-z[i,22-j,2] z3[i,j]&lt;-z[i,22-j,3]&#125;&#125;z1&lt;-diag(z1)z2&lt;-diag(z2)z3&lt;-diag(z3)row&lt;-seq(0,20,1)col&lt;-seq(20,0,-1)z1&lt;-cbind(row,col,z1)z2&lt;-cbind(row,col,z2)z3&lt;-cbind(row,col,z3)F &lt;- 0e &lt;- 0maxx &lt;- 42000A &lt;- 0B &lt;- 0for (p in 1:21)&#123; for (q in 1:21)&#123; for (m in 1:21)&#123; a &lt;- z1[p,1]+z2[q,1]+z3[m,1] b &lt;- z1[p,2]+z2[q,2]+z3[m,2] F &lt;- z1[p,3]+z2[q,3]+z3[m,3] if (a&lt;50 &amp; b&lt;50)&#123; A &lt;- c(A,a) B &lt;- c(B,b) e &lt;- c(e,F) if (maxx &gt; F)&#123; maxx &lt;- F max_index &lt;- c(p,q,m) &#125; &#125; &#125; &#125;&#125;max_index &lt;- cbind(max_index,rep(0,3))max_index[1,] &lt;- z1[max_index[1,1],-3]max_index[2,] &lt;- z2[max_index[2,1],-3]max_index[3,] &lt;- z3[max_index[3,1],-3]max_index #最优分配maxx #最低成本 得到如下结果： 最优解车间A分别生产各20部卡车运往分销中心2和3，车间B仅生产20部卡车运往分销中心1，可使得运输成本最低，为34000美元。 lpSolve包求解写了好长一段代码，偶然发现一个R包lpSolve几行代码就能解决。。。123456789library(lpSolve)costs&lt;-matrix(c(800,600,700,800,400,500),2,3)row.signs&lt;-rep(&quot;&lt;&quot;,2)row.rhs&lt;-c(50,50)col.signs&lt;-rep(&quot;=&quot;,3)col.rhs&lt;-c(20,20,20)ans&lt;-lp.transport(costs,direction=&apos;min&apos;,row.signs,row.rhs,col.signs,col.rhs)ans$solutionans$objval 结果如下：结果和上种解法一致。 总结高级运筹学学的范围相较于本科会更广泛一些，但上面几道题也是比较简单和基础的题目，本文没有讲解原理，仅给出了解析解和数值解两种形式下的解法。关于文中的KKT条件等内容，大家可查看参考文献. 参考文献1 Hillier F S, Lieberma G J. Introduction to operations research[M]. Holden-Day, 2015.[2] nloptr包[3] linprog包[4] lpSolve包]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>运筹学</tag>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[竞赛不止，生命不止]]></title>
    <url>%2F2018%2F02%2F10%2F3-%E7%AB%9E%E8%B5%9B%E4%B8%8D%E6%AD%A2%EF%BC%8C%E7%94%9F%E5%91%BD%E4%B8%8D%E6%AD%A2%2F</url>
    <content type="text"><![CDATA[开始研究生的学习生活已经一个学期了，前几天刚回到家，难得放假，而且个人博客才刚搭建好，并没有太大的心思写技术文章。趁着假期，更想好好反思一下自己在这个学期的各个方面，希望能在下学期开学之前尽快制定好自己的计划，取得更多的成果。这和标题又有什么关系呢？其实我想谈的便是从竞赛开始。 从失落开始回想起在去年8月底的时候，看到全国研究生数学建模竞赛正在接受报名的通知，火速邀请了两个伙伴赶紧报了名，想着靠自己本科的知识和多次参加数模竞赛的经验，在研赛中也拿个奖。自己不太重视，和队友也不曾磨合过，仅在赛前开了个小会，了解了一下大家的想法，安排了下计划，就这样走向了赛场。 4天4夜的时间里，我不愿再去回想。唯一的印象就是，题目很难，难得就像一片汪洋，而我们便是在这片汪洋的滔天巨浪中随时颠覆而又艰难挣扎着的小船。 凭我的经验看来，这样紧张而艰难的过程是很难取得好成绩的，因为这只代表了一种情况，我们的实力和知识水平完全不足以解决这样的题目。事实上也的确如此，在两个多月后，一张印着“成功参赛奖”的证书送到我的面前。小小的失落开始涌上心头，觉得自己很不应该，觉得浪费了时间，觉得对不起队友……慢慢地，那种失落的情绪不断蔓延，在我的脑海里来回荡漾着，把我带到四年前第一次参加数模校赛时，同样经历了失败的失落的时刻…… 在反省中进步大一我的专业是应用统计学，大概在4年前，当大数据的概念还没深入百姓家时，我爸妈还悲观地认为，学统计能有什么出路？还不如建筑学、会计等热门。但当我踏进校园，拿到第一份课程表时，才知道统计所学的东西原来这么实用。我暗暗下定决心，一定要好好学习，让家人知道，学统计是有用的，是有出路的。 李师兄，在数学学院也是传奇般的人物。也正是他，将我们带入数学建模的大门。他是个很有激情的人，现在想起来，哪怕我已经是研究生了，但说到鼓励团队、激励团队，却半点不如他。他组织了数模学社，每周给我们上课，算法讲解、软件操作等，虽然什么都不懂，但仍感到快乐。 第一次数模校赛就是这样开始的，和两个小伙伴干了3天3夜。那时并不懂得什么是累，哪怕通宵也很开心。遇到难题也没什么关系，本来就没打算要取得什么成果，网上查资料、看文献，随随便便写了一些东西，连自己都不知道写了什么。但是总算写出了一篇“论文”，想都没想就交了。那时不懂什么是模型，什么是算法，没拿奖就算了，小小的失落感并不能影响自己，更多的是对获奖同学的羡慕以及佩服。 大一太年轻，要学的太多，但凭着没心没肺的态度就这么过来了。 大二由于自己缺乏信心，而且不太会和队友交流，总以为自己不是搞数模的料。但自己还是有点小心急，觉得自己再不努力就要老了。恰好师兄队伍缺人，于是很巧地抱了师兄的“大腿”。叶师兄是个很和善的人，也很有毅力，我敬佩的人不多，他是其中之一。他和洪师姐都十分出色，一个搞算法，一个写论文，而我在一旁写写代码，画画图，排排版之类的，干些小活。 3天过程中，我很紧张，我在配合着师兄设计算法，主要是帮师兄找文献，看哪些模型用得着。然而我并不能做出判断，因为我了解的模型太少了，很多模型让我如此的困惑，例如层次分析一般只用于评价，神经网络不仅用于预测，还用于分类、优化等。 当然，现在的我，对大部分算法理解了其本质和推导之后，自然可以清晰地知道它的用途。但四年前的我，可给师兄带来了太多的麻烦。师兄没有怪我，靠着师兄和师姐，我们拿了省赛二等奖。至今我和师兄还保持着良好的关系。 在持续地担心之后，知道自己如果再想抱别人的大腿，是绝对没有机会的，因此那个学期，疯狂地自学着一套又一套的算法书和软件教程。寒假开始回家一个星期后，毅然回到了学校，参加数模美赛。我还深刻地记得搭车的那个下午，那一缕缕阳光透过车窗，我有多么的不舍。 有多少个日子，我独自在寝室中，看着SPSS教程，打着matlab代码，吃着外卖，天寒地冻、周身漆黑，却浑然不觉。现在想想，甚至会为当时的自己感到心疼。唯一觉得欣慰的是，新找的队友都在陪着我，郑同学和朱同学，我们花了一个星期进行了模拟训练。在知道那次美赛拿了二等奖后，我才明白努力是有回报的。那个寒假是我们最值得留恋的寒假了。即使再寒冷，依然无所畏惧。 在大二下学期，因为项目的关系认识了钟师兄，于是和钟师兄以及杜同学，参加了数据挖掘竞赛。竞赛觉得完成地不是太好，但也拿了个创新奖，聊胜于无。 大三大三伊始，还是参加了国赛，但和去年一样，还是拿了省赛二等奖。另外因为申报了较多的创新创业项目，而且大一大二基础课都上完了，大三迎来了更加繁重的专业课程，因此开始慢慢脱离数模。 但在大三下学期，参加SAS数据分析大赛拿了优秀奖，参加数据挖掘竞赛拿了一等奖，发表了一篇普刊论文。感觉大三是最忙的一年，忙着不知所然。但印象最深的还是在暑假，拿着众多老师的推荐信，申请了许多大学的夏令营。但自己毕竟来自双非，因此拿到的参营资格并不多，也就3所，整个暑假奔往全国各地，虽然很累，但能尽全力展现自己，还是觉得累有所值。 大四大四似乎和竞赛完全脱节了，但也在慢慢地接触科研。科研和竞赛并不相同，虽然干得差不多，查文献、写论文、打代码，但竞赛更刺激，更紧张，而科研更严谨、更需坚持、更需积累，不能一昧地模仿别人。或许本科的竞赛，就是为了未来的研究生活打下铺垫吧。 生命不止，奋斗不止本想着写一篇关于参加竞赛的经验和建议的博文，却写成了发泄个人情感的小白文了。不太擅长写博文，我想以后无特殊情况下不会再写这样的博文了。 说了这么多，其实只是想说明一个道理，坚持和努力是永恒不变的主题，也是取得成功的前提。我没有什么建议，因为自己也不过是个失败者。人总会遇到各种各样的难题，从来没有什么捷径可走。从这个角度讲，信念反而是最重要的东西，远比前人的经验和方法要有用得多。 每个人有每个人的路，网上一搜唾手可得，可以参照，但不要局限在别人的思维上。要靠自己的才华，靠自己的毅力，靠自己的奋斗。 这样一来也总算明白了，生命不止，在于竞赛不止，在于科研不止，归咎到底，是在于奋斗不止。感谢一路伴我走来的人和事，让我奋斗至今，坚强至今，在以后，还需以更顽强的态度去对待生活，对待一切。]]></content>
      <categories>
        <category>Study</category>
      </categories>
      <tags>
        <tag>随笔</tag>
        <tag>竞赛</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo搭建个人博客中有哪些需要注意的坑？]]></title>
    <url>%2F2018%2F02%2F08%2F2-Hexo%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2%E4%B8%AD%E6%9C%89%E5%93%AA%E4%BA%9B%E9%9C%80%E8%A6%81%E6%B3%A8%E6%84%8F%E7%9A%84%E5%9D%91%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[为了搭建个人的免费博客，KIBO可走了不少弯路，尽管参照了众多教程和Hexo文档，但仍难免遭遇到一些细小的“坑”。在这篇博文中，对如何利用Github和Hexo搭建博客的详细过程不再一一叙述，网上教程众多，且大同小异。本文对一些在多数教程中常被忽略的，且容易导致建站失败的小细节一一列出，并给出相应的解决办法。 之一：npm插件安装出错Node.js是搭建博客的基本环境之一，npm则是随同Nodes.js一起安装的包管理工具，主要用于从NPM服务器下载并安装别人编写的第三方插件或命令行程序来丰富我们搭建的博客的功能。如添加博客本地搜索插件(hexo-generator-searchdb): $ npm install hexo-generator-searchdb --save 然而，如果稍不注意或代码打得比较快时，容易产生如下错误： npm ERR! enoent EnoEnt: no such file or director 解决方法这个错误主要是因为npm安装路径没有配置好，只要在npm安装前添加hexo文件夹位置即可： $ cd /.../hexo/ 之二：配置SSH key时的密码设置配置SSH key是建立本地和Github服务器联系的关键一步，因为改动博客时（如添加博文、修改设置等）提交的代码均需要拥有github的相关权限，设置SSH key十分简单，代码如下： $ ssh-keyen -t rsa -C &quot;address@yourmail.com&quot; Generating public/private rsa key pair Enter file in which to save the key (/Users/your_user_directory/.ssh/id_rsa): 多数教程会直接告诉你，一路回车下去就好。当时并没意识到这句话的重要性，当系统跳出密码设置时，鬼使神差地随手打了串密码上去，结果以后每次部署(deploy)博客时，都只能乖乖敲上一长串密码。。。 Enter passphrase (empty for no passphrase): Enter same passphrase again: 解决方法事实上，如果不想每次更新博客都打密码的话，在上图密码设置时可直接回车，现在才体现到一路回车的内在含义。另外，密码设置时，光标是不会移动的，且密码不可见。（之前敲了好几遍密码没一点反应的样子，还以为电脑卡机了。。） 之三：分类页和标签页设置设置分类页和标签页时，主要设置两个部分，(1)修改菜单按钮，(2)新建分类页面和标签页面，代码如下： # 在主题配置文件_config.yml中修改菜单按钮 menu: home: / archives: /archives tags: /tags categories: /categories # 新建页面 $ cd your-hexo-site $ hexo new page tags $ hexo new page categories 注意在进行上述两个步骤后，Hexo自动生成了分类页和标签页两个页面，但如果不进一步设置，页面是不会显示任何东西的。因此还需对新建的页面进行编辑，根据路径：/…/hexo/source/tags(categories)/，分别找到index.md文件，添加type语段： # 设置标签页 title: 标签 date: 2018-2-8 23:19:00 type: &quot;tags&quot; # 设置分类页 title: 分类 date: 2018-2-8 23:19:00 type: &quot;categories&quot; 之四：博客主页菜单栏中文乱码通常在设置菜单栏时，我们会选择中文，但即使我们在站点配置文件中将language设置为zh-Hans,仍不能保证中文的正常显示，很有可能出现中文乱码。 解决方法每次修改站点配置文件_config.yml后，都要习惯性地将其保存为UTF-8格式： 以上是这次分享的一些小经验，其实都并非什么解决不了的难题，大不了多尝试几次即可，甚至可加深对整个Hexo框架的了解。所以说，实践才是检验真理的唯一标准。如果在接下来的博客建设中还遇到其他难题，也会在本篇文章中继续更新。]]></content>
      <categories>
        <category>Work</category>
      </categories>
      <tags>
        <tag>经验</tag>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾2017]]></title>
    <url>%2F2018%2F02%2F06%2F1-%E5%9B%9E%E9%A1%BE2017%2F</url>
    <content type="text"><![CDATA[回顾仔细想想，2017年也过去一个多月了，至今仿佛还沉浸在去年的生活当中，毕竟6月份是毕业季，本科四年的点点滴滴还在脑海中不断荡漾。前2天看到一篇博客，讲的是5分钟搭建免费个人博客，想想觉得挺有意思的，于是便有了这个博客的产生。对于从本科统计专业转到研究生管科专业的我来说，计算机编程实在不是我的强项，5分钟真心做不到搭建好一个博客，前前后后花了两天时间，下篇博文打算讲讲我的采坑经历。 但是第一篇博文该写什么呢？思前想后，还是写写个人总结最简单吧。嘻嘻，希望能借助该博客不断地激励自己好好学习，天天向上！ 上半年自从2016年9月份成功保研以后，大四的生活简直便如同颓废了一般。虽说仍能够每天8点起床，但对于本科前三年受够了艰苦学习的自己来说，生活可以说是不要太好。于是屁颠屁颠地跑去考了个BEC中级，拿了个C等级。虽然飘过，但毕竟花了600多大洋，还是直痛恨自己为什么不能再刻苦一点。1月初是寒假，早早回家后便赶往学车考驾照。 说实话，过年这种东西的确没什么意思，可能我是放假放得太多了，都疲倦了。于是17年的上半年，也就是大四的下学期了，回校便专注于毕业论文的事了。毕业论文搞了个套利研究。可能是受到了邓老师的影响吧？但指导老师却找了钱老师，邓老师和钱老师都是多么好的老师啊，还有徐老师，到现在还是挺怀念他们的。 这个学期发生了什么有趣的事呢？5月份写了一份创业孵化空间申报书，答辩时横扫全场，受到评委的一致好评，这不得不说让我挺自豪的。另外印象深刻的就是毕业照了，多么值得怀念的事啊！ Po张宿舍集体照，左二是我，为何拘谨地像个小女生？。。。 毕业照之后便是毕业典礼，说起来还挺尴尬的，在辅导员的怂恿下，报名了毕业典礼的代表演讲。选拔是通过了，但却因为没有申请校优秀毕业生失去了这次机会。不得不说真是本科的最后一次教训啊，有机会得到的东西一定要拼尽权利去把握。 最后是毕业分离了，6月份抱着及时行乐的心态，不是KTV就是聚餐，舍不得舍友舍不得同学舍不得老师。大学四年也就这么轰轰烈烈地过去了，我想我应该对得起自己吧。 下半年暑假没去实习，也没回家，跟老师借了办公室，静静地学习。其实也没学什么，捣鼓了一下 JoinQuant,学着写了几个策略，另外上了吴恩达老师的 Machine Learning，受到了很大的启发。同时，在一个老朋友的鼓励下，写了一篇小论文。后来，论文被导师批得体无完肤。 9月份，我的研究生之路也开始了，虽然读得是管理科学，但是自己搞的还是蛮偏向数学和计算机方面。有点无奈的是上的课大部分是本科都接触过的，比如多元统计、运筹学等等，上课并非很多，但自己怎么总是挤不出时间来搞研究？一个学期很快就过去了，却一定成果都没有，很惭愧。 12月份和1月份是汇报的高峰期，接连3周都在汇报，那段时间可把我忙惨啦，还得承受着是否会受到老师批评的巨大压力，苦不堪言。舍友还在寻思着要退学，但现在想起来，总得学会如何去跨过那道坎，而不是逃避，要勇于面对。 1月底随着老师去清远调研，清远是个好地方，山清水秀，舒适悠闲。调研的3天中，顿顿清远鸡成为了我的美好记忆，哈哈哈。学倒没学到什么，只是跟着去旅游了，但还是能感受到清远的现实问题，人才急缺，或许自己未来能去机会碰碰机会吧。 林林总总地记了些流水账，原来自己的语水平写作水平还是那么低，实在是汗颜。以后写论文可有得忙活了，靠多写博客来锻炼吧。2017年虽然过去了，但对于自己的研究生涯来说，却是刚刚开始，希望自己能够坚持下去。 展望十几天后，大年初三，就是我的生日了。在此，希望能提前许下自己的愿望，对自己提出更高的要求，让自己在未来的一年中活得更加充实。 下学期的任务：一篇SCI或SSCI 申报研究生项目 每周至少两篇博客 每周至少阅读两篇论文 完成深度学习Coursera课程 每天20个引体向上 每天健身半小时或一小时 研究基金 每天保证8个小时以上的睡眠 多喝水。。。 好像任务有点多，但是不能怂，要直面困难，把握好机会，让青春无悔！就这样吧，废话不多说了！]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
